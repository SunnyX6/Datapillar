<?xml version="1.0" encoding="UTF-8"?>
<!DOCTYPE mapper PUBLIC "-//mybatis.org//DTD Mapper 3.0//EN"
	"http://mybatis.org/dtd/mybatis-3-mapper.dtd">
<mapper namespace="com.sunny.job.admin.mapper.DatapillarJobInfoMapper">

	<resultMap id="DatapillarJobInfo" type="com.sunny.job.admin.model.DatapillarJobInfo" >
		<result column="id" property="id" />

		<result column="job_group" property="jobGroup" />
	    <result column="job_desc" property="jobDesc" />

	    <result column="create_time" property="createTime" />
	    <result column="update_time" property="updateTime" />

	    <result column="created_by" property="createdBy" />
	    <result column="alarm_email" property="alarmEmail" />


		<result column="executor_route_strategy" property="executorRouteStrategy" />
		<result column="executor_handler" property="executorHandler" />
	    <result column="executor_param" property="executorParam" />
		<result column="executor_block_strategy" property="executorBlockStrategy" />
		<result column="executor_timeout" property="executorTimeout" />
		<result column="executor_fail_retry_count" property="executorFailRetryCount" />

	    <result column="glue_type" property="glueType" />
	    <result column="glue_source" property="glueSource" />
	    <result column="glue_remark" property="glueRemark" />
		<result column="glue_updatetime" property="glueUpdatetime" />
		<result column="workflow_id" property="workflowId" />

		<!-- 任务状态管理字段（从job_state合并而来） -->
		<result column="status" property="status" />
		<result column="dependency_completed" property="dependencyCompleted" />
		<result column="start_time" property="startTime" />
		<result column="end_time" property="endTime" />

	</resultMap>

	<sql id="Base_Column_List">
		t.id,
		t.job_group,
		t.job_desc,
		t.create_time,
		t.update_time,
		t.created_by,
		t.alarm_email,
		t.executor_route_strategy,
		t.executor_handler,
		t.executor_param,
		t.executor_block_strategy,
		t.executor_timeout,
		t.executor_fail_retry_count,
		t.glue_type,
		t.glue_source,
		t.glue_remark,
		t.glue_updatetime,
		t.workflow_id,
		t.status,
		t.dependency_completed,
		t.start_time,
		t.end_time
	</sql>

	<select id="pageList" parameterType="java.util.HashMap" resultMap="DatapillarJobInfo">
		SELECT <include refid="Base_Column_List" />
		FROM job_info AS t
		<trim prefix="WHERE" prefixOverrides="AND | OR" >
			<if test="jobGroup gt 0">
				AND t.job_group = #{jobGroup}
			</if>
            <if test="triggerStatus gte 0">
            </if>
			<if test="jobDesc != null and jobDesc != ''">
				AND t.job_desc like CONCAT(CONCAT('%', #{jobDesc}), '%')
			</if>
			<if test="executorHandler != null and executorHandler != ''">
				AND t.executor_handler like CONCAT(CONCAT('%', #{executorHandler}), '%')
			</if>
			<if test="created_by != null and created_by != ''">
				AND t.created_by like CONCAT(CONCAT('%', #{createdBy}), '%')
			</if>
		</trim>
		ORDER BY id DESC
		LIMIT #{offset}, #{pagesize}
	</select>

	<select id="pageListCount" parameterType="java.util.HashMap" resultType="int">
		SELECT count(1)
		FROM job_info AS t
		<trim prefix="WHERE" prefixOverrides="AND | OR" >
			<if test="jobGroup gt 0">
				AND t.job_group = #{jobGroup}
			</if>
            <if test="triggerStatus gte 0">
            </if>
			<if test="jobDesc != null and jobDesc != ''">
				AND t.job_desc like CONCAT(CONCAT('%', #{jobDesc}), '%')
			</if>
			<if test="executorHandler != null and executorHandler != ''">
				AND t.executor_handler like CONCAT(CONCAT('%', #{executorHandler}), '%')
			</if>
			<if test="created_by != null and created_by != ''">
				AND t.created_by like CONCAT(CONCAT('%', #{createdBy}), '%')
			</if>
		</trim>
	</select>

	<insert id="save" parameterType="com.sunny.job.admin.model.DatapillarJobInfo" useGeneratedKeys="true" keyProperty="id" >
		INSERT INTO job_info (
			job_group,
			job_desc,
			created_by,
			alarm_email,
			executor_route_strategy,
			executor_handler,
			executor_param,
			executor_block_strategy,
			executor_timeout,
			executor_fail_retry_count,
			glue_type,
			glue_source,
			glue_remark,
			glue_updatetime,
			workflow_id
		) VALUES (
			#{jobGroup},
			#{jobDesc},
			#{createdBy},
			#{alarmEmail},
			#{executorRouteStrategy},
			#{executorHandler},
			#{executorParam},
			#{executorBlockStrategy},
			#{executorTimeout},
			#{executorFailRetryCount},
			#{glueType},
			#{glueSource},
			#{glueRemark},
			#{glueUpdatetime},
			#{workflowId}
		);
	</insert>

	<select id="loadById" parameterType="java.util.HashMap" resultMap="DatapillarJobInfo">
		SELECT <include refid="Base_Column_List" />
		FROM job_info AS t
		WHERE t.id = #{id}
	</select>

	<update id="update" parameterType="com.sunny.job.admin.model.DatapillarJobInfo" >
		UPDATE job_info
		SET
			job_group = #{jobGroup},
			job_desc = #{jobDesc},
			created_by = #{createdBy},
			alarm_email = #{alarmEmail},
			executor_route_strategy = #{executorRouteStrategy},
			executor_handler = #{executorHandler},
			executor_param = #{executorParam},
			executor_block_strategy = #{executorBlockStrategy},
			executor_timeout = #{executorTimeout},
			executor_fail_retry_count = #{executorFailRetryCount},
			glue_type = #{glueType},
			glue_source = #{glueSource},
			glue_remark = #{glueRemark},
			glue_updatetime = #{glueUpdatetime}
		WHERE id = #{id}
	</update>

	<delete id="delete" parameterType="java.util.HashMap">
		DELETE
		FROM job_info
		WHERE id = #{id}
	</delete>

	<select id="getJobsByGroup" parameterType="java.util.HashMap" resultMap="DatapillarJobInfo">
		SELECT <include refid="Base_Column_List" />
		FROM job_info AS t
		WHERE t.job_group = #{jobGroup}
	</select>

	<select id="findAllCount" resultType="int">
		SELECT count(1)
		FROM job_info
	</select>


	<select id="scheduleJobQuery" parameterType="java.util.HashMap" resultMap="DatapillarJobInfo">
		SELECT <include refid="Base_Column_List" />
		FROM job_info AS t
		ORDER BY id ASC
		LIMIT #{pagesize}
	</select>

	<update id="scheduleUpdate" parameterType="com.sunny.job.admin.model.DatapillarJobInfo"  >
		UPDATE job_info
		SET
			<if test="triggerStatus gte 0">
			</if>
		WHERE id = #{id}
	</update>

	<update id="updateWorkflowId">
		UPDATE job_info
		SET workflow_id = #{workflowId}
		WHERE id = #{jobId}
	</update>

	<select id="findByWorkflowId" resultMap="DatapillarJobInfo">
		SELECT <include refid="Base_Column_List" />
		FROM job_info AS t
		WHERE t.workflow_id = #{workflowId}
		ORDER BY id
	</select>

	<select id="loadByIds" resultMap="DatapillarJobInfo">
		SELECT <include refid="Base_Column_List" />
		FROM job_info AS t
		WHERE t.id IN
		<foreach item="item" index="index" collection="ids" open="(" separator="," close=")">
			#{item}
		</foreach>
	</select>

	<insert id="batchInsert" parameterType="java.util.List" useGeneratedKeys="true" keyProperty="id">
		INSERT INTO job_info (
			job_group,
			job_desc,
			created_by,
			alarm_email,
			executor_route_strategy,
			executor_handler,
			executor_param,
			executor_block_strategy,
			executor_timeout,
			executor_fail_retry_count,
			glue_type,
			glue_source,
			glue_remark,
			glue_updatetime,
			workflow_id
		) VALUES
		<foreach collection="jobInfoList" item="item" separator=",">
			(
				#{item.jobGroup},
				#{item.jobDesc},
				#{item.createdBy},
				#{item.alarmEmail},
				#{item.executorRouteStrategy},
				#{item.executorHandler},
				#{item.executorParam},
				#{item.executorBlockStrategy},
				#{item.executorTimeout},
				#{item.executorFailRetryCount},
				#{item.glueType},
				#{item.glueSource},
				#{item.glueRemark},
				#{item.glueUpdatetime},
				#{item.workflowId}
			)
		</foreach>
	</insert>

	<!-- ==================== 任务状态管理相关方法（从DatapillarJobTaskStateMapper迁移） ==================== -->

	<!-- 根据工作流ID和任务ID加载任务信息（含状态） -->
	<select id="loadByWorkflowAndJob" resultMap="DatapillarJobInfo">
		SELECT <include refid="Base_Column_List" />
		FROM job_info AS t
		WHERE t.workflow_id = #{workflowId} AND t.id = #{jobId}
	</select>

	<!-- 根据工作流ID批量加载任务（指定jobIds） -->
	<select id="loadByWorkflowAndJobs" resultMap="DatapillarJobInfo">
		SELECT <include refid="Base_Column_List" />
		FROM job_info AS t
		WHERE t.workflow_id = #{workflowId}
		  AND t.id IN
		<foreach item="item" index="index" collection="jobIds" open="(" separator="," close=")">
			#{item}
		</foreach>
	</select>

	<!-- 使用行锁加载任务（FOR UPDATE） -->
	<select id="loadByWorkflowAndJobForUpdate" resultMap="DatapillarJobInfo">
		SELECT <include refid="Base_Column_List" />
		FROM job_info AS t
		WHERE t.workflow_id = #{workflowId} AND t.id = #{jobId}
		FOR UPDATE
	</select>

	<!-- 更新任务状态 -->
	<update id="updateStatus" parameterType="com.sunny.job.admin.model.DatapillarJobInfo">
		UPDATE job_info
		SET status = #{status},
			start_time = #{startTime},
			end_time = #{endTime}
		WHERE id = #{id}
	</update>

	<!-- 使用CAS方式更新状态（防止重复触发） -->
	<update id="updateStatusWithCAS" parameterType="java.util.HashMap">
		UPDATE job_info
		SET status = #{newStatus},
			start_time = #{startTime}
		WHERE workflow_id = #{workflowId}
		  AND id = #{jobId}
		  AND status = #{oldStatus}
	</update>

	<!-- 使用数据库JSON函数原子性添加依赖 -->
	<update id="addDependencyCompletedAtomic" parameterType="java.util.HashMap">
		UPDATE job_info
		SET dependency_completed = JSON_ARRAY_APPEND(
			COALESCE(dependency_completed, '[]'),
			'$',
			#{dependencyJobId}
		)
		WHERE workflow_id = #{workflowId}
		  AND id = #{jobId}
		  AND NOT JSON_CONTAINS(
			COALESCE(dependency_completed, '[]'),
			CAST(#{dependencyJobId} AS JSON),
			'$'
		  )
	</update>

	<!-- 根据工作流ID查找等待状态的任务 -->
	<select id="findPendingTasks" parameterType="java.lang.Long" resultMap="DatapillarJobInfo">
		SELECT <include refid="Base_Column_List" />
		FROM job_info AS t
		WHERE t.workflow_id = #{workflowId} AND t.status = 'PENDING'
		ORDER BY t.create_time ASC
	</select>

	<!-- 根据工作流ID和状态查找任务 -->
	<select id="findByWorkflowIdAndStatus" resultMap="DatapillarJobInfo">
		SELECT <include refid="Base_Column_List" />
		FROM job_info AS t
		WHERE t.workflow_id = #{workflowId} AND t.status = #{status}
		ORDER BY t.create_time ASC
	</select>

	<!-- 批量更新任务状态 -->
	<update id="batchUpdateStatus" parameterType="java.util.HashMap">
		UPDATE job_info
		SET status = #{status}
		WHERE workflow_id = #{workflowId}
		<if test="jobIds != null and jobIds.size() > 0">
			AND id IN
			<foreach collection="jobIds" item="jobId" open="(" separator="," close=")">
				#{jobId}
			</foreach>
		</if>
	</update>

	<!-- 重置工作流所有任务状态为PENDING（用于重跑） -->
	<update id="resetWorkflowTaskStates" parameterType="java.lang.Long">
		UPDATE job_info
		SET status = 'PENDING',
			dependency_completed = '[]',
			start_time = NULL,
			end_time = NULL
		WHERE workflow_id = #{workflowId}
	</update>

	<!-- 批量初始化任务状态（只初始化新增节点，不影响已有数据） -->
	<update id="batchInitStatusByJobIds" parameterType="java.util.HashMap">
		UPDATE job_info
		SET status = IFNULL(status, 'PENDING'),
			dependency_completed = IFNULL(dependency_completed, '[]')
		WHERE workflow_id = #{workflowId}
		  AND id IN
		<foreach collection="jobIds" item="jobId" open="(" separator="," close=")">
			#{jobId}
		</foreach>
	</update>

</mapper>
