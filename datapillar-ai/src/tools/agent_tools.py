"""
Agent å·¥å…·é›†
ä½¿ç”¨ LangChain æ ‡å‡†çš„ @tool è£…é¥°å™¨å®šä¹‰å·¥å…·
"""

import json
from typing import Annotated, List, Optional, Any, Dict
import logging

logger = logging.getLogger(__name__)
from langchain_core.tools import tool
from pydantic import BaseModel, Field
from neo4j_graphrag.retrievers import VectorRetriever
from neo4j_graphrag.embeddings.base import Embedder

from src.core.database import Neo4jClient, MySQLClient


# ==================== çŸ¥è¯†åœ°å›¾ Schema ====================

class GlobalStatistics(BaseModel):
    """å…¨å±€ç»Ÿè®¡ä¿¡æ¯"""
    total_atomic_metrics: int = Field(..., description="åŸå­æŒ‡æ ‡æ€»æ•°")
    total_derived_metrics: int = Field(..., description="æ´¾ç”ŸæŒ‡æ ‡æ€»æ•°")
    total_composite_metrics: int = Field(..., description="å¤åˆæŒ‡æ ‡æ€»æ•°")
    total_tables: int = Field(..., description="æ€»è¡¨æ•°")
    total_columns: int = Field(..., description="æ€»åˆ—æ•°")


class TableInfo(BaseModel):
    """è¡¨ä¿¡æ¯"""
    name: str = Field(..., description="è¡¨å")
    display_name: str = Field(..., description="è¡¨æ˜¾ç¤ºå")
    description: str = Field(..., description="è¡¨æè¿°")
    column_count: int = Field(..., description="è¯¥è¡¨çš„åˆ—æ•°")


class SchemaInfo(BaseModel):
    """Schema å±‚ä¿¡æ¯"""
    layer: str = Field(..., description="å±‚çº§æ ‡è¯†ï¼ˆSRC/ODS/DWD/DWSï¼‰")
    name: str = Field(..., description="å±‚çº§æ˜¾ç¤ºå")
    description: str = Field(..., description="å±‚çº§æè¿°")
    table_count: int = Field(..., description="è¯¥å±‚è¡¨æ•°é‡")
    atomic_metric_count: int = Field(..., description="è¯¥å±‚çš„åŸå­æŒ‡æ ‡æ•°")
    derived_metric_count: int = Field(..., description="è¯¥å±‚çš„æ´¾ç”ŸæŒ‡æ ‡æ•°")
    composite_metric_count: int = Field(..., description="è¯¥å±‚çš„å¤åˆæŒ‡æ ‡æ•°")
    tables: List[TableInfo] = Field(default_factory=list, description="è¡¨åˆ—è¡¨")


class SubjectInfo(BaseModel):
    """Subject ä¿¡æ¯"""
    name: str = Field(..., description="ä¸»é¢˜æ˜¾ç¤ºå")
    subject_name: str = Field(..., description="ä¸»é¢˜åç§°")
    description: str = Field(..., description="ä¸»é¢˜æè¿°")
    schemas: List[SchemaInfo] = Field(default_factory=list, description="Schema åˆ—è¡¨")


class CatalogInfo(BaseModel):
    """Catalog ä¿¡æ¯"""
    name: str = Field(..., description="ç›®å½•æ˜¾ç¤ºå")
    catalog_name: str = Field(..., description="ç›®å½•åç§°")
    description: str = Field(..., description="ç›®å½•æè¿°")
    subject: SubjectInfo = Field(..., description="Subject ä¿¡æ¯")


class BusinessHierarchy(BaseModel):
    """ä¸šåŠ¡å±‚çº§ç»“æ„"""
    domain: str = Field(..., description="ä¸šåŠ¡åŸŸæ˜¾ç¤ºå")
    domain_name: str = Field(..., description="ä¸šåŠ¡åŸŸåç§°")
    description: str = Field(..., description="ä¸šåŠ¡æè¿°")
    catalog: CatalogInfo = Field(..., description="Catalog ä¿¡æ¯")


class KnowledgeMapPayload(BaseModel):
    """çŸ¥è¯†åœ°å›¾è¿”å›æ•°æ®ç»“æ„"""
    system_instruction: str = Field(..., description="ç³»ç»ŸæŒ‡ä»¤")
    statistics: GlobalStatistics = Field(..., description="å…¨å±€ç»Ÿè®¡ä¿¡æ¯")
    business_hierarchy: BusinessHierarchy = Field(..., description="ä¸šåŠ¡å±‚çº§ç»“æ„")


# ==================== ç»Ÿä¸€å·¥å…·è¿”å›ç»“æ„ ====================

class ToolResult(BaseModel):
    """
    ç»Ÿä¸€çš„å·¥å…·è¿”å›ç»“æ„

    æ³¨æ„ï¼šsearch_assets å·¥å…·ä¸ä½¿ç”¨æ­¤ç»“æ„ï¼Œç›´æ¥è¿”å› kg_context JSON
    """
    status: str = Field(..., description="çŠ¶æ€ï¼šsuccess/error/partial")
    tool_name: str = Field(..., description="å·¥å…·åç§°")
    data: Any = Field(default=None, description="å·¥å…·è¿”å›çš„æ•°æ®")
    message: Optional[str] = Field(None, description="å¯é€‰çš„æè¿°ä¿¡æ¯")
    error: Optional[str] = Field(None, description="é”™è¯¯ä¿¡æ¯ï¼ˆä»…å½“ status=error æ—¶ï¼‰")


# ==================== å·¥å…·å‚æ•° Schema ====================

class SearchAssetsInput(BaseModel):
    """æœç´¢æ•°æ®èµ„äº§çš„å‚æ•°"""
    query: str = Field(
        ...,
        description="æœç´¢å…³é”®è¯ï¼Œç”¨äºåŒ¹é…è¡¨åã€åˆ—åã€æè¿°ç­‰ï¼Œæ”¯æŒè‡ªç„¶è¯­è¨€æŸ¥è¯¢ï¼ˆå¦‚'è®¢å•è¡¨'ã€'ç”¨æˆ·ç›¸å…³çš„è¡¨'ï¼‰"
    )


class GetTableLineageInput(BaseModel):
    """è·å–è¡¨è¡€ç¼˜è¯¦æƒ…çš„å‚æ•°ï¼ˆåŸå­æ“ä½œï¼‰"""
    source_table: str = Field(
        ...,
        description="æºè¡¨åï¼Œå¦‚ 'orders' æˆ– 'mysql.orders'"
    )
    target_table: Optional[str] = Field(
        None,
        description="ç›®æ ‡è¡¨åï¼ˆå¯é€‰ï¼‰ï¼Œå¦‚ 'dwd_orders'ã€‚å¦‚æœæä¾›ï¼Œä¼šæŸ¥è¯¢æºè¡¨åˆ°ç›®æ ‡è¡¨çš„åˆ—çº§è¡€ç¼˜å’Œ JOIN å…³ç³»"
    )


# ==================== å¤šæ¨¡å‹ Embedder ====================

class MultiModelEmbedder(Embedder):
    """æ”¯æŒå¤šç§æ¨¡å‹çš„ Embedderï¼ˆGLMã€OpenAIã€DeepSeekï¼‰"""

    def __init__(self, config: Dict[str, Any]):
        self.config = config
        self.provider = config["provider"].lower()

    def embed_query(self, text: str) -> List[float]:
        """ç”Ÿæˆå•ä¸ªæŸ¥è¯¢çš„å‘é‡åµŒå…¥"""
        if self.provider == "glm":
            from zai import ZhipuAiClient
            client = ZhipuAiClient(
                api_key=self.config["api_key"],
                base_url=self.config.get("base_url")
            )
            response = client.embeddings.create(
                model=self.config["model_name"],
                input=text
            )
            if hasattr(response, "data") and len(response.data) > 0:
                return response.data[0].embedding
            elif isinstance(response, dict) and "data" in response:
                return response["data"][0]["embedding"]
            else:
                raise ValueError(f"æ— æ³•ä»Embeddingå“åº”ä¸­æå–å‘é‡: {response}")

        elif self.provider in ["openai", "deepseek"]:
            from openai import OpenAI
            client = OpenAI(
                api_key=self.config["api_key"],
                base_url=self.config.get("base_url")
            )
            response = client.embeddings.create(
                model=self.config["model_name"],
                input=text
            )
            return response.data[0].embedding

        else:
            raise ValueError(f"ä¸æ”¯æŒçš„Embeddingæ¨¡å‹æä¾›å•†: {self.provider}")


# ==================== å…¨å±€å˜é‡ ====================

_neo4j_client: Neo4jClient = None
_mysql_client: MySQLClient = None
_embedder: MultiModelEmbedder = None
_vector_retriever: VectorRetriever = None


def init_tools(
    neo4j_client: Neo4jClient,
    mysql_client: MySQLClient = None,
    embedding_config: Dict[str, Any] = None,
):
    """åˆå§‹åŒ–å·¥å…·ä¾èµ–"""
    global _neo4j_client, _mysql_client, _embedder, _vector_retriever
    _neo4j_client = neo4j_client
    _mysql_client = mysql_client

    if embedding_config:
        _embedder = MultiModelEmbedder(embedding_config)
        # åˆå§‹åŒ– VectorRetriever
        _vector_retriever = VectorRetriever(
            driver=neo4j_client.driver,
            index_name="table_vector_index",
            embedder=_embedder,
            return_properties=["name", "displayName", "description"]
        )


# ==================== å·¥å…·å®šä¹‰ ====================

@tool(args_schema=SearchAssetsInput)
async def search_assets(query: str) -> str:
    """
    æœç´¢æ•°ä»“æ•°æ®èµ„äº§ï¼ˆå‘é‡+å›¾æ··åˆæ£€ç´¢ï¼‰

    [åŠŸèƒ½]: åŸºäºç”¨æˆ·æŸ¥è¯¢ï¼Œä½¿ç”¨å‘é‡ç›¸ä¼¼åº¦+å›¾éå†æ··åˆæ£€ç´¢ï¼Œè¿”å›æœ€ç›¸å…³çš„è¡¨ã€åˆ—ã€æŒ‡æ ‡ç­‰æ•°æ®èµ„äº§ã€‚

    [æ£€ç´¢ç­–ç•¥]:
    - å‘é‡æ£€ç´¢ï¼šåŸºäº embedding è¯­ä¹‰ç›¸ä¼¼åº¦å¬å› Top-K èŠ‚ç‚¹ï¼ˆTableã€Columnã€Metric ç­‰ï¼‰
    - å›¾éå†ï¼šåŸºäºå¬å›èŠ‚ç‚¹å‘ä¸Šæ‰©å±•ä¸šåŠ¡å±‚çº§ï¼ˆSchema â†’ Subject â†’ Catalog â†’ Domainï¼‰
    - å…¨æ–‡æ£€ç´¢ï¼šè¾…åŠ©åŒ¹é…è¡¨åã€å­—æ®µåã€æè¿°ç­‰

    [è¿”å›å†…å®¹]:
    - åŒ¹é…åˆ°çš„è¡¨ï¼ˆåŒ…å«åˆ—ä¿¡æ¯ã€ä¸‹æ¸¸è¡€ç¼˜å…³ç³»ã€å…³è”æŒ‡æ ‡ï¼‰
    - ä¸šåŠ¡å±‚çº§ä¸Šä¸‹æ–‡ï¼ˆæ‰€å± Domain/Catalog/Subject/Schemaï¼‰
    - ç›¸å…³æ€§å¾—åˆ†

    Examples:
    - User: "è®¢å•è¡¨" -> è¿”å›åŒ…å« ordersã€order_detail ç­‰è¡¨
    - User: "ç”¨æˆ·ç›¸å…³çš„è¡¨" -> è¿”å› userã€user_profileã€user_behavior ç­‰è¡¨
    - User: "é”€å”®é¢æŒ‡æ ‡" -> è¿”å›å…³è”çš„è¡¨å’ŒæŒ‡æ ‡
    """
    if not _vector_retriever:
        logger.error("âŒ VectorRetriever æœªåˆå§‹åŒ–ï¼Œè¯·å…ˆé…ç½® embedding_config")
        return json.dumps({
            "status": "error",
            "message": "å‘é‡æ£€ç´¢æœªé…ç½®",
            "tables": []
        }, ensure_ascii=False, indent=2)

    try:
        # Step 1: ä½¿ç”¨ VectorRetriever æ£€ç´¢ Top-K è¡¨èŠ‚ç‚¹
        retrieval_results = _vector_retriever.search(query_text=query, top_k=10)

        if not retrieval_results.items:
            logger.warning(f"âš  æœªæ‰¾åˆ°ä¸'{query}'ç›¸å…³çš„æ•°æ®èµ„äº§")
            return json.dumps({
                "status": "no_results",
                "message": f"æœªæ‰¾åˆ°ä¸'{query}'ç›¸å…³çš„æ•°æ®èµ„äº§",
                "tables": []
            }, ensure_ascii=False, indent=2)

        # Step 2: åŸºäºå¬å›çš„è¡¨èŠ‚ç‚¹ï¼Œå›¾éå†è·å–è¯¦ç»†ä¿¡æ¯
        table_ids = [item.node.element_id for item in retrieval_results.items]

        expand_cypher = """
        UNWIND $table_ids AS table_id
        MATCH (table:Table)
        WHERE elementId(table) = table_id

        // è·å–åˆ—ä¿¡æ¯
        OPTIONAL MATCH (table)-[:HAS_COLUMN]->(col:Column)

        // è·å–ä¸‹æ¸¸è¡€ç¼˜
        OPTIONAL MATCH (table)-[:HAS_DOWNSTREAM_LINEAGE]->(downstream:Table)

        // è·å–ä¸šåŠ¡å±‚çº§ä¸Šä¸‹æ–‡
        MATCH (table)<-[:CONTAINS]-(sch:Schema)<-[:CONTAINS]-(subj:Subject)<-[:CONTAINS]-(cat:Catalog)<-[:CONTAINS]-(dom:Domain)

        WITH table, sch, subj, cat, dom,
             collect(DISTINCT {
                 name: col.name,
                 displayName: col.displayName,
                 dataType: col.dataType,
                 description: col.description
             }) as columns,
             collect(DISTINCT downstream.name) as downstream_tables

        RETURN
            elementId(table) as table_id,
            table.name as table_name,
            table.displayName as table_display_name,
            table.description as table_description,
            columns,
            downstream_tables,
            sch.layer as schema_layer,
            sch.displayName as schema_name,
            subj.displayName as subject_name,
            cat.displayName as catalog_name,
            dom.displayName as domain_name
        """

        expanded_results = _neo4j_client.execute_query(expand_cypher, {"table_ids": table_ids})

        # Step 3: æ„å»ºè¿”å›ç»“æœï¼ˆåˆå¹¶å‘é‡å¾—åˆ†å’Œå›¾éå†è¯¦æƒ…ï¼‰
        score_map = {item.node.element_id: item.score for item in retrieval_results.items}

        search_results = {
            "status": "success",
            "query": query,
            "total_results": len(expanded_results),
            "tables": []
        }

        for result in expanded_results:
            table_info = {
                "table_name": result["table_name"],
                "table_display_name": result["table_display_name"],
                "description": result["table_description"],
                "relevance_score": float(score_map.get(result["table_id"], 0.0)),
                "columns": result["columns"],
                "downstream_lineage": result["downstream_tables"],
                "business_context": {
                    "domain": result["domain_name"],
                    "catalog": result["catalog_name"],
                    "subject": result["subject_name"],
                    "schema": result["schema_name"],
                    "layer": result["schema_layer"]
                }
            }
            search_results["tables"].append(table_info)

        # æŒ‰ç›¸å…³æ€§å¾—åˆ†æ’åº
        search_results["tables"].sort(key=lambda x: x["relevance_score"], reverse=True)

        logger.info(
            f"âœ… [å·¥å…·å®Œæˆ] search_assets æ‰¾åˆ° {len(expanded_results)} ä¸ªç›¸å…³è¡¨ï¼Œ"
            f"Top1: {search_results['tables'][0]['table_name']} (score: {search_results['tables'][0]['relevance_score']:.3f})"
        )

        return json.dumps(search_results, ensure_ascii=False, indent=2)

    except Exception as e:
        logger.error(f"âŒ search_assets æ‰§è¡Œå¤±è´¥: {e}", exc_info=True)
        return json.dumps({
            "status": "error",
            "message": f"æœç´¢å¤±è´¥ï¼š{str(e)}",
            "tables": []
        }, ensure_ascii=False, indent=2)


@tool(args_schema=GetTableLineageInput)
async def get_table_lineage(source_table: str, target_table: Optional[str] = None) -> str:
    """
    è·å–è¡¨çš„è¯¦ç»†ä¿¡æ¯å’Œè¡€ç¼˜å…³ç³»ï¼ˆåŸå­æ“ä½œï¼‰

    [åŠŸèƒ½]: æŸ¥è¯¢å•ä¸ªæºè¡¨çš„è¯¦ç»†ä¿¡æ¯ï¼ˆåˆ—ã€ç±»å‹ã€æè¿°ï¼‰åŠå…¶ä¸ç›®æ ‡è¡¨çš„è¡€ç¼˜å…³ç³»ã€‚

    [è¿”å›å†…å®¹]:
    - æºè¡¨çš„åˆ—ä¿¡æ¯ï¼ˆnameã€dataTypeã€descriptionï¼‰
    - å¦‚æœæä¾› target_tableï¼š
      * ç›®æ ‡è¡¨çš„åˆ—ä¿¡æ¯
      * åˆ—çº§è¡€ç¼˜æ˜ å°„ï¼ˆsource.column â†’ target.columnï¼‰
      * è½¬æ¢ç±»å‹ï¼ˆdirectã€transformã€aggregateï¼‰
    - å¦‚æœæœªæä¾› target_tableï¼š
      * æºè¡¨çš„æ‰€æœ‰ä¸‹æ¸¸è¡€ç¼˜è¡¨åˆ—è¡¨

    [ä½¿ç”¨åœºæ™¯]:
    - å•è¡¨åŒæ­¥ï¼šget_table_lineage("orders", "dwd_orders")
    - å¤šä»»åŠ¡ï¼šA1â†’B1 å’Œ A2â†’B2ï¼Œåˆ†åˆ«è°ƒç”¨ä¸¤æ¬¡
    - æ¢ç´¢ä¸‹æ¸¸ï¼šget_table_lineage("orders") æŸ¥çœ‹æ‰€æœ‰ä¸‹æ¸¸è¡¨

    Examples:
    - get_table_lineage("orders", "dwd_orders") â†’ è¿”å› orders â†’ dwd_orders çš„åˆ—æ˜ å°„
    - get_table_lineage("orders") â†’ è¿”å› orders çš„åˆ—ä¿¡æ¯å’Œæ‰€æœ‰ä¸‹æ¸¸è¡¨
    """
    logger.info(f"ğŸ”§ [å·¥å…·è°ƒç”¨] get_table_lineage(source='{source_table}', target='{target_table}')")

    try:
        if target_table:
            # åœºæ™¯1ï¼šæŸ¥è¯¢ source â†’ target çš„åˆ—çº§è¡€ç¼˜
            cypher = """
            MATCH (source:Table {name: $source_table})
            MATCH (target:Table {name: $target_table})

            // è·å–æºè¡¨çš„æ‰€æœ‰åˆ—ï¼ˆç‹¬ç«‹è·¯å¾„ï¼Œé¿å…ç¬›å¡å°”ç§¯ï¼‰
            OPTIONAL MATCH (source)-[:HAS_COLUMN]->(source_col:Column)

            // è·å–ç›®æ ‡è¡¨çš„æ‰€æœ‰åˆ—ï¼ˆç‹¬ç«‹è·¯å¾„ï¼‰
            OPTIONAL MATCH (target)-[:HAS_COLUMN]->(target_col:Column)

            // è·å–æ˜¾å¼çš„åˆ—çº§è¡€ç¼˜å…³ç³»ï¼ˆåªåŒ¹é…å­˜åœ¨ LINEAGE_TO å…³ç³»çš„åˆ—ï¼‰
            OPTIONAL MATCH (source)-[:HAS_COLUMN]->(sc:Column)-[:LINEAGE_TO]->(tc:Column)<-[:HAS_COLUMN]-(target)

            RETURN
                source.name as source_table_name,
                source.displayName as source_display_name,
                source.description as source_description,
                collect(DISTINCT {
                    name: source_col.name,
                    displayName: source_col.displayName,
                    dataType: source_col.dataType,
                    description: source_col.description
                }) as source_columns,
                target.name as target_table_name,
                target.displayName as target_display_name,
                target.description as target_description,
                collect(DISTINCT {
                    name: target_col.name,
                    displayName: target_col.displayName,
                    dataType: target_col.dataType,
                    description: target_col.description
                }) as target_columns,
                collect(DISTINCT {
                    source_column: sc.name,
                    target_column: tc.name,
                    transformation_type: "direct"
                }) as column_lineage
            """

            results = _neo4j_client.execute_query(cypher, {
                "source_table": source_table,
                "target_table": target_table
            })

            if not results:
                return json.dumps({
                    "status": "not_found",
                    "message": f"æœªæ‰¾åˆ°è¡¨ '{source_table}' æˆ– '{target_table}'",
                    "source_table": None,
                    "target_table": None,
                    "column_lineage": []
                }, ensure_ascii=False, indent=2)

            result = results[0]

            # æå–æºåˆ—å’Œç›®æ ‡åˆ—
            source_columns = [col for col in result["source_columns"] if col.get("name")]
            target_columns = [col for col in result["target_columns"] if col.get("name")]

            # æå–æ˜¾å¼è¡€ç¼˜æ˜ å°„
            explicit_lineage = [
                mapping for mapping in result.get("column_lineage", [])
                if mapping.get("source_column") and mapping.get("target_column")
            ]

            # ğŸ”¥ å¦‚æœæ²¡æœ‰æ˜¾å¼è¡€ç¼˜å…³ç³»ï¼ŒåŸºäºåˆ—ååŒ¹é…ç”Ÿæˆé»˜è®¤æ˜ å°„
            column_lineage = explicit_lineage
            if not explicit_lineage:
                logger.info("âš ï¸ æœªæ‰¾åˆ°æ˜¾å¼è¡€ç¼˜å…³ç³»ï¼ŒåŸºäºåˆ—ååŒ¹é…ç”Ÿæˆé»˜è®¤æ˜ å°„")
                # åˆ›å»ºç›®æ ‡åˆ—åé›†åˆï¼Œä¾¿äºå¿«é€ŸæŸ¥æ‰¾
                target_col_names = {col["name"] for col in target_columns}

                # ä¸ºæ¯ä¸ªæºåˆ—å¯»æ‰¾åŒåç›®æ ‡åˆ—
                for source_col in source_columns:
                    source_name = source_col["name"]
                    if source_name in target_col_names:
                        column_lineage.append({
                            "source_column": source_name,
                            "target_column": source_name,  # åŒåæ˜ å°„
                            "transformation_type": "direct"
                        })

            lineage_info = {
                "status": "success",
                "has_lineage": bool(explicit_lineage),  # æ˜¯å¦æœ‰æ˜¾å¼è¡€ç¼˜
                "source_table": {
                    "name": result["source_table_name"],
                    "display_name": result["source_display_name"],
                    "description": result["source_description"],
                    "columns": source_columns
                },
                "target_table": {
                    "name": result["target_table_name"],
                    "display_name": result["target_display_name"],
                    "description": result["target_description"],
                    "columns": target_columns
                },
                "column_lineage": column_lineage
            }

            logger.info(
                f"âœ… [å·¥å…·å®Œæˆ] get_table_lineage æ‰¾åˆ° {len(source_columns)} ä¸ªæºåˆ—ï¼Œ"
                f"{len(target_columns)} ä¸ªç›®æ ‡åˆ—ï¼Œ"
                f"{len(column_lineage)} ä¸ªè¡€ç¼˜æ˜ å°„ï¼ˆ{'æ˜¾å¼' if explicit_lineage else 'åŸºäºåç§°åŒ¹é…'}ï¼‰"
            )

            return json.dumps(lineage_info, ensure_ascii=False, indent=2)

        else:
            # åœºæ™¯2ï¼šåªæŸ¥è¯¢ source è¡¨çš„è¯¦ç»†ä¿¡æ¯å’Œä¸‹æ¸¸è¡¨
            cypher = """
            MATCH (source:Table {name: $source_table})

            // è·å–æºè¡¨åˆ—
            OPTIONAL MATCH (source)-[:HAS_COLUMN]->(col:Column)

            // è·å–ä¸‹æ¸¸è¡€ç¼˜è¡¨
            OPTIONAL MATCH (source)-[:HAS_DOWNSTREAM_LINEAGE]->(downstream:Table)

            WITH source,
                 collect(DISTINCT {
                     name: col.name,
                     displayName: col.displayName,
                     dataType: col.dataType,
                     description: col.description
                 }) as columns,
                 collect(DISTINCT downstream.name) as downstream_tables

            RETURN
                source.name as table_name,
                source.displayName as display_name,
                source.description as description,
                columns,
                downstream_tables
            """

            results = _neo4j_client.execute_query(cypher, {"source_table": source_table})

            if not results:
                return json.dumps({
                    "status": "not_found",
                    "message": f"æœªæ‰¾åˆ°è¡¨ '{source_table}'",
                    "table": None
                }, ensure_ascii=False, indent=2)

            result = results[0]

            table_info = {
                "status": "success",
                "table": {
                    "name": result["table_name"],
                    "display_name": result["display_name"],
                    "description": result["description"],
                    "columns": [col for col in result["columns"] if col.get("name")]
                },
                "downstream_tables": [
                    name for name in result.get("downstream_tables", [])
                    if name
                ]
            }

            logger.info(
                f"âœ… [å·¥å…·å®Œæˆ] get_table_lineage æ‰¾åˆ° {len(table_info['table']['columns'])} ä¸ªåˆ—ï¼Œ"
                f"{len(table_info['downstream_tables'])} ä¸ªä¸‹æ¸¸è¡¨"
            )

            return json.dumps(table_info, ensure_ascii=False, indent=2)

    except Exception as e:
        logger.error(f"âŒ get_table_lineage æ‰§è¡Œå¤±è´¥: {e}", exc_info=True)
        return json.dumps({
            "status": "error",
            "message": f"æŸ¥è¯¢å¤±è´¥ï¼š{str(e)}"
        }, ensure_ascii=False, indent=2)


@tool
def list_component() -> str:
    """
    è·å–æ‰€æœ‰å¯ç”¨ ETL ç»„ä»¶çš„å®Œæ•´é…ç½®

    [åŠŸèƒ½]: ä¸€æ¬¡æ€§è¿”å›æ•°æ®åº“ä¸­æ‰€æœ‰æ¿€æ´»ç»„ä»¶çš„å®Œæ•´é…ç½®ï¼ˆåŒ…æ‹¬ config_schemaï¼‰ï¼Œä¾› LLM é€‰æ‹©ä½¿ç”¨ã€‚

    [è¿”å›å†…å®¹]:
    - component_id: ç»„ä»¶å”¯ä¸€æ ‡è¯†
    - component_name: ç»„ä»¶åç§°
    - component_type: ç»„ä»¶ç±»å‹ï¼ˆETL/SQL/SCRIPTï¼‰
    - category: ç»„ä»¶åˆ†ç±»
    - description: ç»„ä»¶æè¿°
    - config_schema: é…ç½®æ¨¡æ¿ï¼ˆJSON Schemaï¼‰
    - supported_operations: æ”¯æŒçš„æ“ä½œç±»å‹åˆ—è¡¨

    [ä½¿ç”¨åœºæ™¯]:
    - ç”Ÿæˆå·¥ä½œæµèŠ‚ç‚¹æ—¶ï¼Œä»æ‰€æœ‰ç»„ä»¶ä¸­é€‰æ‹©åˆé€‚çš„ç»„ä»¶
    - æ ¹æ®æ“ä½œç±»å‹ï¼ˆsync/transform/aggregateï¼‰ç­›é€‰ç»„ä»¶
    - ä½¿ç”¨ config_schema ç”ŸæˆèŠ‚ç‚¹çš„ config å­—æ®µ

    Returns:
        æ‰€æœ‰ç»„ä»¶çš„å®Œæ•´é…ç½®åˆ—è¡¨ï¼ˆJSONå­—ç¬¦ä¸²ï¼‰

    Examples:
    - ä»è¿”å›ç»“æœä¸­ç­›é€‰ supported_operations åŒ…å« "sync" çš„ç»„ä»¶
    - æ ¹æ® component_id æ‰¾åˆ°å¯¹åº”çš„ config_schema
    """
    logger.info(f"ğŸ”§ [å·¥å…·è°ƒç”¨] list_component() - è¿”å›æ‰€æœ‰ç»„ä»¶é…ç½®")

    if not _mysql_client:
        logger.error("âŒ MySQLClient æœªåˆå§‹åŒ–ï¼Œè¯·å…ˆè°ƒç”¨ init_tools")
        return json.dumps({
            "status": "error",
            "message": "MySQL å®¢æˆ·ç«¯æœªåˆå§‹åŒ–",
            "components": []
        }, ensure_ascii=False, indent=2)

    try:
        query = """
            SELECT
                component_id,
                component_name,
                component_type,
                category,
                description,
                config_schema,
                supported_operations
            FROM xxl_job_component
            WHERE status = 'ACTIVE'
            ORDER BY component_type, component_id
        """

        results = _mysql_client.execute_query(query)

        if not results:
            logger.warning(f"âš ï¸ æœªæ‰¾åˆ°ä»»ä½•å¯ç”¨ç»„ä»¶")
            return json.dumps({
                "status": "error",
                "message": "æœªæ‰¾åˆ°ä»»ä½•å¯ç”¨ç»„ä»¶",
                "components": []
            }, ensure_ascii=False, indent=2)

        # è§£æ JSON å­—æ®µ
        components = []
        for row in results:
            if isinstance(row['config_schema'], str):
                row['config_schema'] = json.loads(row['config_schema'])
            if isinstance(row['supported_operations'], str):
                row['supported_operations'] = json.loads(row['supported_operations'])
            components.append(row)

        logger.info(f"âœ… [å·¥å…·å®Œæˆ] è¿”å› {len(components)} ä¸ªç»„ä»¶çš„å®Œæ•´é…ç½®")

        return json.dumps({
            "status": "success",
            "total": len(components),
            "components": components
        }, ensure_ascii=False, indent=2)

    except Exception as e:
        logger.error(f"âŒ list_component æ‰§è¡Œå¤±è´¥: {e}", exc_info=True)
        return json.dumps({
            "status": "error",
            "message": f"æŸ¥è¯¢å¤±è´¥ï¼š{str(e)}",
            "components": []
        }, ensure_ascii=False, indent=2)


# ==================== å·¥å…·åˆ—è¡¨ ====================

ALL_TOOLS = [
    # å…¨å±€èµ„äº§åœ°å›¾
    search_assets,
    # è¡¨è¡€ç¼˜è¯¦æƒ…
    get_table_lineage,
    # ç»„ä»¶é…ç½®åˆ—è¡¨
    list_component,
]


# ==================== å·¥å…·ç®¡ç†å™¨ ====================

class AgentTools:
    """Agent å·¥å…·ç®¡ç†å™¨"""

    def __init__(self, neo4j_client: Neo4jClient, embedding_config: Dict[str, Any] = None):
        # åˆå§‹åŒ–å…¨å±€ä¾èµ–
        init_tools(neo4j_client, embedding_config)

    def get_all_tools(self) -> list:
        """è·å–æ‰€æœ‰å·¥å…·"""
        return ALL_TOOLS
