"""
Analyst Agentï¼ˆéœ€æ±‚åˆ†æå¸ˆï¼‰

æ ¸å¿ƒç†å¿µï¼šä»ä¸šåŠ¡è§’åº¦æ‹†åˆ†éœ€æ±‚ï¼Œåˆ†è€Œæ²»ä¹‹
- ç”¨æˆ·éœ€æ±‚ â†’ æ‹†æˆå‡ ä¸ªä¸šåŠ¡æ­¥éª¤ â†’ æ¯ä¸ªæ­¥éª¤ä¸€ä¸ª Step
- æ¯ä¸ª Step å¯ä»¥åŒ…å«å¤šä¸ª Stageï¼ˆSQLï¼‰
"""

import json
import logging
from typing import Optional

from langchain_core.messages import AIMessage, HumanMessage
from langgraph.types import Command

from src.agent.etl_agents.schemas.state import AgentState
from src.agent.etl_agents.schemas.requirement import AnalysisResult, Step, Stage
from src.integrations.llm import call_llm

logger = logging.getLogger(__name__)


ANALYST_AGENT_PROMPT = """ä½ æ˜¯èµ„æ·±æ•°æ®éœ€æ±‚åˆ†æå¸ˆï¼Œè´Ÿè´£å°†ç”¨æˆ·çš„ ETL éœ€æ±‚æ‹†åˆ†ä¸ºä¸šåŠ¡æ­¥éª¤ã€‚

## æ ¸å¿ƒç†å¿µ

**ä»ä¸šåŠ¡è§’åº¦æ‹†åˆ†ï¼Œåˆ†è€Œæ²»ä¹‹ã€‚**

## ä¸¤å±‚æ‹†åˆ†

### ç¬¬ä¸€å±‚ï¼šæ‹†åˆ†ä¸šåŠ¡æ­¥éª¤ï¼ˆStepï¼‰
- æ ¸å¿ƒé—®é¢˜ï¼šå®Œæˆè¿™ä¸ªéœ€æ±‚éœ€è¦å‡ ä¸ªä¸šåŠ¡æ­¥éª¤ï¼Ÿ
- æ¯ä¸ª Step æ˜¯ä¸€ä¸ªç‹¬ç«‹çš„ä¸šåŠ¡æ­¥éª¤ï¼Œå¯¹åº”å‰ç«¯ä¸€ä¸ªèŠ‚ç‚¹

### ç¬¬äºŒå±‚ï¼šæ‹†åˆ† Stage ä»»åŠ¡ï¼ˆStageï¼‰
- æ ¸å¿ƒé—®é¢˜ï¼šå®ç°è¿™ä¸ªä¸šåŠ¡æ­¥éª¤éœ€è¦å‡ ä¸ª Stageï¼Ÿ
- æ¯ä¸ª Stage æ˜¯ä¸€ä¸ªä»»åŠ¡ï¼Œäº§å‡ºä¸€ä¸ªè¡¨

## Step æ‹†åˆ†åŸåˆ™

ä»€ä¹ˆæ—¶å€™æ‹†åˆ†å¤šä¸ª Stepï¼š
- éœ€æ±‚æ¶‰åŠå¤šä¸ªç‹¬ç«‹çš„ä¸šåŠ¡æ­¥éª¤
- æŸä¸ªä¸­é—´ç»“æœä¼šè¢«å¤šæ¬¡ä½¿ç”¨
- æœ‰å¤šä¸ªè¾“å‡ºç›®æ ‡

ä»€ä¹ˆæ—¶å€™åªéœ€è¦ä¸€ä¸ª Stepï¼š
- å•è¡¨ç®€å•æŸ¥è¯¢

## Stage æ‹†åˆ†åŸåˆ™

ä»€ä¹ˆæ—¶å€™ä¸€ä¸ª Step éœ€è¦å¤šä¸ª Stageï¼š
- éœ€è¦å…ˆè¿‡æ»¤/æ¸…æ´—æ•°æ®ï¼Œå†åšèšåˆ
- éœ€è¦å…ˆèšåˆï¼Œå†å…³è”å…¶ä»–è¡¨
- é€»è¾‘å¤æ‚ï¼Œæ‹†æˆå¤šæ­¥æ›´æ¸…æ™°
- ä¸­é—´ç»“æœéœ€è¦è¢«åŒ Step å†…å¤šæ¬¡ä½¿ç”¨

ä»€ä¹ˆæ—¶å€™ä¸€ä¸ª Step åªéœ€è¦ä¸€ä¸ª Stageï¼š
- é€»è¾‘ç®€å•ï¼Œä¸€ä¸ª SQL å°±èƒ½æå®š

## ç¤ºä¾‹

### ç®€å•éœ€æ±‚
```
éœ€æ±‚ï¼šæŸ¥è¯¢è®¢å•é‡‘é¢å¤§äº1000çš„VIPç”¨æˆ·

Step 1: æŸ¥è¯¢é«˜é¢è®¢å•VIPç”¨æˆ·
  â””â”€ Stage 1: è¿‡æ»¤æŸ¥è¯¢ â†’ è¾“å‡ºç»“æœè¡¨
```

### ä¸­ç­‰éœ€æ±‚ï¼ˆæ³¨æ„ï¼šStep 1 æœ‰ 2 ä¸ª Stageï¼‰
```
éœ€æ±‚ï¼šè®¡ç®—æ¯ä¸ªç”¨æˆ·çš„æœˆåº¦GMV

Step 1: è®¢å•æœˆåº¦æ±‡æ€»
  â””â”€ Stage 1: è¿‡æ»¤æœ‰æ•ˆè®¢å• â†’ tmp.tmp_valid_orders
  â””â”€ Stage 2: æŒ‰ç”¨æˆ·æœˆèšåˆ â†’ tmp.tmp_user_monthly

Step 2: å…³è”ç”¨æˆ·è¾“å‡º
  â””â”€ Stage 1: å…³è”ç”¨æˆ·ç»´åº¦è¡¨ â†’ dwd.dwd_user_monthly_gmv
```

### å¤æ‚éœ€æ±‚ï¼ˆæ³¨æ„ï¼šStep 1 æœ‰ 5 ä¸ª Stageï¼‰
```
éœ€æ±‚ï¼šç”¨æˆ·æ¶ˆè´¹åˆ†ææŠ¥è¡¨ï¼ŒåŒ…å«æ¶ˆè´¹é‡‘é¢ã€æ¶ˆè´¹é¢‘æ¬¡ã€å®¢å•ä»·

Step 1: è®¡ç®—æ¶ˆè´¹æŒ‡æ ‡
  â””â”€ Stage 1: è¿‡æ»¤æœ‰æ•ˆè®¢å• â†’ tmp.tmp_valid_orders
  â””â”€ Stage 2: è®¡ç®—æ¶ˆè´¹é‡‘é¢ï¼ˆSUMï¼‰ â†’ tmp.tmp_amount
  â””â”€ Stage 3: è®¡ç®—æ¶ˆè´¹é¢‘æ¬¡ï¼ˆCOUNTï¼‰ â†’ tmp.tmp_freq
  â””â”€ Stage 4: è®¡ç®—å®¢å•ä»·ï¼ˆé‡‘é¢/é¢‘æ¬¡ï¼‰ â†’ tmp.tmp_avg_price
  â””â”€ Stage 5: åˆå¹¶ä¸‰ä¸ªæŒ‡æ ‡ â†’ tmp.tmp_user_metrics

Step 2: å…³è”ç”¨æˆ·ä¿¡æ¯è¾“å‡º
  â””â”€ Stage 1: å…³è”ç”¨æˆ·ç»´åº¦è¡¨ â†’ dwd.dwd_user_consume_report
```

## çŸ¥è¯†ä¸Šä¸‹æ–‡

### ç›¸å…³è¡¨
{tables_info}

### JOIN å…³ç³»
{join_info}

## ç”¨æˆ·éœ€æ±‚
{user_query}

## è¾“å‡ºè¦æ±‚

è¯·æŒ‰ä»¥ä¸‹ JSON æ ¼å¼è¾“å‡ºï¼š

```json
{{
  "user_query": "ç”¨æˆ·åŸå§‹è¾“å…¥",
  "summary": "ä¸€å¥è¯æ¦‚æ‹¬éœ€æ±‚",
  "steps": [
    {{
      "step_id": "step_1",
      "step_name": "è®¢å•æœˆåº¦æ±‡æ€»",
      "description": "æ¸…æ´—è®¢å•æ•°æ®å¹¶æŒ‰ç”¨æˆ·æœˆèšåˆ",
      "stages": [
        {{
          "stage_id": 1,
          "name": "è¿‡æ»¤æœ‰æ•ˆè®¢å•",
          "description": "è¿‡æ»¤çŠ¶æ€ä¸ºå·²å®Œæˆçš„è®¢å•",
          "input_tables": ["ods.ods_order"],
          "output_table": "tmp.tmp_valid_orders",
          "is_temp_table": true
        }},
        {{
          "stage_id": 2,
          "name": "æŒ‰ç”¨æˆ·æœˆèšåˆ",
          "description": "æŒ‰ç”¨æˆ·IDå’Œæœˆä»½èšåˆè®¢å•é‡‘é¢",
          "input_tables": ["tmp.tmp_valid_orders"],
          "output_table": "tmp.tmp_user_monthly",
          "is_temp_table": true
        }}
      ],
      "depends_on": [],
      "output_table": "tmp.tmp_user_monthly",
      "suggested_component": "hive"
    }},
    {{
      "step_id": "step_2",
      "step_name": "å…³è”ç”¨æˆ·è¾“å‡º",
      "description": "å…³è”ç”¨æˆ·ä¿¡æ¯å¹¶è¾“å‡ºåˆ°ç›®æ ‡è¡¨",
      "stages": [
        {{
          "stage_id": 1,
          "name": "å…³è”ç”¨æˆ·ç»´åº¦è¡¨",
          "description": "å°†æœˆåº¦æ±‡æ€»æ•°æ®ä¸ç”¨æˆ·ç»´åº¦è¡¨å…³è”",
          "input_tables": ["tmp.tmp_user_monthly", "dim.dim_user"],
          "output_table": "dwd.dwd_user_monthly_gmv",
          "is_temp_table": false
        }}
      ],
      "depends_on": ["step_1"],
      "output_table": "dwd.dwd_user_monthly_gmv",
      "suggested_component": "hive"
    }}
  ],
  "final_target": {{
    "table_name": "dwd.dwd_user_monthly_gmv",
    "write_mode": "overwrite",
    "partition_by": ["dt"]
  }},
  "ambiguities": [],
  "confidence": 0.85
}}
```

## æ³¨æ„äº‹é¡¹
1. ä¸è¦å·æ‡’ï¼è®¤çœŸåˆ†ææ¯ä¸ª Step éœ€è¦å‡ ä¸ª Stage
2. å¤æ‚é€»è¾‘å¿…é¡»æ‹†åˆ†å¤šä¸ª Stageï¼Œä¸è¦æŠŠæ‰€æœ‰é€»è¾‘å¡è¿›ä¸€ä¸ª Stage
3. ä¸´æ—¶è¡¨å‘½åè§„èŒƒï¼štmp.tmp_xxx
4. åªè¾“å‡º JSONï¼Œä¸è¦è§£é‡Š
"""


class AnalystAgent:
    """
    éœ€æ±‚åˆ†æå¸ˆ

    èŒè´£ï¼š
    1. ä»ä¸šåŠ¡è§’åº¦å°†éœ€æ±‚æ‹†åˆ†ä¸º Stepï¼ˆä¸šåŠ¡æ­¥éª¤ï¼‰
    2. æ¯ä¸ª Step å¯ä»¥åŒ…å«å¤šä¸ª Stage
    3. åˆ†è€Œæ²»ä¹‹ï¼Œä¸ºåç»­ SQL ç”Ÿæˆåšå¥½é“ºå«
    """

    def __init__(self):
        self.llm = call_llm(temperature=0.0)

    async def __call__(self, state: AgentState) -> Command:
        """æ‰§è¡Œéœ€æ±‚åˆ†æ"""
        user_query = state.user_input
        knowledge_context = state.knowledge_context

        if not user_query:
            return Command(
                update={
                    "messages": [AIMessage(content="ç¼ºå°‘ç”¨æˆ·è¾“å…¥ï¼Œæ— æ³•åˆ†æéœ€æ±‚")],
                    "current_agent": "analyst_agent",
                    "error": "ç¼ºå°‘ç”¨æˆ·è¾“å…¥",
                }
            )

        logger.info(f"ğŸ“‹ AnalystAgent å¼€å§‹åˆ†æéœ€æ±‚: {user_query}")

        try:
            context_info = self._format_context(knowledge_context)

            prompt = ANALYST_AGENT_PROMPT.format(
                tables_info=context_info["tables"],
                join_info=context_info["joins"],
                user_query=user_query,
            )

            response = await self.llm.ainvoke([HumanMessage(content=prompt)])
            result_dict = self._parse_response(response.content)

            analysis_result = self._build_analysis_result(result_dict, user_query)
            analysis_result = self._validate_and_enrich(analysis_result, knowledge_context)

            plan_summary = analysis_result.get_execution_plan_summary()
            logger.info(f"âœ… AnalystAgent å®Œæˆåˆ†æ:\n{plan_summary}")

            if analysis_result.needs_clarification():
                questions = [a.question for a in analysis_result.ambiguities]
                return Command(
                    update={
                        "messages": [AIMessage(content="éœ€æ±‚åˆ†æå®Œæˆï¼Œæœ‰ä»¥ä¸‹é—®é¢˜éœ€è¦æ¾„æ¸…")],
                        "analysis_result": analysis_result.model_dump(),
                        "current_agent": "analyst_agent",
                        "needs_clarification": True,
                        "clarification_questions": questions,
                    }
                )

            return Command(
                update={
                    "messages": [AIMessage(content=f"éœ€æ±‚åˆ†æå®Œæˆ: {analysis_result.summary}")],
                    "analysis_result": analysis_result.model_dump(),
                    "current_agent": "analyst_agent",
                }
            )

        except Exception as e:
            logger.error(f"AnalystAgent åˆ†æå¤±è´¥: {e}", exc_info=True)
            return Command(
                update={
                    "messages": [AIMessage(content=f"éœ€æ±‚åˆ†æå¤±è´¥: {str(e)}")],
                    "current_agent": "analyst_agent",
                    "error": str(e),
                }
            )

    def _parse_response(self, content: str) -> dict:
        """è§£æ LLM å“åº”"""
        import re

        json_match = re.search(r'```json\s*([\s\S]*?)\s*```', content)
        if json_match:
            return json.loads(json_match.group(1))

        json_match = re.search(r'\{[\s\S]*\}', content)
        if json_match:
            return json.loads(json_match.group())

        raise ValueError("æ— æ³•è§£æ LLM å“åº”ä¸º JSON")

    def _build_analysis_result(self, result_dict: dict, user_query: str) -> AnalysisResult:
        """æ„å»º AnalysisResult"""
        steps = []
        for step_dict in result_dict.get("steps", []):
            stages = []
            for stage_dict in step_dict.get("stages", []):
                stage = Stage(
                    stage_id=stage_dict.get("stage_id", 1),
                    name=stage_dict.get("name", ""),
                    description=stage_dict.get("description", ""),
                    input_tables=stage_dict.get("input_tables", []),
                    output_table=stage_dict.get("output_table", ""),
                    is_temp_table=stage_dict.get("is_temp_table", True),
                )
                stages.append(stage)

            step = Step(
                step_id=step_dict.get("step_id", ""),
                step_name=step_dict.get("step_name", ""),
                description=step_dict.get("description"),
                stages=stages,
                depends_on=step_dict.get("depends_on", []),
                output_table=step_dict.get("output_table"),
                suggested_component=step_dict.get("suggested_component", "hive"),
            )
            steps.append(step)

        return AnalysisResult(
            user_query=user_query,
            summary=result_dict.get("summary", ""),
            steps=steps,
            final_target=result_dict.get("final_target"),
            ambiguities=result_dict.get("ambiguities", []),
            confidence=result_dict.get("confidence", 0.5),
        )

    def _format_context(self, context: Optional[dict]) -> dict:
        """æ ¼å¼åŒ–ä¸Šä¸‹æ–‡ä¿¡æ¯"""
        if not context:
            return {"tables": "ï¼ˆæ— ï¼‰", "joins": "ï¼ˆæ— ï¼‰"}

        # æ ¼å¼åŒ–è¡¨ä¿¡æ¯
        tables_lines = []
        tables_dict = context.get("tables", {})
        for name, table in tables_dict.items():
            layer = table.get("layer", "")
            key_columns = table.get("key_columns", [])
            col_names = [c.get("name", "") for c in key_columns[:10]]
            tables_lines.append(f"- {name} ({layer}): {', '.join(col_names)}")

        # æ ¼å¼åŒ– JOIN ä¿¡æ¯
        joins_lines = []
        for join in context.get("join_hints", []):
            joins_lines.append(
                f"- {join.get('left_table')}.{join.get('left_column')} = "
                f"{join.get('right_table')}.{join.get('right_column')}"
            )

        return {
            "tables": "\n".join(tables_lines) if tables_lines else "ï¼ˆæ— ï¼‰",
            "joins": "\n".join(joins_lines) if joins_lines else "ï¼ˆæ— ï¼‰",
        }

    def _validate_and_enrich(
        self,
        result: AnalysisResult,
        context: Optional[dict]
    ) -> AnalysisResult:
        """éªŒè¯åˆ†æç»“æœ"""
        if not context:
            return result

        tables_dict = context.get("tables", {})
        table_names = set(tables_dict.keys())

        # éªŒè¯ Step ä¾èµ–æ˜¯å¦æœ‰æ•ˆ
        step_ids = {s.step_id for s in result.steps}
        for step in result.steps:
            for dep_id in step.depends:
                if dep_id not in step_ids:
                    result.ambiguities.append({
                        "question": f"Step '{step.step_id}' ä¾èµ–çš„ '{dep_id}' ä¸å­˜åœ¨",
                        "context": "ä¾èµ–å…³ç³»é…ç½®é”™è¯¯",
                        "options": list(step_ids),
                    })

        # éªŒè¯è¾“å…¥è¡¨æ˜¯å¦å­˜åœ¨ï¼ˆè·³è¿‡ä¸´æ—¶è¡¨ï¼‰
        for step in result.steps:
            for stage in step.stages:
                for input_table in stage.input_tables:
                    if input_table.startswith("tmp."):
                        continue
                    if input_table not in table_names:
                        result.ambiguities.append({
                            "question": f"è¡¨ '{input_table}' ä¸å­˜åœ¨ï¼Œè¯·ç¡®è®¤è¡¨åæ˜¯å¦æ­£ç¡®",
                            "context": f"Stage '{stage.name}' å¼•ç”¨äº†ä¸å­˜åœ¨çš„è¡¨",
                            "options": list(table_names),
                        })

        return result
