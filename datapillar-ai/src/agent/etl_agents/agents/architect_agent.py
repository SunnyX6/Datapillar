"""
Architect Agentï¼ˆæ•°æ®æ¶æ„å¸ˆï¼‰

èŒè´£ï¼šå°† AnalystAgent çš„ Step æ˜ å°„ä¸º Job
- ä¸€ä¸ª Step â†’ ä¸€ä¸ª Job â†’ ä¸€ä¸ªå‰ç«¯èŠ‚ç‚¹
"""

import json
import logging
from typing import List, Dict, Any

from langchain_core.messages import AIMessage
from langgraph.types import Command

from src.agent.etl_agents.schemas.state import AgentState
from src.agent.etl_agents.schemas.plan import Workflow, Job
from src.agent.etl_agents.schemas.requirement import AnalysisResult, Step
from src.agent.etl_agents.schemas.kg_context import KnowledgeContext

logger = logging.getLogger(__name__)


class ArchitectAgent:
    """
    æ•°æ®æ¶æ„å¸ˆ

    èŒè´£ï¼š
    1. å°† AnalysisResult ä¸­çš„ Step æ˜ å°„ä¸º Job
    2. éªŒè¯ç»„ä»¶æ˜¯å¦å­˜åœ¨ï¼ˆä» KnowledgeContext è·å–ï¼‰
    3. æ„å»º Workflow
    """

    async def __call__(self, state: AgentState) -> Command:
        """æ‰§è¡Œæ¶æ„è®¾è®¡"""
        analysis_result = state.analysis_result
        knowledge_context = state.knowledge_context

        if not analysis_result:
            return Command(
                update={
                    "messages": [AIMessage(content="ç¼ºå°‘éœ€æ±‚åˆ†æç»“æœï¼Œæ— æ³•è®¾è®¡æ¶æ„")],
                    "current_agent": "architect_agent",
                    "error": "ç¼ºå°‘éœ€æ±‚åˆ†æç»“æœ",
                }
            )

        logger.info("ğŸ—ï¸ ArchitectAgent å¼€å§‹è®¾è®¡æ¶æ„")

        # ä» knowledge_context è·å–å¯ç”¨ç»„ä»¶
        valid_component_ids = set()
        if knowledge_context:
            if isinstance(knowledge_context, dict):
                context = KnowledgeContext(**knowledge_context)
            else:
                context = knowledge_context
            valid_component_ids = set(context.get_component_ids())

        if not valid_component_ids:
            return Command(
                update={
                    "messages": [AIMessage(content="æœªæ‰¾åˆ°å¯ç”¨ç»„ä»¶ï¼ŒKnowledgeAgent å¯èƒ½æœªè°ƒç”¨ list_component")],
                    "current_agent": "architect_agent",
                    "error": "æœªæ‰¾åˆ°å¯ç”¨ç»„ä»¶",
                }
            )

        logger.info(f"ğŸ“¦ å¯ç”¨ç»„ä»¶: {valid_component_ids}")

        try:
            if isinstance(analysis_result, dict):
                analysis = AnalysisResult(**analysis_result)
            else:
                analysis = analysis_result

            workflow_plan = self._build_workflow_plan(analysis, valid_component_ids)

            dag_errors = workflow_plan.validate_dag()
            if dag_errors:
                workflow_plan.risks.extend(dag_errors)

            logger.info(
                f"âœ… ArchitectAgent å®Œæˆè®¾è®¡: {workflow_plan.name}, "
                f"èŠ‚ç‚¹æ•°={len(workflow_plan.jobs)}"
            )

            return Command(
                update={
                    "messages": [AIMessage(content=f"æ¶æ„è®¾è®¡å®Œæˆ: {workflow_plan.name}")],
                    "architecture_plan": workflow_plan.model_dump(),
                    "current_agent": "architect_agent",
                }
            )

        except Exception as e:
            logger.error(f"ArchitectAgent è®¾è®¡å¤±è´¥: {e}", exc_info=True)
            return Command(
                update={
                    "messages": [AIMessage(content=f"æ¶æ„è®¾è®¡å¤±è´¥: {str(e)}")],
                    "current_agent": "architect_agent",
                    "error": str(e),
                }
            )

    def _build_workflow_plan(
        self,
        analysis: AnalysisResult,
        valid_component_ids: set
    ) -> Workflow:
        """å°† AnalysisResult è½¬æ¢ä¸º Workflow"""
        nodes: List[Job] = []

        # Step ID â†’ Job ID æ˜ å°„
        step_to_node_id: Dict[str, str] = {}

        for step in analysis.steps:
            node_id = f"node_{step.step_id}"
            step_to_node_id[step.step_id] = node_id

            # éªŒè¯ç»„ä»¶
            component_id = step.suggested_component
            if component_id not in valid_component_ids:
                logger.warning(f"ç»„ä»¶ {component_id} ä¸å­˜åœ¨ï¼Œé™çº§ä¸º hive")
                component_id = "hive" if "hive" in valid_component_ids else list(valid_component_ids)[0]

            # è·å– Step çš„å¤–éƒ¨è¾“å…¥è¡¨
            input_tables = step.get_all_input_tables()

            # è·å–ä¾èµ–çš„ä¸Šæ¸¸èŠ‚ç‚¹
            depends_on = [step_to_node_id[dep_id] for dep_id in step.depends if dep_id in step_to_node_id]

            # æ„å»º Job
            node = Job(
                id=node_id,
                name=step.step_name,
                description=step.description,
                component_id=component_id,
                depends_on=depends_on,
                input_tables=input_tables,
                output_table=step.output_table,
                config={
                    "stages": [stage.model_dump() for stage in step.get_ordered_stages()]
                },
                config_generated=False,
                config_validated=False,
            )
            nodes.append(node)

        # ç¡®å®šæ•°æ®åˆ†å±‚
        layers = set()
        for step in analysis.steps:
            for stage in step.stages:
                output = stage.output_table
                if output.startswith("ods."):
                    layers.add("ODS")
                elif output.startswith("dwd."):
                    layers.add("DWD")
                elif output.startswith("dws."):
                    layers.add("DWS")
                elif output.startswith("ads."):
                    layers.add("ADS")

        return Workflow(
            name=analysis.summary[:50] if analysis.summary else "etl_workflow",
            description=analysis.summary,
            schedule=None,
            env="dev",
            nodes=nodes,
            layers=list(layers),
            risks=[],
            decision_points=[],
            confidence=analysis.confidence,
        )
