"""
Tester Agentï¼ˆæµ‹è¯•éªŒè¯ï¼‰

å°†ç”Ÿæˆçš„æ•´ä¸ªå·¥ä½œæµå’Œç”¨æˆ·éœ€æ±‚ä¸€èµ·äº¤ç»™ LLM reviewã€‚
éªŒè¯æ™ºèƒ½ä½“äº§å‡ºæ˜¯å¦ç¬¦åˆç”¨æˆ·éœ€æ±‚ã€‚

èŒè´£ï¼š
1. æ•´ä½“ review - å·¥ä½œæµæ˜¯å¦å®Œæ•´å®ç°ç”¨æˆ·éœ€æ±‚
2. é€»è¾‘æ­£ç¡®æ€§ - SQL ä¸šåŠ¡é€»è¾‘æ˜¯å¦æ­£ç¡®
3. æ€§èƒ½é£é™©æç¤º - æ½œåœ¨çš„æ€§èƒ½é—®é¢˜
"""

import json
import logging
import re

from langchain_core.messages import AIMessage, HumanMessage
from langgraph.types import Command

from src.infrastructure.llm.client import call_llm
from src.modules.etl.schemas.plan import TestResult, Workflow
from src.modules.etl.schemas.requirement import AnalysisResult
from src.modules.etl.schemas.state import AgentState

logger = logging.getLogger(__name__)


WORKFLOW_REVIEW_PROMPT = """ä½ æ˜¯èµ„æ·±æ•°æ®æ¶æ„å¸ˆå’Œæµ‹è¯•ä¸“å®¶ï¼Œè´Ÿè´£ review ç”Ÿæˆçš„ ETL å·¥ä½œæµæ˜¯å¦æ»¡è¶³ç”¨æˆ·éœ€æ±‚ã€‚

## ç”¨æˆ·åŸå§‹éœ€æ±‚
{user_input}

## éœ€æ±‚åˆ†æç»“æœ
{analysis_summary}

## ç”Ÿæˆçš„å·¥ä½œæµ

### å·¥ä½œæµåç§°
{workflow_name}

### å·¥ä½œæµæè¿°
{workflow_description}

### Jobs å’Œ SQL
{jobs_detail}

## Review ä»»åŠ¡

è¯·ä»ä»¥ä¸‹ç»´åº¦è¿›è¡Œ reviewï¼š

1. **éœ€æ±‚å®Œæ•´æ€§** - å·¥ä½œæµæ˜¯å¦å®Œæ•´å®ç°äº†ç”¨æˆ·çš„æ‰€æœ‰éœ€æ±‚
2. **æ•°æ®æµå‘æ­£ç¡®æ€§** - æºè¡¨ã€ç›®æ ‡è¡¨æ˜¯å¦æ­£ç¡®ï¼Œæ•°æ®æµå‘æ˜¯å¦åˆç†
3. **ä¸šåŠ¡é€»è¾‘æ­£ç¡®æ€§** - SQL çš„èšåˆã€è¿‡æ»¤ã€JOINã€è½¬æ¢é€»è¾‘æ˜¯å¦æ­£ç¡®
4. **å­—æ®µæ˜ å°„æ­£ç¡®æ€§** - è¾“å‡ºå­—æ®µæ˜¯å¦ç¬¦åˆç›®æ ‡è¡¨ç»“æ„å’Œä¸šåŠ¡å«ä¹‰
5. **æ€§èƒ½é£é™©** - æ˜¯å¦æœ‰å…¨è¡¨æ‰«æã€ç¬›å¡å°”ç§¯ã€å¤§å°è¡¨ JOIN é¡ºåºä¸å½“ç­‰é—®é¢˜

## è¾“å‡ºæ ¼å¼

```json
{{
  "passed": trueæˆ–false,
  "score": 0-100çš„è¯„åˆ†,
  "summary": "æ•´ä½“è¯„ä»·ï¼ˆ1-2å¥è¯ï¼‰",
  "issues": ["ä¸¥é‡é—®é¢˜1", "ä¸¥é‡é—®é¢˜2"],
  "warnings": ["è­¦å‘Š/å»ºè®®1", "è­¦å‘Š/å»ºè®®2"]
}}
```

è¯„åˆ†æ ‡å‡†ï¼š
- 90-100: å®Œå…¨æ»¡è¶³éœ€æ±‚ï¼Œæ— é—®é¢˜
- 70-89: åŸºæœ¬æ»¡è¶³éœ€æ±‚ï¼Œæœ‰å°é—®é¢˜æˆ–å»ºè®®
- 50-69: éƒ¨åˆ†æ»¡è¶³éœ€æ±‚ï¼Œæœ‰æ˜æ˜¾é—®é¢˜
- 0-49: ä¸æ»¡è¶³éœ€æ±‚ï¼Œéœ€è¦é‡æ–°ç”Ÿæˆ

åªè¾“å‡º JSONï¼Œä¸è¦è§£é‡Šã€‚
"""


class TesterAgent:
    """
    æµ‹è¯•éªŒè¯

    å°†æ•´ä¸ªå·¥ä½œæµå’Œç”¨æˆ·éœ€æ±‚ä¸€èµ·äº¤ç»™ LLM reviewã€‚
    """

    def __init__(self):
        self.llm = call_llm(temperature=0.0)

    async def __call__(self, state: AgentState) -> Command:
        """æ‰§è¡Œæµ‹è¯•éªŒè¯"""
        architecture_plan = state.architecture_plan
        analysis_result = state.analysis_result

        if not architecture_plan:
            return Command(
                update={
                    "messages": [AIMessage(content="ç¼ºå°‘æ¶æ„æ–¹æ¡ˆï¼Œæ— æ³•æµ‹è¯•")],
                    "current_agent": "tester_agent",
                    "error": "ç¼ºå°‘æ¶æ„æ–¹æ¡ˆ",
                }
            )

        logger.info("ğŸ§ª TesterAgent å¼€å§‹ review å·¥ä½œæµ")

        try:
            # è½¬æ¢ä¸ºå¯¹è±¡
            if isinstance(architecture_plan, dict):
                plan = Workflow(**architecture_plan)
            else:
                plan = architecture_plan

            if isinstance(analysis_result, dict):
                analysis = AnalysisResult(**analysis_result)
            else:
                analysis = analysis_result

            # æ„å»º Jobs è¯¦æƒ…
            jobs_detail = self._build_jobs_detail(plan)

            # è°ƒç”¨ LLM review
            review_result = await self._review_workflow(
                user_input=state.user_input,
                analysis=analysis,
                plan=plan,
                jobs_detail=jobs_detail,
            )

            # æ„å»ºæµ‹è¯•ç»“æœ
            passed = review_result.get("passed", True)
            score = review_result.get("score", 100)

            test_result = TestResult(
                passed=passed,
                total_tests=1,
                passed_tests=1 if passed else 0,
                failed_tests=0 if passed else 1,
                test_cases=[],
                validation_errors=review_result.get("issues", []),
                validation_warnings=review_result.get("warnings", []),
                coverage_summary={
                    "score": score,
                    "summary": review_result.get("summary", ""),
                },
                notes=review_result.get("summary"),
            )

            if not passed:
                logger.warning(f"âš ï¸ å·¥ä½œæµ review æœªé€šè¿‡: {review_result.get('summary')}")
            else:
                logger.info(f"âœ… TesterAgent review é€šè¿‡ï¼Œè¯„åˆ†: {score}")

            return Command(
                update={
                    "messages": [AIMessage(content=f"Review å®Œæˆï¼Œè¯„åˆ†: {score}")],
                    "test_result": test_result.model_dump(),
                    "current_agent": "tester_agent",
                    "iteration_count": state.iteration_count if passed else state.iteration_count + 1,
                }
            )

        except Exception as e:
            logger.error(f"TesterAgent review å¤±è´¥: {e}", exc_info=True)
            return Command(
                update={
                    "messages": [AIMessage(content=f"Review å¤±è´¥: {str(e)}")],
                    "current_agent": "tester_agent",
                    "error": str(e),
                }
            )

    def _build_jobs_detail(self, plan: Workflow) -> str:
        """æ„å»º Jobs è¯¦æƒ…æ–‡æœ¬"""
        lines = []

        for i, job in enumerate(plan.jobs, 1):
            lines.append(f"#### Job {i}: {job.name}")
            lines.append(f"- æè¿°: {job.description}")
            lines.append(f"- ç±»å‹: {job.type}")
            lines.append(f"- è¾“å…¥è¡¨: {', '.join(job.input_tables) if job.input_tables else 'æ— '}")
            lines.append(f"- è¾“å‡ºè¡¨: {job.output_table or 'æ— '}")

            # SQL
            sql = job.config.get("content") if job.config else None
            if sql:
                lines.append(f"- SQL:")
                lines.append("```sql")
                lines.append(sql)
                lines.append("```")
            else:
                lines.append("- SQL: æœªç”Ÿæˆ")

            lines.append("")

        return "\n".join(lines)

    async def _review_workflow(
        self,
        user_input: str,
        analysis: AnalysisResult | None,
        plan: Workflow,
        jobs_detail: str,
    ) -> dict:
        """ä½¿ç”¨ LLM review æ•´ä¸ªå·¥ä½œæµ"""
        try:
            prompt = WORKFLOW_REVIEW_PROMPT.format(
                user_input=user_input,
                analysis_summary=analysis.summary if analysis else "æ— ",
                workflow_name=plan.name,
                workflow_description=plan.description or "æ— ",
                jobs_detail=jobs_detail,
            )

            response = await self.llm.ainvoke([HumanMessage(content=prompt)])

            # è§£æå“åº”
            content = response.content.strip()
            json_match = re.search(r'\{[\s\S]*\}', content)
            if json_match:
                result = json.loads(json_match.group())
                return {
                    "passed": result.get("passed", True),
                    "score": result.get("score", 100),
                    "summary": result.get("summary", ""),
                    "issues": result.get("issues", []),
                    "warnings": result.get("warnings", []),
                }

        except Exception as e:
            logger.warning(f"å·¥ä½œæµ review è§£æå¤±è´¥: {e}")

        # é»˜è®¤é€šè¿‡
        return {
            "passed": True,
            "score": 80,
            "summary": "Review å®Œæˆ",
            "issues": [],
            "warnings": [],
        }
