"""
Tester Agentï¼ˆæµ‹è¯•éªŒè¯ï¼‰

éªŒè¯ç”Ÿæˆçš„ SQL ä»£ç çš„æ­£ç¡®æ€§ã€‚
"""

import json
import logging
from typing import Optional, List, Dict, Any

from langchain_core.messages import AIMessage, HumanMessage
from langgraph.types import Command

from src.modules.etl.schemas.state import AgentState
from src.modules.etl.schemas.plan import (
    Workflow,
    Job,
    TestResult,
    TestCase,
)
from src.modules.etl.sql_validator import SqlValidator, ValidationResult
from src.infrastructure.llm.client import call_llm

logger = logging.getLogger(__name__)

# æµ‹è¯•ç”¨ä¾‹ç”Ÿæˆæç¤ºè¯
TEST_CASE_GENERATION_PROMPT = """ä½ æ˜¯èµ„æ·±æ•°æ®æµ‹è¯•å·¥ç¨‹å¸ˆï¼Œè´Ÿè´£ä¸º ETL SQL ç”Ÿæˆæµ‹è¯•ç”¨ä¾‹ã€‚

## SQL ä»£ç 
{sql}

## èŠ‚ç‚¹ä¿¡æ¯
èŠ‚ç‚¹ID: {node_id}
èŠ‚ç‚¹ç±»å‹: {node_type}
æ“ä½œåŸè¯­: {node_op}

## è¡¨ç»“æ„
{table_schemas}

## æµ‹è¯•ç”¨ä¾‹è¦æ±‚
è¯·ä¸ºè¿™æ®µ SQL ç”Ÿæˆæµ‹è¯•ç”¨ä¾‹ï¼ŒåŒ…å«ï¼š

1. **æ­£å‘æµ‹è¯•**ï¼šéªŒè¯æ­£å¸¸æ•°æ®æµè½¬
   - è¾“å…¥æ•°æ®æ ·ä¾‹
   - é¢„æœŸè¾“å‡ºç»“æœ

2. **è¾¹ç•Œæµ‹è¯•**ï¼šéªŒè¯è¾¹ç•Œæ¡ä»¶
   - NULL å€¼å¤„ç†
   - ç©ºè¡¨å¤„ç†
   - æå€¼å¤„ç†

3. **å¼‚å¸¸æµ‹è¯•**ï¼šéªŒè¯å¼‚å¸¸æƒ…å†µ
   - æ•°æ®ç±»å‹ä¸åŒ¹é…
   - è¿åçº¦æŸæ¡ä»¶

## è¾“å‡ºæ ¼å¼
è¯·ä»¥ JSON æ ¼å¼è¾“å‡ºæµ‹è¯•ç”¨ä¾‹åˆ—è¡¨ï¼Œæ¯ä¸ªç”¨ä¾‹åŒ…å«ï¼š
- name: æµ‹è¯•ç”¨ä¾‹åç§°
- description: æµ‹è¯•æè¿°
- test_type: æµ‹è¯•ç±»å‹ï¼ˆpositive/boundary/negativeï¼‰
- input_data: è¾“å…¥æ•°æ®æè¿°
- expected_result: é¢„æœŸç»“æœæè¿°
- sql_assertion: SQL æ–­è¨€ï¼ˆå¯é€‰ï¼‰

åªè¾“å‡º JSONï¼Œä¸è¦è§£é‡Šã€‚
"""


class TesterAgent:
    """
    æµ‹è¯•éªŒè¯

    èŒè´£ï¼š
    1. éªŒè¯æ‰€æœ‰èŠ‚ç‚¹çš„ SQL è¯­æ³•å’Œè¯­ä¹‰
    2. ç”Ÿæˆæµ‹è¯•ç”¨ä¾‹
    3. æ‰§è¡Œé™æ€åˆ†æ
    4. æŠ¥å‘Šæµ‹è¯•ç»“æœ
    """

    def __init__(self):
        self.llm = call_llm(temperature=0.0, enable_json_mode=True)
        self.validator = SqlValidator()

    async def __call__(self, state: AgentState) -> Command:
        """æ‰§è¡Œæµ‹è¯•éªŒè¯"""
        architecture_plan = state.architecture_plan
        knowledge_context = state.knowledge_context

        if not architecture_plan:
            return Command(
                update={
                    "messages": [AIMessage(content="ç¼ºå°‘æ¶æ„æ–¹æ¡ˆï¼Œæ— æ³•æµ‹è¯•")],
                    "current_agent": "tester_agent",
                    "error": "ç¼ºå°‘æ¶æ„æ–¹æ¡ˆ",
                }
            )

        logger.info(f"ğŸ§ª TesterAgent å¼€å§‹æµ‹è¯•éªŒè¯")

        try:
            # å°† dict è½¬æ¢ä¸º Workflow
            if isinstance(architecture_plan, dict):
                plan = Workflow(**architecture_plan)
            else:
                plan = architecture_plan

            # æ‰§è¡Œæµ‹è¯•
            test_results = await self._run_tests(plan, knowledge_context)

            # ç»Ÿè®¡ç»“æœ
            passed_count = sum(1 for r in test_results if r.get("passed"))
            total_count = len(test_results)
            all_passed = passed_count == total_count

            # ç”Ÿæˆæµ‹è¯•ç”¨ä¾‹ï¼ˆä»…å¯¹æœ‰ SQL çš„èŠ‚ç‚¹ï¼‰
            test_cases = []
            for node in plan.jobs:
                sql = node.config.get("sql") if node.config else None
                if sql:
                    cases = await self._generate_test_cases(node, knowledge_context)
                    test_cases.extend(cases)

            # æ„å»ºæµ‹è¯•ç»“æœ
            test_result = TestResult(
                passed=all_passed,
                total_tests=total_count,
                passed_tests=passed_count,
                failed_tests=total_count - passed_count,
                test_cases=test_cases,
                validation_errors=self._extract_errors(test_results),
                coverage_summary={
                    "nodes_tested": total_count,
                    "nodes_passed": passed_count,
                    "coverage_rate": passed_count / total_count if total_count > 0 else 0,
                },
            )

            logger.info(
                f"âœ… TesterAgent å®Œæˆæµ‹è¯•: passed={all_passed}, "
                f"{passed_count}/{total_count} èŠ‚ç‚¹é€šè¿‡"
            )

            return Command(
                update={
                    "messages": [AIMessage(content=f"æµ‹è¯•å®Œæˆ: {passed_count}/{total_count} é€šè¿‡")],
                    "test_result": test_result.model_dump(),
                    "current_agent": "tester_agent",
                    "iteration_count": state.iteration_count if all_passed else state.iteration_count + 1,
                }
            )

        except Exception as e:
            logger.error(f"TesterAgent æµ‹è¯•å¤±è´¥: {e}", exc_info=True)
            return Command(
                update={
                    "messages": [AIMessage(content=f"æµ‹è¯•å¤±è´¥: {str(e)}")],
                    "current_agent": "tester_agent",
                    "error": str(e),
                }
            )

    async def _run_tests(
        self, plan: Workflow, context: Optional[dict]
    ) -> List[Dict[str, Any]]:
        """æ‰§è¡Œæ‰€æœ‰æµ‹è¯•"""
        results = []

        context_info = self._build_context_info(context)

        for node in plan.jobs:
            result = await self._test_node(node, context_info)
            results.append(result)

        return results

    async def _test_node(
        self, node: Job, context_info: dict
    ) -> Dict[str, Any]:
        """æµ‹è¯•å•ä¸ªèŠ‚ç‚¹"""
        result = {
            "node_id": node.id,
            "node_type": "transform",
            "passed": True,
            "errors": [],
            "warnings": [],
        }

        # è·å– SQL
        sql = node.config.get("sql") if node.config else None

        # 1. æ£€æŸ¥ SQL æ˜¯å¦å­˜åœ¨
        if not sql:
            result["warnings"].append("èŠ‚ç‚¹æ²¡æœ‰ç”Ÿæˆ SQL")
            return result

        # 2. è¯­æ³•éªŒè¯
        validation = await self.validator.validate(sql, context_info)

        if not validation.is_valid:
            result["passed"] = False
            result["errors"].extend(validation.errors)

        result["warnings"].extend(validation.warnings)

        # 3. é¢å¤–çš„é™æ€åˆ†æ
        static_issues = self._static_analysis(sql, node, context_info)
        if static_issues:
            result["warnings"].extend(static_issues)

        return result

    def _static_analysis(
        self, sql: str, node: Job, context_info: dict
    ) -> List[str]:
        """é™æ€åˆ†æ SQL"""
        issues = []
        sql_upper = sql.upper()

        # 1. SELECT * æ£€æŸ¥
        if "SELECT *" in sql_upper or "SELECT  *" in sql_upper:
            issues.append("ä½¿ç”¨äº† SELECT *ï¼Œå»ºè®®æ˜ç¡®åˆ—å‡ºå­—æ®µ")

        # 2. ç¬›å¡å°”ç§¯æ£€æŸ¥
        if "CROSS JOIN" in sql_upper:
            issues.append("ä½¿ç”¨äº† CROSS JOINï¼Œå¯èƒ½äº§ç”Ÿç¬›å¡å°”ç§¯")

        # 3. æ—  WHERE æ¡ä»¶çš„ DELETE/UPDATE
        if ("DELETE " in sql_upper or "UPDATE " in sql_upper) and "WHERE" not in sql_upper:
            issues.append("DELETE/UPDATE è¯­å¥æ²¡æœ‰ WHERE æ¡ä»¶ï¼Œå¯èƒ½å½±å“å…¨è¡¨")

        # 4. ç¡¬ç¼–ç å€¼æ£€æŸ¥
        if "= 'test'" in sql.lower() or "= \"test\"" in sql.lower():
            issues.append("SQL ä¸­å­˜åœ¨ç¡¬ç¼–ç æµ‹è¯•å€¼")

        # 5. åˆ†åŒºå­—æ®µæ£€æŸ¥
        tables = context_info.get("tables", {})
        for table_name, table in tables.items():
            partition_keys = table.get("partition_keys", [])
            if partition_keys:
                # æ£€æŸ¥æ˜¯å¦åœ¨ WHERE ä¸­ä½¿ç”¨äº†åˆ†åŒºå­—æ®µ
                if table_name.lower() in sql.lower():
                    has_partition_filter = any(
                        pk.lower() in sql.lower() for pk in partition_keys
                    )
                    if not has_partition_filter:
                        issues.append(f"è¡¨ {table_name} æœ‰åˆ†åŒºå­—æ®µ {partition_keys}ï¼Œä½†æœªåœ¨ WHERE ä¸­ä½¿ç”¨")

        # 6. å¤§è¡¨ JOIN æ£€æŸ¥ï¼ˆåŸºäºè¡¨åæ¨¡å¼ï¼‰
        large_table_patterns = ["fact_", "dwd_", "ods_"]
        for pattern in large_table_patterns:
            if pattern in sql.lower() and "JOIN" in sql_upper:
                issues.append(f"å¯èƒ½æ¶‰åŠå¤§è¡¨ JOINï¼ˆåŒ…å« {pattern} è¡¨ï¼‰ï¼Œè¯·ç¡®è®¤æ€§èƒ½")
                break

        return issues

    async def _generate_test_cases(
        self, node: Job, context: Optional[dict]
    ) -> List[TestCase]:
        """ä¸ºèŠ‚ç‚¹ç”Ÿæˆæµ‹è¯•ç”¨ä¾‹"""
        sql = node.config.get("sql") if node.config else None
        if not sql:
            return []

        try:
            context_info = self._build_context_info(context)

            prompt = TEST_CASE_GENERATION_PROMPT.format(
                sql=sql,
                node_id=node.id,
                node_type="transform",
                node_op=node.type,
                table_schemas=context_info.get("table_schemas", "ï¼ˆæ— ï¼‰"),
            )

            response = await self.llm.ainvoke([HumanMessage(content=prompt)])

            # è§£æå“åº”
            content = response.content
            # æ¸…ç† markdown ä»£ç å—
            content = content.strip()
            if content.startswith("```"):
                content = content.split("```")[1]
                if content.startswith("json"):
                    content = content[4:]
            content = content.strip()

            cases_data = json.loads(content)

            # è½¬æ¢ä¸º TestCase å¯¹è±¡
            test_cases = []
            for case in cases_data[:5]:  # æœ€å¤š5ä¸ªæµ‹è¯•ç”¨ä¾‹
                test_cases.append(TestCase(
                    name=case.get("name", "æœªå‘½åæµ‹è¯•"),
                    description=case.get("description", ""),
                    test_type=case.get("test_type", "positive"),
                    node_id=node.id,
                    input_data=case.get("input_data", ""),
                    expected_result=case.get("expected_result", ""),
                    sql_assertion=case.get("sql_assertion"),
                ))

            return test_cases

        except Exception as e:
            logger.warning(f"ç”Ÿæˆæµ‹è¯•ç”¨ä¾‹å¤±è´¥: {e}")
            # è¿”å›åŸºç¡€æµ‹è¯•ç”¨ä¾‹
            return [
                TestCase(
                    name=f"åŸºç¡€æµ‹è¯•_{node.id}",
                    description="éªŒè¯ SQL èƒ½å¤Ÿæ­£ç¡®æ‰§è¡Œ",
                    test_type="positive",
                    node_id=node.id,
                    input_data="ä½¿ç”¨æ ·ä¾‹æ•°æ®",
                    expected_result="SQL æ‰§è¡ŒæˆåŠŸï¼Œæ— é”™è¯¯",
                )
            ]

    def _build_context_info(self, context: Optional[dict]) -> dict:
        """æ„å»ºä¸Šä¸‹æ–‡ä¿¡æ¯"""
        if not context:
            return {
                "tables": {},
                "table_schemas": "ï¼ˆæ— ï¼‰",
            }

        tables = context.get("tables", {})

        # æ ¼å¼åŒ–è¡¨ç»“æ„
        schema_lines = []
        for name, table in tables.items():
            columns = table.get("columns", [])
            col_info = [
                f"{c.get('name')} ({c.get('data_type', 'string')})"
                for c in columns
            ]
            schema_lines.append(f"### {name}")
            schema_lines.append(f"åˆ—: {', '.join(col_info)}")
            if table.get("primary_keys"):
                schema_lines.append(f"ä¸»é”®: {', '.join(table['primary_keys'])}")
            if table.get("partition_keys"):
                schema_lines.append(f"åˆ†åŒº: {', '.join(table['partition_keys'])}")
            schema_lines.append("")

        return {
            "tables": tables,
            "table_schemas": "\n".join(schema_lines) if schema_lines else "ï¼ˆæ— ï¼‰",
        }

    def _extract_errors(self, test_results: List[Dict]) -> List[str]:
        """æå–æ‰€æœ‰é”™è¯¯"""
        errors = []
        for result in test_results:
            if not result.get("passed"):
                node_id = result.get("node_id", "unknown")
                for error in result.get("errors", []):
                    errors.append(f"[{node_id}] {error}")
        return errors
