"""
Reviewer Agentï¼ˆæ–¹æ¡ˆ/ä»£ç è¯„å®¡ï¼‰

èŒè´£ï¼šå¯¹å·¥ä½œæµåš LLM review
- è®¾è®¡é˜¶æ®µ reviewï¼šè¯„å®¡æ¶æ„å¸ˆäº§ç‰©ï¼ˆJob/Stage è®¾è®¡ï¼‰
- å¼€å‘é˜¶æ®µ reviewï¼šè¯„å®¡å¼€å‘äº§ç‰©ï¼ˆSQL ä»£ç ï¼‰
"""

import json
import logging
from typing import Literal

from langchain_core.messages import HumanMessage, SystemMessage
from pydantic import BaseModel, Field, field_validator

from src.infrastructure.llm.client import call_llm
from src.modules.etl.schemas.agent_result import AgentResult
from src.modules.etl.schemas.analyst import AnalysisResult
from src.modules.etl.schemas.review import ReviewResult
from src.modules.etl.schemas.workflow import Workflow

logger = logging.getLogger(__name__)


def _try_parse_json(value: object) -> object:
    """å°è¯•è§£æå­—ç¬¦ä¸²åŒ–çš„ JSON"""
    if not isinstance(value, str):
        return value
    text = value.strip()
    if not text:
        return None
    try:
        return json.loads(text)
    except json.JSONDecodeError:
        return value


class ReviewOutput(BaseModel):
    """Review è¾“å‡ºï¼ˆLLM ç”Ÿæˆï¼‰"""

    passed: bool = Field(..., description="æ˜¯å¦é€šè¿‡ reviewï¼Œæœ‰é˜»æ–­çº§é—®é¢˜æ—¶ä¸º False")
    score: int = Field(..., ge=0, le=100, description="è¯„åˆ† 0-100")
    summary: str = Field(..., description="æ•´ä½“è¯„ä»·ï¼Œ1-2 å¥è¯")
    issues: list[str] = Field(default_factory=list, description="é˜»æ–­çº§é—®é¢˜")
    warnings: list[str] = Field(default_factory=list, description="è­¦å‘Š/å»ºè®®")

    @field_validator("issues", "warnings", mode="before")
    @classmethod
    def _parse_list_fields(cls, v: object) -> object:
        """å®¹é”™ï¼šnull -> ç©ºåˆ—è¡¨ï¼Œå­—ç¬¦ä¸²åŒ– JSON -> è§£æ"""
        v = _try_parse_json(v)
        if v is None:
            return []
        if isinstance(v, str):
            items = [s.strip() for s in v.split(",")]
            return [s for s in items if s]
        return v


REVIEWER_SYSTEM_PROMPT = """ä½ æ˜¯ ETL æ–¹æ¡ˆ/ä»£ç è¯„å®¡ä¸“å®¶ã€‚

## ä½ çš„ä»»åŠ¡
ç”¨æˆ·ä¼šæä¾›ï¼š
1. åŸå§‹éœ€æ±‚
2. éœ€æ±‚åˆ†æç»“æœï¼ˆAnalysisResultï¼‰
3. å·¥ä½œæµæ–¹æ¡ˆï¼ˆWorkflowï¼‰

ä½ éœ€è¦ review è¿™ä¸ªæ–¹æ¡ˆæ˜¯å¦èƒ½æ­£ç¡®å®ç°ç”¨æˆ·éœ€æ±‚ã€‚

## Review ç»´åº¦
1. éœ€æ±‚è¦†ç›–ï¼šæ–¹æ¡ˆæ˜¯å¦è¦†ç›–äº†éœ€æ±‚åˆ†æä¸­çš„æ‰€æœ‰æ­¥éª¤å’Œç›®æ ‡
2. æ•°æ®æµå‘ï¼šè¯»å†™è¡¨æ˜¯å¦æ­£ç¡®ã€ä¾èµ–å…³ç³»æ˜¯å¦åˆç†
3. ä¸šåŠ¡é€»è¾‘ï¼šSQL çš„èšåˆ/è¿‡æ»¤/JOIN æ˜¯å¦æ­£ç¡®ï¼ˆå¦‚æœæœ‰ SQLï¼‰
4. æ€§èƒ½é£é™©ï¼šæ˜¯å¦å­˜åœ¨å…¨è¡¨æ‰«æã€ç¬›å¡å°”ç§¯ç­‰é—®é¢˜

## è¯„åˆ†æ ‡å‡†
- 90+ï¼šä¼˜ç§€ï¼Œæ— é˜»æ–­é—®é¢˜
- 70-89ï¼šè‰¯å¥½ï¼Œæœ‰å°é—®é¢˜
- 60-69ï¼šåŠæ ¼ï¼Œéœ€è¦ä¿®æ”¹
- <60ï¼šä¸åŠæ ¼ï¼Œå¿…é¡»é‡åš

## è¾“å‡ºæ ¼å¼ï¼ˆJSONï¼‰
è¯„å®¡å®Œæˆåï¼Œç›´æ¥è¾“å‡ºä»¥ä¸‹ JSON æ ¼å¼ï¼š
```json
{
  "passed": true,
  "score": 85,
  "summary": "æ–¹æ¡ˆæ•´ä½“åˆç†ï¼Œèƒ½æ­£ç¡®å®ç°éœ€æ±‚",
  "issues": [],
  "warnings": ["å»ºè®®å¢åŠ å¼‚å¸¸å¤„ç†"]
}
```

## å­—æ®µè¯´æ˜
- passed: æ˜¯å¦é€šè¿‡ reviewï¼ˆæœ‰é˜»æ–­çº§é—®é¢˜æ—¶ä¸º falseï¼‰
- score: è¯„åˆ† 0-100
- summary: æ•´ä½“è¯„ä»·ï¼Œ1-2 å¥è¯
- issues: é˜»æ–­çº§é—®é¢˜åˆ—è¡¨ï¼ˆæœ‰ issue æ—¶ passed å¿…é¡»ä¸º falseï¼‰
- warnings: å»ºè®®/é£é™©åˆ—è¡¨ï¼ˆä¸å½±å“ passedï¼‰
"""


class ReviewerAgent:
    """
    æ–¹æ¡ˆ/ä»£ç è¯„å®¡

    èŒè´£ï¼šreview å·¥ä½œæµæ˜¯å¦ç¬¦åˆéœ€æ±‚ï¼Œåªè¯„å®¡ä¸å†³ç­–ã€‚
    """

    def __init__(self):
        self.llm = call_llm(temperature=0.0)

    async def run(
        self,
        *,
        user_query: str,
        analysis_result: AnalysisResult,
        workflow: Workflow,
        review_stage: Literal["design", "development"],
    ) -> AgentResult:
        """
        æ‰§è¡Œ review

        å‚æ•°ï¼š
        - user_query: ç”¨æˆ·åŸå§‹éœ€æ±‚
        - analysis_result: éœ€æ±‚åˆ†æç»“æœ
        - workflow: å·¥ä½œæµæ–¹æ¡ˆ
        - review_stage: review é˜¶æ®µï¼ˆdesign/developmentï¼‰
        """
        logger.info(f"ğŸ“ ReviewerAgent å¼€å§‹ {review_stage} é˜¶æ®µ review")

        try:
            review = await self._do_review(
                user_query=user_query,
                analysis_result=analysis_result,
                workflow=workflow,
                review_stage=review_stage,
            )

            review_result = ReviewResult(
                passed=review.passed,
                score=review.score,
                summary=review.summary,
                issues=review.issues,
                warnings=review.warnings,
                review_stage=review_stage,
            )

            if review.passed:
                logger.info(f"âœ… {review_stage} review é€šè¿‡ï¼Œè¯„åˆ†: {review.score}")
            else:
                logger.warning(f"âš ï¸ {review_stage} review æœªé€šè¿‡ï¼Œè¯„åˆ†: {review.score}")

            return AgentResult.completed(
                summary=f"{review_stage} review {'é€šè¿‡' if review.passed else 'æœªé€šè¿‡'}ï¼Œè¯„åˆ†: {review.score}",
                deliverable=review_result,
                deliverable_type=f"review_{review_stage}",
            )

        except Exception as e:
            logger.error(f"ReviewerAgent æ‰§è¡Œå¤±è´¥: {e}", exc_info=True)
            return AgentResult.failed(
                summary=f"Review æ‰§è¡Œå¤±è´¥: {str(e)}",
                error=str(e),
            )

    async def _do_review(
        self,
        user_query: str,
        analysis_result: AnalysisResult,
        workflow: Workflow,
        review_stage: Literal["design", "development"],
    ) -> ReviewOutput:
        """
        è°ƒç”¨ LLM æ‰§è¡Œ reviewï¼šwith_structured_output(json_mode) + parse_structured_output å…œåº•
        """
        from src.infrastructure.llm.structured_output import parse_structured_output

        stage_hint = (
            "è®¾è®¡é˜¶æ®µï¼Œå…³æ³¨æ¶æ„è®¾è®¡æ˜¯å¦åˆç†"
            if review_stage == "design"
            else "å¼€å‘é˜¶æ®µï¼Œå…³æ³¨ SQL å®ç°æ˜¯å¦æ­£ç¡®"
        )

        human_content = f"""## ç”¨æˆ·éœ€æ±‚
{user_query}

## å½“å‰é˜¶æ®µ
{stage_hint}

## éœ€æ±‚åˆ†æç»“æœ
{analysis_result.model_dump_json(indent=2)}

## å·¥ä½œæµæ–¹æ¡ˆ
{workflow.model_dump_json(indent=2)}

è¯· review ä»¥ä¸Šæ–¹æ¡ˆæ˜¯å¦èƒ½æ­£ç¡®å®ç°ç”¨æˆ·éœ€æ±‚ã€‚"""

        messages = [
            SystemMessage(content=REVIEWER_SYSTEM_PROMPT),
            HumanMessage(content=human_content),
        ]

        # ä½¿ç”¨ json_modeï¼ˆreviewer æ²¡æœ‰å·¥å…·è°ƒç”¨ï¼Œä½†ä¿æŒä¸€è‡´ï¼‰
        llm_structured = self.llm.with_structured_output(
            ReviewOutput,
            method="json_mode",
            include_raw=True,
        )
        result = await llm_structured.ainvoke(messages)

        # æƒ…å†µ 1ï¼šç›´æ¥è§£ææˆåŠŸ
        if isinstance(result, ReviewOutput):
            return result

        # æƒ…å†µ 2ï¼šdict æ ¼å¼ï¼ˆinclude_raw=True çš„è¿”å›ï¼‰
        if isinstance(result, dict):
            parsed = result.get("parsed")
            if isinstance(parsed, ReviewOutput):
                return parsed

            # è§£æå¤±è´¥ï¼Œå°è¯•ä» raw ä¸­æ¢å¤
            parsing_error = result.get("parsing_error")
            raw = result.get("raw")

            if raw:
                raw_text = getattr(raw, "content", None)
                if raw_text:
                    logger.warning(
                        "with_structured_output è§£æå¤±è´¥ï¼Œå°è¯• parse_structured_output å…œåº•"
                    )
                    try:
                        return parse_structured_output(raw_text, ReviewOutput)
                    except ValueError as e:
                        logger.error(f"parse_structured_output å…œåº•ä¹Ÿå¤±è´¥: {e}")
                        raise

            if parsing_error:
                raise parsing_error

        raise ValueError(f"æ— æ³•è·å–ç»“æ„åŒ–è¾“å‡º: {type(result)}")
