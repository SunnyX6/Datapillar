"""
Architect Agentï¼ˆæ•°æ®æž¶æž„å¸ˆï¼‰

èŒè´£ï¼šæŠ€æœ¯å±‚é¢çš„è§„åˆ’
- æ ¹æ®éœ€æ±‚åˆ†æžç»“æžœï¼ˆAnalystAgent äº§ç‰©ï¼‰ï¼Œå†³å®šæŠ€æœ¯å®žçŽ°æ–¹æ¡ˆ
- é€‰æ‹©åˆé€‚çš„ç»„ä»¶ï¼ˆHIVE/SPARK_SQL/FLINK ç­‰ï¼‰
- å†³å®šéœ€è¦å‡ ä¸ª Jobï¼ˆå‰ç«¯èŠ‚ç‚¹ï¼‰
- è§„åˆ’æ¯ä¸ª Job çš„ Stageï¼ˆSQL æ‰§è¡Œå•å…ƒï¼‰
- é€šè¿‡å·¥å…·èŽ·å–è¡€ç¼˜å’Œç»„ä»¶ä¿¡æ¯
"""

import json
import logging

from langchain_core.messages import ToolMessage

from src.infrastructure.llm.client import call_llm
from src.modules.etl.agents.knowledge_agent import AgentType, get_agent_tools
from src.modules.etl.agents.prompt_messages import build_llm_messages
from src.modules.etl.schemas.agent_result import AgentResult
from src.modules.etl.schemas.plan import Job, Stage, Workflow
from src.modules.etl.schemas.requirement import AnalysisResult
from src.modules.etl.tools.agent_tools import get_table_lineage, list_component

logger = logging.getLogger(__name__)


def _tool_error(message: str, **extra: object) -> str:
    """æž„é€ å·¥å…·é”™è¯¯å“åº”"""
    payload: dict[str, object] = {"status": "error", "message": message}
    payload.update(extra)
    return json.dumps(payload, ensure_ascii=False)


ARCHITECT_AGENT_SYSTEM_INSTRUCTIONS = """ä½ æ˜¯èµ„æ·±æ•°æ®æž¶æž„å¸ˆã€‚

## ä»»åŠ¡
æ ¹æ®éœ€æ±‚åˆ†æžç»“æžœï¼Œè®¾è®¡æŠ€æœ¯å®žçŽ°æ–¹æ¡ˆï¼š
1. å†³å®šéœ€è¦å‡ ä¸ª Jobï¼ˆå‰ç«¯èŠ‚ç‚¹ï¼‰
2. è§„åˆ’æ¯ä¸ª Job çš„ Stageï¼ˆSQL æ‰§è¡Œå•å…ƒï¼‰
3. ç¡®å®š Job ä¹‹é—´çš„è°ƒåº¦ä¾èµ–

## ä»»åŠ¡å‚æ•°ï¼ˆç³»ç»Ÿæ³¨å…¥ï¼Œä¸æ˜¯ç”¨æˆ·è¾“å…¥ï¼‰
ç³»ç»Ÿä¼šæä¾›ä¸€æ®µ"ä»»åŠ¡å‚æ•° JSON"ï¼ˆSystemMessageï¼‰ï¼Œå…¶ä¸­åŒ…å«ï¼š
- analysis_resultï¼šéœ€æ±‚åˆ†æžç»“æžœï¼ˆAnalystAgent äº§ç‰©ï¼Œä¸¥æ ¼ JSONï¼‰
- selected_componentï¼šç”¨æˆ·é€‰æ‹©çš„ç»„ä»¶ï¼ˆæœ¬ Agent çš„äº¤äº’ç»“æžœï¼Œç”¨äºŽæœ¬æ¬¡æž¶æž„è§„åˆ’ï¼‰

## çŸ¥è¯†ä¸Šä¸‹æ–‡ï¼ˆç³»ç»Ÿæ³¨å…¥ï¼Œä¸æ˜¯ç”¨æˆ·è¾“å…¥ï¼‰
ç³»ç»Ÿä¼šæä¾›ä¸€æ®µ"çŸ¥è¯†ä¸Šä¸‹æ–‡ JSON"ï¼ˆSystemMessageï¼‰ï¼Œå…¶ä¸­åŒ…å«ï¼š
- tablesï¼šå¯ç”¨çš„ schema.table åˆ—è¡¨ï¼ˆå¯¼èˆªæŒ‡é’ˆï¼‰
- etl_pointersï¼šå¯éªŒè¯çš„ ETL æŒ‡é’ˆï¼ˆå« qualified_name/element_id/tools/labelsï¼‰
- allowlist_toolsï¼šä½ å…è®¸è°ƒç”¨çš„å·¥å…·ååˆ—è¡¨

ä½ å¿…é¡»æŠŠè¯¥ JSON è§†ä¸ºå”¯ä¸€å¯ä¿¡çŸ¥è¯†å…¥å£ï¼š
- ç¦æ­¢è‡†é€ ä»»ä½• schema.table
- å·¥å…·è°ƒç”¨åªèƒ½ä½¿ç”¨è¯¥ JSON ä¸­å‡ºçŽ°çš„è¡¨æŒ‡é’ˆï¼ˆæŒ‰ qualified_name ç²¾ç¡®åŒ¹é…ï¼‰
- ä»…å½“ ETLPointer.tools åŒ…å«å·¥å…·åæ—¶ï¼Œæ‰å…è®¸å¯¹è¯¥è¡¨è°ƒç”¨è¯¥å·¥å…·

## è®¾è®¡åŽŸåˆ™
1. **Job åˆ’åˆ†**ï¼š
   - ç®€å•éœ€æ±‚ç”¨ä¸€ä¸ª Job
   - æ¯ä¸ª Job å¯¹åº”å‰ç«¯ä¸€ä¸ªèŠ‚ç‚¹
   - æ‰€æœ‰ Job çš„ type éƒ½ä½¿ç”¨ selected_component

2. **Job ä¾èµ–**ï¼ˆè°ƒåº¦ä¾èµ–ï¼‰ï¼š
   - Job ä¹‹é—´æ˜¯è°ƒåº¦ä¾èµ–ï¼Œä¸æ˜¯æ•°æ®ä¾èµ–
   - å¦‚æžœ Job B è¯»çš„è¡¨æ˜¯ Job A å†™çš„ï¼Œåˆ™ Job B ä¾èµ– Job A
   - å‚è€ƒè¡¨çº§è¡€ç¼˜æŽ¨å¯¼ä¾èµ–å…³ç³»

3. **Stage è§„åˆ’**ï¼š
   - Stage æ˜¯ Job å†…éƒ¨çš„æ‰§è¡Œå•å…ƒ
   - ä¸´æ—¶è¡¨åªåœ¨ Job å†…éƒ¨ Stage ä¹‹é—´ä½¿ç”¨
   - è·¨ Job å¿…é¡»ç”¨æŒä¹…åŒ–è¡¨

## è¾“å‡ºæ ¼å¼
{{
  "name": "å·¥ä½œæµåç§°",
  "description": "å·¥ä½œæµæè¿°",
  "jobs": [
    {{
      "id": "job_1",
      "name": "Job åç§°",
      "description": "Job æè¿°",
      "type": "{selected_component}",
      "depends": ["ä¾èµ–çš„ Job IDï¼ˆè°ƒåº¦ä¾èµ–ï¼‰"],
      "step_ids": ["å…³è”çš„ä¸šåŠ¡æ­¥éª¤ ID"],
      "input_tables": ["è¯»å–çš„æŒä¹…åŒ–è¡¨"],
      "output_table": "å†™å…¥çš„æŒä¹…åŒ–è¡¨",
      "stages": [
        {{
          "stage_id": 1,
          "name": "Stage åç§°",
          "description": "è¿™ä¸ª Stage åšä»€ä¹ˆ",
          "input_tables": ["è¾“å…¥è¡¨"],
          "output_table": "è¾“å‡ºè¡¨æˆ–ä¸´æ—¶è¡¨",
          "is_temp_table": true
        }}
      ]
    }}
  ],
  "risks": ["æž¶æž„é£Žé™©ç‚¹"],
  "confidence": 0.85
}}

é‡è¦ï¼š
- **å¿…é¡»è¾“å‡ºçº¯ JSON**ï¼šä¸å¾—è¾“å‡º Markdownã€ä¸å¾—è¾“å‡º ```json ä»£ç å—ã€ä¸å¾—è¾“å‡ºè§£é‡Šæ€§æ–‡å­—

åªè¾“å‡º JSONï¼Œä¸è¦è§£é‡Šã€‚
"""


class ArchitectAgent:
    """
    æ•°æ®æž¶æž„å¸ˆ

    èŒè´£ï¼š
    1. è®©ç”¨æˆ·é€‰æ‹©ç»„ä»¶ï¼ˆæŠ€æœ¯æ ˆï¼‰
    2. é€šè¿‡å·¥å…·èŽ·å–è¡€ç¼˜ä¿¡æ¯
    3. å†³å®šéœ€è¦å‡ ä¸ª Job
    4. è§„åˆ’æ¯ä¸ª Job çš„ Stage
    5. è¯†åˆ«æž¶æž„é£Žé™©
    """

    def __init__(self):
        self.llm = call_llm(temperature=0.0)
        self.llm_json = call_llm(temperature=0.0, enable_json_mode=True)
        self.max_tool_calls = 4
        self.allowlist = get_agent_tools(AgentType.ARCHITECT)

    async def run(
        self,
        *,
        user_query: str,
        analysis_result: AnalysisResult,
        selected_component: str,
        selected_component_id: int | None = None,
        knowledge_agent=None,
    ) -> AgentResult:
        """
        æ‰§è¡Œæž¶æž„è®¾è®¡

        å‚æ•°ï¼š
        - user_query: ç”¨æˆ·è¾“å…¥
        - analysis_result: éœ€æ±‚åˆ†æžç»“æžœ
        - selected_component: ç”¨æˆ·é€‰æ‹©çš„ç»„ä»¶
        - selected_component_id: ç»„ä»¶ ID
        - knowledge_agent: KnowledgeAgent å®žä¾‹ï¼ˆç”¨äºŽæŒ‰éœ€æŸ¥è¯¢æŒ‡é’ˆï¼‰

        è¿”å›žï¼š
        - AgentResult: æ‰§è¡Œç»“æžœ
        """
        self._knowledge_agent = knowledge_agent

        logger.info(f"ðŸ—ï¸ ArchitectAgent å¼€å§‹è®¾è®¡æž¶æž„, ç»„ä»¶: {selected_component}")

        try:
            llm_with_tools = self._bind_tools()

            result_dict = await self._design_with_tools(
                analysis=analysis_result,
                selected_component=selected_component,
                llm_with_tools=llm_with_tools,
                user_query=user_query,
            )

            workflow_plan = self._build_workflow(
                result_dict, analysis_result, selected_component, selected_component_id
            )

            dag_errors = workflow_plan.validate_dag()
            if dag_errors:
                workflow_plan.risks.extend(dag_errors)

            dep_errors, dep_warnings = workflow_plan.validate_data_dependencies()
            if dep_errors:
                fixes = workflow_plan.fix_missing_dependencies()
                for fix in fixes:
                    logger.info(f"ðŸ”§ {fix}")
                    workflow_plan.risks.append(f"[å·²è‡ªåŠ¨ä¿®å¤] {fix}")

            temp_table_errors = workflow_plan.validate_temp_scope()
            if temp_table_errors:
                workflow_plan.risks.extend(temp_table_errors)

            logger.info(
                f"âœ… ArchitectAgent å®Œæˆè®¾è®¡: {workflow_plan.name}, "
                f"Job æ•°={len(workflow_plan.jobs)}, é£Žé™©={len(workflow_plan.risks)}"
            )

            return AgentResult.completed(
                summary=f"æž¶æž„è®¾è®¡å®Œæˆ: {workflow_plan.name}",
                deliverable=workflow_plan,
                deliverable_type="plan",
            )

        except Exception as e:
            logger.error(f"ArchitectAgent è®¾è®¡å¤±è´¥: {e}", exc_info=True)
            return AgentResult.failed(
                summary=f"æž¶æž„è®¾è®¡å¤±è´¥: {str(e)}",
                error=str(e),
            )

    async def get_components(self) -> list[dict]:
        """é€šè¿‡å·¥å…·èŽ·å–ç»„ä»¶åˆ—è¡¨"""
        if "list_component" not in self.allowlist:
            logger.error("å·¥å…·ä¸åœ¨ allowlist ä¸­: list_component")
            return []
        try:
            result = list_component.invoke({})
            data = json.loads(result)
            if data.get("status") == "success":
                return data.get("components", [])
            return []
        except Exception as e:
            logger.error(f"èŽ·å–ç»„ä»¶åˆ—è¡¨å¤±è´¥: {e}")
            return []

    async def _design_with_tools(
        self,
        analysis: AnalysisResult,
        selected_component: str,
        llm_with_tools,
        user_query: str,
    ) -> dict:
        """æ‰§è¡Œå¸¦å·¥å…·è°ƒç”¨çš„æž¶æž„è®¾è®¡"""
        task_payload = {
            "analysis_result": analysis.model_dump(),
            "selected_component": selected_component,
        }

        messages = build_llm_messages(
            system_instructions=ARCHITECT_AGENT_SYSTEM_INSTRUCTIONS,
            agent_id="architect_agent",
            user_query=user_query,
            task_payload=task_payload,
        )
        tool_call_count = 0

        while tool_call_count < self.max_tool_calls:
            response = await llm_with_tools.ainvoke(messages)
            messages.append(response)

            if not response.tool_calls:
                return self._parse_response(response.content)

            for tool_call in response.tool_calls:
                tool_call_count += 1
                tool_name = tool_call["name"]
                tool_args = tool_call["args"]
                tool_id = tool_call["id"]

                logger.info(f"ðŸ”§ ArchitectAgent è°ƒç”¨å·¥å…·: {tool_name}({tool_args})")

                tool_result = await self._execute_tool(tool_name, tool_args)

                messages.append(ToolMessage(content=tool_result, tool_call_id=tool_id))

                if tool_call_count >= self.max_tool_calls:
                    break

        response = await self.llm_json.ainvoke(messages)
        return self._parse_response(response.content)

    def _bind_tools(self):
        """ç»‘å®šå·¥å…·åˆ° LLM"""
        tool_registry = {
            "get_table_lineage": get_table_lineage,
            "list_component": list_component,
        }
        tools = [tool_registry[name] for name in self.allowlist if name in tool_registry]
        return self.llm.bind_tools(tools)

    async def _execute_tool(self, tool_name: str, tool_args: dict) -> str:
        """
        æ‰§è¡Œå·¥å…·è°ƒç”¨ï¼ˆæŒ‰éœ€èŽ·å–æŒ‡é’ˆ + æƒé™æ ¡éªŒï¼‰

        æµç¨‹ï¼š
        1. è°ƒç”¨ query_pointers èŽ·å–å¯¹åº”ç±»åž‹çš„æŒ‡é’ˆ
        2. æ£€æŸ¥æŒ‡é’ˆä¸Šçš„ tools æ˜¯å¦åŒ…å«è¦è°ƒç”¨çš„å·¥å…·
        3. ç”¨æŒ‡é’ˆçš„ä¿¡æ¯è°ƒç”¨å·¥å…·
        """
        try:
            if tool_name not in self.allowlist:
                return _tool_error(f"å·¥å…·ä¸åœ¨ allowlist ä¸­: {tool_name}")

            # list_component ä¸éœ€è¦æŒ‡é’ˆï¼Œç›´æŽ¥è°ƒç”¨
            if tool_name == "list_component":
                return list_component.invoke(tool_args)

            if not self._knowledge_agent:
                return _tool_error("æ— æ³•æŸ¥è¯¢æŒ‡é’ˆï¼šknowledge_agent æœªæ³¨å…¥")

            if tool_name == "get_table_lineage":
                table_name = (tool_args or {}).get("table_name") or ""
                direction = (tool_args or {}).get("direction") or "both"
                if not table_name:
                    return _tool_error("ç¼ºå°‘ table_name å‚æ•°")

                # æŒ‰éœ€æŸ¥è¯¢æŒ‡é’ˆ
                pointers = await self._knowledge_agent.query_pointers(
                    table_name,
                    node_types=["Table"],
                    top_k=5,
                )
                pointer = self._find_matching_pointer(pointers, table_name)
                if not pointer:
                    return _tool_error("æœªæ‰¾åˆ°æŒ‡é’ˆ", table_name=table_name)
                if "get_table_lineage" not in (pointer.tools or []):
                    return _tool_error("æŒ‡é’ˆæœªæŽˆæƒæ­¤å·¥å…·", table_name=table_name)

                logger.info(f"ðŸ“Š è°ƒç”¨ get_table_lineage: {pointer.qualified_name}")
                return await get_table_lineage.ainvoke(
                    {"table_name": pointer.qualified_name, "direction": direction}
                )

            return _tool_error(f"æœªçŸ¥å·¥å…·: {tool_name}")
        except Exception as e:
            logger.error(f"å·¥å…· {tool_name} æ‰§è¡Œå¤±è´¥: {e}")
            return _tool_error(str(e))

    def _find_matching_pointer(self, pointers: list, name: str):
        """ä»ŽæŒ‡é’ˆåˆ—è¡¨ä¸­æ‰¾åˆ°åŒ¹é…çš„æŒ‡é’ˆ"""
        if not pointers:
            return None
        # ç²¾ç¡®åŒ¹é…
        for p in pointers:
            if p.qualified_name == name:
                return p
        # éƒ¨åˆ†åŒ¹é…
        for p in pointers:
            if name in (p.qualified_name or ""):
                return p
        # è¿”å›žç¬¬ä¸€ä¸ª
        return pointers[0] if pointers else None

    def _parse_response(self, content: str) -> dict:
        """ä¸¥æ ¼è§£æž LLM å“åº”ï¼ˆå¿…é¡»æ˜¯çº¯ JSONï¼‰"""
        text = (content or "").strip()
        try:
            parsed = json.loads(text)
        except json.JSONDecodeError as e:
            raise ValueError("LLM è¾“å‡ºä¸æ˜¯åˆæ³• JSONï¼ˆå¿…é¡»è¾“å‡ºçº¯ JSONï¼‰") from e
        if not isinstance(parsed, dict):
            raise ValueError("LLM è¾“å‡ºå¿…é¡»æ˜¯ JSON object")
        return parsed

    def _build_workflow(
        self,
        result_dict: dict,
        analysis: AnalysisResult,
        selected_component: str,
        selected_component_id: int | None,
    ) -> Workflow:
        """æž„å»º Workflow å¯¹è±¡ï¼ˆå¼ºåˆ¶ä½¿ç”¨ç”¨æˆ·é€‰æ‹©çš„ç»„ä»¶ï¼‰"""
        jobs = []
        for job_dict in result_dict.get("jobs", []):
            stages = []
            for stage_dict in job_dict.get("stages", []):
                stage = Stage(
                    stage_id=stage_dict.get("stage_id", 1),
                    name=stage_dict.get("name", ""),
                    description=stage_dict.get("description", ""),
                    input_tables=stage_dict.get("input_tables", []),
                    output_table=stage_dict.get("output_table", ""),
                    is_temp_table=stage_dict.get("is_temp_table", True),
                    sql=None,
                )
                stages.append(stage)

            job = Job(
                id=job_dict.get("id", ""),
                name=job_dict.get("name", ""),
                description=job_dict.get("description"),
                type=selected_component,
                type_id=selected_component_id,
                depends=job_dict.get("depends", []),
                step_ids=job_dict.get("step_ids", []),
                stages=stages,
                input_tables=job_dict.get("input_tables", []),
                output_table=job_dict.get("output_table"),
                config_generated=False,
                config_validated=False,
            )
            jobs.append(job)

        return Workflow(
            id=None,
            name=result_dict.get(
                "name", analysis.summary[:50] if analysis.summary else "etl_workflow"
            ),
            description=result_dict.get("description", analysis.summary),
            schedule=None,
            env="dev",
            jobs=jobs,
            risks=result_dict.get("risks", []),
            decision_points=[],
            confidence=result_dict.get("confidence", analysis.confidence),
        )
