"""
Architect Agentï¼ˆæ•°æ®æ¶æ„å¸ˆï¼‰

èŒè´£ï¼šæŠ€æœ¯å±‚é¢çš„è§„åˆ’
- æ ¹æ®éœ€æ±‚åˆ†æç»“æœï¼ˆAnalystAgent äº§ç‰©ï¼‰ï¼Œå†³å®šæŠ€æœ¯å®ç°æ–¹æ¡ˆ
- é€‰æ‹©åˆé€‚çš„ç»„ä»¶ï¼ˆHIVE/SPARK_SQL/FLINK ç­‰ï¼‰
- å†³å®šéœ€è¦å‡ ä¸ª Jobï¼ˆå‰ç«¯èŠ‚ç‚¹ï¼‰
- è§„åˆ’æ¯ä¸ª Job çš„ Stageï¼ˆSQL æ‰§è¡Œå•å…ƒï¼‰
- é€šè¿‡å·¥å…·è·å–è¡€ç¼˜å’Œç»„ä»¶ä¿¡æ¯
"""

import asyncio
import json
import logging
from typing import Any

from langchain_core.messages import ToolMessage

from src.infrastructure.llm.client import call_llm
from src.infrastructure.resilience import get_resilience_config
from src.modules.etl.agents.knowledge_agent import AgentType, get_agent_tools
from src.modules.etl.agents.prompt_messages import build_llm_messages
from src.modules.etl.schemas.agent_result import AgentResult
from src.modules.etl.schemas.analyst import AnalysisResult
from src.modules.etl.schemas.workflow import Workflow, WorkflowOutput
from src.modules.etl.tools.component import list_component
from src.modules.etl.tools.table import get_table_lineage

logger = logging.getLogger(__name__)


def _tool_error(message: str, **extra: object) -> str:
    """æ„é€ å·¥å…·é”™è¯¯å“åº”"""
    payload: dict[str, object] = {"status": "error", "message": message}
    payload.update(extra)
    return json.dumps(payload, ensure_ascii=False)


ARCHITECT_AGENT_SYSTEM_INSTRUCTIONS = """ä½ æ˜¯èµ„æ·±æ•°æ®æ¶æ„å¸ˆã€‚

## ä»»åŠ¡
æ ¹æ®éœ€æ±‚åˆ†æç»“æœï¼Œè®¾è®¡æŠ€æœ¯å®ç°æ–¹æ¡ˆï¼š
1. å†³å®šéœ€è¦å‡ ä¸ª Jobï¼ˆå‰ç«¯èŠ‚ç‚¹ï¼‰
2. è§„åˆ’æ¯ä¸ª Job çš„ Stageï¼ˆSQL æ‰§è¡Œå•å…ƒï¼‰
3. ç¡®å®š Job ä¹‹é—´çš„è°ƒåº¦ä¾èµ–

## ä»»åŠ¡å‚æ•°ï¼ˆç³»ç»Ÿæ³¨å…¥ï¼‰
ç³»ç»Ÿä¼šæä¾› analysis_resultï¼ˆéœ€æ±‚åˆ†æç»“æœï¼‰å’Œ selected_componentï¼ˆç”¨æˆ·é€‰æ‹©çš„ç»„ä»¶ï¼‰ã€‚

## å¯ç”¨å·¥å…·

### get_table_lineage
æŸ¥è¯¢è¡¨çš„è¡€ç¼˜å…³ç³»ï¼ˆä¸Šä¸‹æ¸¸è¡¨ï¼‰ã€‚
- ç”¨äºæ¨å¯¼ Job ä¹‹é—´çš„ä¾èµ–å…³ç³»
- å¦‚æœ Job B è¯»çš„è¡¨æ˜¯ Job A å†™çš„ï¼Œåˆ™ Job B ä¾èµ– Job A

### list_component
è·å–å¯ç”¨ç»„ä»¶åˆ—è¡¨ï¼ˆå¯é€‰ï¼‰ã€‚

## è®¾è®¡åŸåˆ™

### Job åˆ’åˆ†
- ç®€å•éœ€æ±‚ç”¨ä¸€ä¸ª Job
- æ¯ä¸ª Job å¯¹åº”å‰ç«¯ä¸€ä¸ªèŠ‚ç‚¹
- æ‰€æœ‰ Job çš„ type éƒ½ä½¿ç”¨ selected_component

### Job ä¾èµ–ï¼ˆè°ƒåº¦ä¾èµ–ï¼‰
- Job ä¹‹é—´æ˜¯è°ƒåº¦ä¾èµ–ï¼Œä¸æ˜¯æ•°æ®ä¾èµ–
- å¦‚æœ Job B è¯»çš„è¡¨æ˜¯ Job A å†™çš„ï¼Œåˆ™ Job B ä¾èµ– Job A
- å‚è€ƒè¡¨çº§è¡€ç¼˜æ¨å¯¼ä¾èµ–å…³ç³»

### Stage è§„åˆ’
- Stage æ˜¯ Job å†…éƒ¨çš„æ‰§è¡Œå•å…ƒ
- ä¸´æ—¶è¡¨åªåœ¨ Job å†…éƒ¨ Stage ä¹‹é—´ä½¿ç”¨
- è·¨ Job å¿…é¡»ç”¨æŒä¹…åŒ–è¡¨

## è¾“å‡ºæ ¼å¼ï¼ˆJSONï¼‰
è®¾è®¡å®Œæˆåï¼Œç›´æ¥è¾“å‡ºä»¥ä¸‹ JSON æ ¼å¼ï¼š
```json
{
  "name": "å·¥ä½œæµåç§°",
  "description": "å·¥ä½œæµæè¿°",
  "jobs": [
    {
      "id": "job_1",
      "name": "ä½œä¸šåç§°",
      "description": "ä½œä¸šæè¿°",
      "depends": [],
      "step_ids": ["s1"],
      "stages": [
        {
          "stage_id": 1,
          "name": "Stageåç§°",
          "description": "Stageæè¿°",
          "input_tables": ["schema.table"],
          "output_table": "schema.output_table",
          "is_temp_table": false
        }
      ],
      "input_tables": ["schema.table"],
      "output_table": "schema.output_table"
    }
  ],
  "risks": ["é£é™©ç‚¹1", "é£é™©ç‚¹2"],
  "confidence": 0.8
}
```

## å­—æ®µè¯´æ˜
- name: å·¥ä½œæµåç§°
- description: å·¥ä½œæµæè¿°
- jobs: ä½œä¸šåˆ—è¡¨
  - id: Job å”¯ä¸€æ ‡è¯†ï¼ˆjob_1, job_2 æ ¼å¼ï¼‰
  - name: Job åç§°
  - depends: ä¾èµ–çš„ä¸Šæ¸¸ Job ID åˆ—è¡¨
  - step_ids: å…³è”çš„ä¸šåŠ¡æ­¥éª¤ ID
  - stages: Stage åˆ—è¡¨
    - stage_id: Stage åºå·ï¼ˆä» 1 å¼€å§‹ï¼‰
    - name: Stage åç§°
    - input_tables: è¯»å–çš„è¡¨
    - output_table: è¾“å‡ºçš„è¡¨
    - is_temp_table: æ˜¯å¦ä¸´æ—¶è¡¨
  - input_tables: Job è¯»å–çš„æŒä¹…åŒ–è¡¨
  - output_table: Job å†™å…¥çš„æœ€ç»ˆç›®æ ‡è¡¨
- risks: æ¶æ„é£é™©ç‚¹
- confidence: ç½®ä¿¡åº¦ï¼ˆå¤æ‚åœºæ™¯ < 0.8ï¼‰

## é‡è¦çº¦æŸ
1. ä¸å…è®¸è‡†é€ è¡¨åï¼Œå¿…é¡»ä½¿ç”¨å·¥å…·éªŒè¯æˆ–ä½¿ç”¨ analysis_result ä¸­çš„è¡¨å
2. è®¾è®¡å®Œæˆåç›´æ¥è¾“å‡º JSONï¼Œä¸è¦è°ƒç”¨ä»»ä½•å·¥å…·
"""


class ArchitectAgent:
    """
    æ•°æ®æ¶æ„å¸ˆ

    èŒè´£ï¼š
    1. è®©ç”¨æˆ·é€‰æ‹©ç»„ä»¶ï¼ˆæŠ€æœ¯æ ˆï¼‰
    2. é€šè¿‡å·¥å…·è·å–è¡€ç¼˜ä¿¡æ¯
    3. å†³å®šéœ€è¦å‡ ä¸ª Job
    4. è§„åˆ’æ¯ä¸ª Job çš„ Stage
    5. è¯†åˆ«æ¶æ„é£é™©
    """

    def __init__(self):
        self.llm = call_llm(temperature=0.0)
        config = get_resilience_config()
        self.max_iterations = config.max_iterations
        self.allowlist = get_agent_tools(AgentType.ARCHITECT)

    async def run(
        self,
        *,
        user_query: str,
        analysis_result: AnalysisResult,
        selected_component: str,
        selected_component_id: int | None = None,
        knowledge_agent=None,
        memory_context: dict[str, Any] | None = None,
    ) -> AgentResult:
        """
        æ‰§è¡Œæ¶æ„è®¾è®¡

        å‚æ•°ï¼š
        - user_query: ç”¨æˆ·è¾“å…¥
        - analysis_result: éœ€æ±‚åˆ†æç»“æœ
        - selected_component: ç”¨æˆ·é€‰æ‹©çš„ç»„ä»¶
        - selected_component_id: ç»„ä»¶ ID
        - knowledge_agent: KnowledgeAgent å®ä¾‹ï¼ˆç”¨äºæŒ‰éœ€æŸ¥è¯¢æŒ‡é’ˆï¼‰
        - memory_context: å¯¹è¯å†å²ä¸Šä¸‹æ–‡ï¼ˆæ”¯æŒå¤šè½®å¯¹è¯ï¼‰

        è¿”å›ï¼š
        - AgentResult: æ‰§è¡Œç»“æœ
        """
        self._knowledge_agent = knowledge_agent

        logger.info(f"ğŸ—ï¸ ArchitectAgent å¼€å§‹è®¾è®¡æ¶æ„, ç»„ä»¶: {selected_component}")

        try:
            llm_with_tools = self._bind_tools()

            output = await self._design_with_tools(
                analysis=analysis_result,
                selected_component=selected_component,
                llm_with_tools=llm_with_tools,
                user_query=user_query,
                memory_context=memory_context,
            )

            workflow_plan = Workflow.from_output(output, selected_component, selected_component_id)

            # completed æ ‡å‡†ï¼šå¿…é¡»ç”Ÿæˆå¯æ‰§è¡Œçš„ Job/Stage ç»“æ„
            if not workflow_plan.jobs:
                return AgentResult.failed(
                    summary="æ¶æ„è®¾è®¡å¤±è´¥ï¼šæœªç”Ÿæˆä»»ä½• Job",
                    error="Workflow.jobs ä¸ºç©º",
                )
            jobs_missing_stages = [job.id for job in workflow_plan.jobs if not job.stages]
            if jobs_missing_stages:
                return AgentResult.failed(
                    summary=f"æ¶æ„è®¾è®¡å¤±è´¥ï¼šå­˜åœ¨æ²¡æœ‰ Stage çš„ Job: {', '.join(jobs_missing_stages)}",
                    error=f"å­˜åœ¨æ²¡æœ‰ Stage çš„ Job: {', '.join(jobs_missing_stages)}",
                )

            dag_errors = workflow_plan.validate_dag()
            if dag_errors:
                workflow_plan.risks.extend(dag_errors)

            dep_errors, dep_warnings = workflow_plan.validate_data_dependencies()
            if dep_errors:
                fixes = workflow_plan.fix_missing_dependencies()
                for fix in fixes:
                    logger.info(f"ğŸ”§ {fix}")
                    workflow_plan.risks.append(f"[å·²è‡ªåŠ¨ä¿®å¤] {fix}")

            temp_table_errors = workflow_plan.validate_temp_scope()
            if temp_table_errors:
                workflow_plan.risks.extend(temp_table_errors)

            logger.info(
                f"âœ… ArchitectAgent å®Œæˆè®¾è®¡: {workflow_plan.name}, "
                f"Job æ•°={len(workflow_plan.jobs)}, é£é™©={len(workflow_plan.risks)}"
            )

            # æ£€æŸ¥ LLM è¿”å›çš„ confidence å’Œ risksï¼Œåˆ¤æ–­æ˜¯å¦éœ€è¦ç”¨æˆ·ç¡®è®¤
            # è¿‡æ»¤æ‰å·²è‡ªåŠ¨ä¿®å¤çš„é£é™©ï¼Œåªä¿ç•™éœ€è¦ç”¨æˆ·å…³æ³¨çš„é£é™©
            unresolved_risks = [r for r in workflow_plan.risks if not r.startswith("[å·²è‡ªåŠ¨ä¿®å¤]")]
            if workflow_plan.confidence < 0.8 and unresolved_risks:
                logger.info(
                    f"âš ï¸ ArchitectAgent éœ€è¦ç¡®è®¤: confidence={workflow_plan.confidence}, "
                    f"risks={unresolved_risks}"
                )
                return AgentResult.needs_clarification(
                    summary="æ¶æ„æ–¹æ¡ˆéœ€è¦ç¡®è®¤",
                    message="æ¶æ„è®¾è®¡å­˜åœ¨ä¸€äº›é£é™©ç‚¹ï¼Œéœ€è¦ä½ ç¡®è®¤åæ‰èƒ½ç»§ç»­",
                    questions=unresolved_risks,
                )

            return AgentResult.completed(
                summary=f"æ¶æ„è®¾è®¡å®Œæˆ: {workflow_plan.name}",
                deliverable=workflow_plan,
                deliverable_type="plan",
            )

        except Exception as e:
            logger.error(f"ArchitectAgent è®¾è®¡å¤±è´¥: {e}", exc_info=True)
            return AgentResult.failed(
                summary=f"æ¶æ„è®¾è®¡å¤±è´¥: {str(e)}",
                error=str(e),
            )

    async def get_components(self) -> list[dict]:
        """é€šè¿‡å·¥å…·è·å–ç»„ä»¶åˆ—è¡¨"""
        if "list_component" not in self.allowlist:
            logger.error("å·¥å…·ä¸åœ¨ allowlist ä¸­: list_component")
            return []
        try:
            result = list_component.invoke({})
            data = json.loads(result)
            if data.get("status") == "success":
                return data.get("components", [])
            return []
        except Exception as e:
            logger.error(f"è·å–ç»„ä»¶åˆ—è¡¨å¤±è´¥: {e}")
            return []

    async def _design_with_tools(
        self,
        analysis: AnalysisResult,
        selected_component: str,
        llm_with_tools,
        user_query: str,
        memory_context: dict[str, Any] | None = None,
    ) -> WorkflowOutput:
        """
        å¸¦å·¥å…·è°ƒç”¨çš„æ¶æ„è®¾è®¡æµç¨‹ï¼š
        1. é¢„å…ˆè°ƒç”¨ KnowledgeAgent è·å–å€™é€‰è¡¨/åˆ—/å€¼åŸŸï¼ˆå¸¦æƒé™è¿‡æ»¤ï¼‰
        2. ç¬¬ä¸€é˜¶æ®µï¼šLLM è°ƒç”¨å·¥å…·è·å–è¡€ç¼˜ä¿¡æ¯ï¼ˆbind_tools + ToolMessageï¼‰
        3. ç¬¬äºŒé˜¶æ®µï¼šLLM è¾“å‡ºç»“æ„åŒ–ç»“æœï¼ˆwith_structured_output + parse_structured_output å…œåº•ï¼‰
        """
        # é¢„å…ˆæ£€ç´¢çŸ¥è¯†ä¸Šä¸‹æ–‡ï¼ˆå¸¦æƒé™è¿‡æ»¤ï¼‰
        context_payload = None
        if self._knowledge_agent:
            ctx = await self._knowledge_agent.global_search(user_query, top_k=10, min_score=0.5)
            logger.info(f"ğŸ“š çŸ¥è¯†æ£€ç´¢å®Œæˆ: {ctx.summary()}")
            context_payload = ctx.to_llm_context(allowlist=self.allowlist)

        task_payload = {
            "analysis_result": analysis.model_dump(),
            "selected_component": selected_component,
        }

        messages = build_llm_messages(
            system_instructions=ARCHITECT_AGENT_SYSTEM_INSTRUCTIONS,
            agent_id="architect_agent",
            user_query=user_query,
            task_payload=task_payload,
            context_payload=context_payload,
            memory_context=memory_context,
        )

        # ç¬¬ä¸€é˜¶æ®µï¼šå·¥å…·è°ƒç”¨æ”¶é›†ä¿¡æ¯
        for _ in range(self.max_iterations):
            response = await llm_with_tools.ainvoke(messages)

            if not response.tool_calls:
                # æ²¡æœ‰å·¥å…·è°ƒç”¨ï¼Œè¿›å…¥ç¬¬äºŒé˜¶æ®µ
                break

            # æ‰§è¡Œå·¥å…·è°ƒç”¨ï¼Œç»“æœæ”¾å…¥ ToolMessage
            messages.append(response)
            for tc in response.tool_calls:
                logger.info(f"ğŸ”§ ArchitectAgent è°ƒç”¨å·¥å…·: {tc['name']}({tc['args']})")

            results = await asyncio.gather(
                *[self._execute_tool(tc["name"], tc["args"]) for tc in response.tool_calls]
            )

            for tc, result in zip(response.tool_calls, results, strict=True):
                messages.append(ToolMessage(content=result, tool_call_id=tc["id"]))

        # ç¬¬äºŒé˜¶æ®µï¼šç»“æ„åŒ–è¾“å‡ºï¼ˆwith_structured_output è®© LLM çŸ¥é“ schemaï¼‰
        return await self._get_structured_output(messages, WorkflowOutput)

    async def _get_structured_output(
        self,
        messages: list,
        schema: type[WorkflowOutput],
    ) -> WorkflowOutput:
        """
        è·å–ç»“æ„åŒ–è¾“å‡ºï¼šwith_structured_output(json_mode) + parse_structured_output å…œåº•
        """
        from src.infrastructure.llm.structured_output import parse_structured_output

        # ä½¿ç”¨ json_modeï¼ˆä¸æ˜¯ function_callingï¼Œé¿å…å’Œå·¥å…·è°ƒç”¨æ··æ·†ï¼‰
        llm_structured = self.llm.with_structured_output(
            schema,
            method="json_mode",
            include_raw=True,
        )
        result = await llm_structured.ainvoke(messages)

        # æƒ…å†µ 1ï¼šç›´æ¥è§£ææˆåŠŸ
        if isinstance(result, schema):
            return result

        # æƒ…å†µ 2ï¼šdict æ ¼å¼ï¼ˆinclude_raw=True çš„è¿”å›ï¼‰
        if isinstance(result, dict):
            parsed = result.get("parsed")
            if isinstance(parsed, schema):
                return parsed

            # è§£æå¤±è´¥ï¼Œå°è¯•ä» raw ä¸­æ¢å¤
            parsing_error = result.get("parsing_error")
            raw = result.get("raw")

            if raw:
                raw_text = getattr(raw, "content", None)
                if raw_text:
                    logger.warning(
                        "with_structured_output è§£æå¤±è´¥ï¼Œå°è¯• parse_structured_output å…œåº•"
                    )
                    try:
                        return parse_structured_output(raw_text, schema)
                    except ValueError as e:
                        logger.error(f"parse_structured_output å…œåº•ä¹Ÿå¤±è´¥: {e}")
                        raise

            if parsing_error:
                raise parsing_error

        raise ValueError(f"æ— æ³•è·å–ç»“æ„åŒ–è¾“å‡º: {type(result)}")

    def _bind_tools(self):
        """ç»‘å®šæŸ¥è¯¢å·¥å…·åˆ° LLM"""
        tool_registry = {
            "get_table_lineage": get_table_lineage,
            "list_component": list_component,
        }
        tools = [tool_registry[name] for name in self.allowlist if name in tool_registry]
        return self.llm.bind_tools(
            tools,
            tool_choice="auto",
        )

    async def _execute_tool(self, tool_name: str, tool_args: dict) -> str:
        """æ‰§è¡Œå·¥å…·è°ƒç”¨ï¼ˆé€šè¿‡ knowledge_agent è·å–ç²¾ç¡®è·¯å¾„ï¼‰"""
        try:
            if tool_name not in self.allowlist:
                return _tool_error(f"å·¥å…·ä¸åœ¨ allowlist ä¸­: {tool_name}")

            # list_component ä¸éœ€è¦æŒ‡é’ˆï¼Œç›´æ¥è°ƒç”¨
            if tool_name == "list_component":
                return list_component.invoke(tool_args)

            if tool_name == "get_table_lineage":
                # æ£€æŸ¥æ˜¯å¦å·²æä¾›ç²¾ç¡®å‚æ•°
                catalog = tool_args.get("catalog")
                schema_name = tool_args.get("schema_name") or tool_args.get("schema")
                table = tool_args.get("table")
                direction = tool_args.get("direction", "both")

                # å¦‚æœåªæä¾›äº† table_nameï¼Œé€šè¿‡ knowledge_agent æŸ¥æ‰¾ç²¾ç¡®è·¯å¾„
                if not (catalog and schema_name and table):
                    table_name = tool_args.get("table_name") or tool_args.get("table") or ""
                    if not table_name:
                        return _tool_error("ç¼ºå°‘ table å‚æ•°")

                    if not self._knowledge_agent:
                        return _tool_error("æ— æ³•æŸ¥è¯¢è¡¨ä½ç½®ï¼šknowledge_agent æœªæ³¨å…¥")

                    # ä½¿ç”¨ global_search æŸ¥æ‰¾è¡¨
                    ctx = await self._knowledge_agent.global_search(
                        table_name, top_k=5, min_score=0.6
                    )
                    if not ctx.tables:
                        return _tool_error("æœªæ‰¾åˆ°ç›¸å…³è¡¨", table_name=table_name)

                    # éå†æ‰€æœ‰åŒ¹é…çš„è¡¨
                    results = []
                    for pointer in ctx.tables:
                        if "get_table_lineage" not in pointer.tools:
                            continue
                        logger.info(
                            f"ğŸ“Š è°ƒç”¨ get_table_lineage: catalog={pointer.catalog}, "
                            f"schema_name={pointer.schema_name}, table={pointer.table}"
                        )
                        result = await get_table_lineage.ainvoke(
                            {
                                "catalog": pointer.catalog,
                                "schema_name": pointer.schema_name,
                                "table": pointer.table,
                                "direction": direction,
                            }
                        )
                        results.append(result)

                    if not results:
                        return _tool_error("æ— å¯ç”¨æŒ‡é’ˆæˆæƒæ­¤å·¥å…·", table_name=table_name)

                    return json.dumps({"status": "success", "results": results}, ensure_ascii=False)

                # å·²æä¾›ç²¾ç¡®å‚æ•°ï¼Œç›´æ¥è°ƒç”¨
                logger.info(
                    f"ğŸ“Š è°ƒç”¨ get_table_lineage: catalog={catalog}, schema_name={schema_name}, table={table}"
                )
                return await get_table_lineage.ainvoke(
                    {
                        "catalog": catalog,
                        "schema_name": schema_name,
                        "table": table,
                        "direction": direction,
                    }
                )

            return _tool_error(f"æœªçŸ¥å·¥å…·: {tool_name}")
        except Exception as e:
            logger.error(f"å·¥å…· {tool_name} æ‰§è¡Œå¤±è´¥: {e}")
            return _tool_error(str(e))
