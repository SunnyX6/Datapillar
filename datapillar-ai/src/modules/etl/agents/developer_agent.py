"""
Developer Agentï¼ˆæ•°æ®å¼€å‘ï¼‰

èŒè´£ï¼šä¸ºæ¯ä¸ª Job çš„ Stage ç”Ÿæˆ SQL
- æŒ‰ Job å¤„ç†ï¼Œæ¯ä¸ª Job åŒ…å«å¤šä¸ª Stage
- ä¸ºæ¯ä¸ª Stage ç”Ÿæˆ SQL
- å°†æ‰€æœ‰ Stage çš„ SQL ç»„åˆæˆå®Œæ•´è„šæœ¬
- é€šè¿‡å·¥å…·è·å–è¡¨ç»“æ„ã€åˆ—çº§è¡€ç¼˜ã€å†å² SQLï¼ˆç²¾å‡†åŒ¹é…ï¼‰
"""

import json
import logging
import re

from langchain_core.messages import ToolMessage

from src.infrastructure.llm.client import call_llm
from src.modules.etl.agents.knowledge_agent import AgentType, get_agent_tools
from src.modules.etl.agents.prompt_messages import build_llm_messages
from src.modules.etl.schemas.agent_result import AgentResult
from src.modules.etl.schemas.plan import Job, Stage, TestResult, Workflow
from src.modules.etl.tools.agent_tools import (
    get_column_valuedomain,
    get_lineage_sql,
    get_table_columns,
    get_table_lineage,
)

logger = logging.getLogger(__name__)


DEVELOPER_AGENT_SYSTEM_INSTRUCTIONS = """ä½ æ˜¯ Datapillar çš„ DeveloperAgentï¼ˆæ•°æ®å¼€å‘ï¼‰ã€‚

## ä»»åŠ¡
æ ¹æ®"ä»»åŠ¡å‚æ•° JSON"å’Œ"çŸ¥è¯†ä¸Šä¸‹æ–‡ JSON"ï¼Œä¸ºæŒ‡å®š Job ç”Ÿæˆå®Œæ•´ SQL è„šæœ¬ã€‚

## ä»»åŠ¡å‚æ•°ï¼ˆç³»ç»Ÿæ³¨å…¥ï¼Œä¸æ˜¯ç”¨æˆ·è¾“å…¥ï¼‰
ç³»ç»Ÿä¼šæä¾›ä¸€æ®µ"ä»»åŠ¡å‚æ•° JSON"ï¼ˆSystemMessageï¼‰ï¼Œå…¶ä¸­åŒ…å«ï¼š
- user_queryï¼šç”¨æˆ·åŸå§‹éœ€æ±‚ï¼ˆä»…ç”¨äºç†è§£ä¸šåŠ¡ï¼‰
- current_jobï¼šæœ¬æ¬¡éœ€è¦ç”Ÿæˆ SQL çš„ Jobï¼ˆå« stagesï¼‰
- evidenceï¼šå·²é€šè¿‡å·¥å…·è·å–çš„è¯æ®ï¼ˆè¡¨ç»“æ„/åˆ—çº§è¡€ç¼˜/å†å² SQLï¼‰
- test_feedbackï¼šä¸Šä¸€è½®æµ‹è¯•åé¦ˆï¼ˆå¦‚æœ‰ï¼‰

## çŸ¥è¯†ä¸Šä¸‹æ–‡ï¼ˆç³»ç»Ÿæ³¨å…¥ï¼Œä¸æ˜¯ç”¨æˆ·è¾“å…¥ï¼‰
ç³»ç»Ÿä¼šæä¾›ä¸€æ®µ"çŸ¥è¯†ä¸Šä¸‹æ–‡ JSON"ï¼ˆSystemMessageï¼‰ï¼Œå…¶ä¸­åŒ…å«ï¼š
- tablesï¼šå¯ç”¨çš„ schema.table åˆ—è¡¨ï¼ˆå¯¼èˆªæŒ‡é’ˆï¼‰
- etl_pointersï¼šå¯éªŒè¯çš„ ETL æŒ‡é’ˆï¼ˆå« qualified_name/element_id/toolsï¼‰
- allowlist_toolsï¼šä½ å…è®¸è°ƒç”¨çš„å·¥å…·ååˆ—è¡¨

ä½ å¿…é¡»æŠŠè¯¥ JSON è§†ä¸ºå”¯ä¸€å¯ä¿¡çŸ¥è¯†å…¥å£ï¼š
- ç¦æ­¢è‡†é€ ä»»ä½• schema.table
- å·¥å…·è°ƒç”¨åªèƒ½ä½¿ç”¨è¯¥ JSON ä¸­å‡ºç°çš„è¡¨æŒ‡é’ˆï¼ˆæŒ‰ qualified_name ç²¾ç¡®åŒ¹é…ï¼‰
- ä»…å½“ ETLPointer.tools åŒ…å«å·¥å…·åæ—¶ï¼Œæ‰å…è®¸å¯¹è¯¥è¡¨è°ƒç”¨è¯¥å·¥å…·

## ç”Ÿæˆè¦æ±‚ï¼ˆä¸¥æ ¼ï¼‰

### 1. åˆ—åˆ«åè§„èŒƒï¼ˆä¸¥æ ¼æ‰§è¡Œï¼‰
æ‰€æœ‰ SELECT å­—æ®µå¿…é¡»ä½¿ç”¨ AS åˆ«åï¼š
- æ™®é€šå­—æ®µï¼š`t.order_id AS order_id`
- è®¡ç®—å­—æ®µï¼š`t.amount * 2 AS double_amount`
- èšåˆå‡½æ•°ï¼š`SUM(t.amount) AS total_amount`
- ä¸å…è®¸æ— åˆ«åå­—æ®µï¼š`t.order_id` âŒ â†’ `t.order_id AS order_id` âœ…

ç›®æ ‡è¡¨åˆ—å¯¹é½ï¼š
- SELECT çš„åˆ«åå¿…é¡»ä¸ç›®æ ‡è¡¨åˆ—åå®Œå…¨ä¸€è‡´
- ä¾‹ï¼šç›®æ ‡è¡¨æœ‰åˆ— `adjusted_amount` â†’ å†™ `t.amount AS adjusted_amount`

ä¸´æ—¶è¡¨åˆ—å¼•ç”¨ï¼š
- ä¸´æ—¶è¡¨çš„ SELECT åˆ—å¿…é¡»å…¨éƒ¨æœ‰æ˜ç¡®åˆ«å
- åç»­ Stage é€šè¿‡åˆ«åå¼•ç”¨ä¸´æ—¶è¡¨åˆ—

### 2. ä¸´æ—¶è¡¨è§„èŒƒ
- åˆ›å»ºä¸´æ—¶è¡¨å‰å¿…é¡»å…ˆåˆ é™¤ï¼š`DROP TABLE IF EXISTS temp.xxx;` ç„¶åå† `CREATE TABLE temp.xxx AS ...`
- ä¸´æ—¶è¡¨å¿…é¡»æ”¾åœ¨ temp åº“ä¸‹ï¼Œæ ¼å¼ä¸º `temp.tmp_<æè¿°æ€§åç§°>`

### 3. å‚è€ƒè¯æ®ï¼ˆä¸¥æ ¼ï¼‰
- å¿…é¡»å‚è€ƒå†å² SQL ä¸­çš„ JOIN æ¡ä»¶ï¼Œä¸è¦è‡ªå·±çŒœæµ‹å…³è”å­—æ®µ
- å‚è€ƒåˆ—çº§è¡€ç¼˜ä¸­çš„å­—æ®µæ˜ å°„å…³ç³»ï¼Œç¡®ä¿å­—æ®µè½¬æ¢æ­£ç¡®
- ä¿æŒä¸å†å² SQL ç›¸åŒçš„å†™æ³•é£æ ¼

### 4. è¾“å‡ºæ ¼å¼å‚è€ƒï¼ˆä»…ç¤ºä¾‹ï¼‰
```sql
-- Stage 1: xxx
DROP TABLE IF EXISTS temp.tmp_step1;
CREATE TABLE temp.tmp_step1 AS
SELECT
    t.order_id AS order_id,
    t.user_id AS user_id,
    t.amount AS amount,
    SUM(t.amount) AS total_amount
FROM source_table t
GROUP BY t.order_id, t.user_id, t.amount;

-- Stage 2: xxx
INSERT OVERWRITE TABLE schema.target_table
SELECT
    tmp.order_id AS order_id,
    tmp.user_id AS user_id,
    tmp.total_amount AS total_amount
FROM temp.tmp_step1 tmp;
```

åªè¾“å‡º SQLï¼Œä¸è¦è§£é‡Šã€‚
"""


class DeveloperAgent:
    """
    æ•°æ®å¼€å‘

    èŒè´£ï¼š
    1. è¯»å–æ¯ä¸ª Job ä¸­çš„ Stage ä¿¡æ¯
    2. é€šè¿‡å·¥å…·è·å–è¡¨ç»“æ„ã€åˆ—çº§è¡€ç¼˜ã€å‚è€ƒ SQL
    3. ä¸ºæ¯ä¸ª Stage ç”Ÿæˆ SQL
    4. å°†æ‰€æœ‰ Stage SQL ç»„åˆä¸ºå®Œæ•´è„šæœ¬
    5. è®°å½•å‚è€ƒçš„ SQL IDï¼Œç”¨äºåç»­æ‰“åˆ†
    """

    def __init__(self):
        self.llm = call_llm(temperature=0.0)
        self.max_retries = 2
        self.max_tool_calls = 6
        self._referenced_sql_ids: list[str] = []
        self.allowlist = get_agent_tools(AgentType.DEVELOPER)

    async def run(
        self,
        *,
        user_query: str,
        workflow: Workflow,
        test_feedback: TestResult | None = None,
        knowledge_agent=None,
    ) -> AgentResult:
        """
        æ‰§è¡Œ SQL ç”Ÿæˆ

        å‚æ•°ï¼š
        - user_query: ç”¨æˆ·è¾“å…¥
        - workflow: å·¥ä½œæµï¼ˆåŒ…å« Jobsï¼‰
        - test_feedback: ä¸Šä¸€è½®æµ‹è¯•åé¦ˆ
        - knowledge_agent: KnowledgeAgent å®ä¾‹ï¼ˆç”¨äºæŒ‰éœ€æŸ¥è¯¢æŒ‡é’ˆï¼‰

        è¿”å›ï¼š
        - AgentResult: æ‰§è¡Œç»“æœ
        """
        self._referenced_sql_ids = []
        self._knowledge_agent = knowledge_agent

        is_iteration = test_feedback is not None
        if is_iteration:
            logger.info("ğŸ’» DeveloperAgent æ ¹æ®æµ‹è¯•åé¦ˆé‡æ–°ç”Ÿæˆ SQL")
        else:
            logger.info("ğŸ’» DeveloperAgent å¼€å§‹ç”Ÿæˆ SQL")

        all_errors: list[str] = []
        generated_count = 0

        try:
            sorted_jobs = workflow.topological_sort()

            for job in sorted_jobs:
                if not job.stages:
                    all_errors.append(f"Job {job.id} æ²¡æœ‰ Stage ä¿¡æ¯")
                    break

                previous_sql = job.config.get("content") if job.config else None
                job_test_feedback = self._format_test_feedback(test_feedback, previous_sql)

                sql_script, success, errors = await self._generate_job_sql(
                    user_query=user_query,
                    job=job,
                    test_feedback=job_test_feedback,
                )

                if success:
                    job.config = {"content": sql_script}
                    job.config_generated = True
                    generated_count += 1
                    logger.info(f"âœ… Job {job.id} SQL ç”ŸæˆæˆåŠŸ ({len(job.stages)} ä¸ª Stage)")
                else:
                    all_errors.extend(errors)
                    logger.error(f"âŒ Job {job.id} SQL ç”Ÿæˆå¤±è´¥: {errors}")
                    break

            if all_errors or generated_count < len(sorted_jobs):
                logger.error(f"âŒ DeveloperAgent å¤±è´¥: {generated_count}/{len(sorted_jobs)} æˆåŠŸ")
                return AgentResult.failed(
                    summary=f"SQL ç”Ÿæˆå¤±è´¥: {all_errors[0] if all_errors else 'éƒ¨åˆ† Job æœªç”Ÿæˆ'}",
                    error="\n".join(all_errors) if all_errors else "éƒ¨åˆ† Job ç”Ÿæˆå¤±è´¥",
                )

            logger.info(f"âœ… DeveloperAgent å®Œæˆ: å…¨éƒ¨ {generated_count} ä¸ª Job æˆåŠŸ")

            unique_sql_ids = list(set(self._referenced_sql_ids))
            if unique_sql_ids:
                logger.info(f"ğŸ“ å‚è€ƒäº† {len(unique_sql_ids)} ä¸ªå†å² SQL: {unique_sql_ids}")

            return AgentResult.completed(
                summary=f"SQL ç”Ÿæˆå®Œæˆ: {generated_count} ä¸ª Job",
                deliverable=workflow,
                deliverable_type="workflow",
            )

        except Exception as e:
            logger.error(f"DeveloperAgent ç”Ÿæˆå¤±è´¥: {e}", exc_info=True)
            return AgentResult.failed(
                summary=f"SQL ç”Ÿæˆå¤±è´¥: {str(e)}",
                error=str(e),
            )

    def _format_test_feedback(
        self, test_result: TestResult | None, previous_sql: str | None = None
    ) -> str:
        """æ ¼å¼åŒ–æµ‹è¯•åé¦ˆï¼ˆåŒ…å«ä¸Šä¸€è½®é”™è¯¯ SQLï¼‰"""
        if not test_result:
            return ""

        validation_errors = test_result.validation_errors or []
        failed_tests = test_result.failed_tests or 0

        if not validation_errors and failed_tests == 0:
            return ""

        lines = ["\n## âš ï¸ ä¸Šä¸€è½®æµ‹è¯•åé¦ˆï¼ˆå¿…é¡»ä¿®å¤ï¼‰\n"]

        if failed_tests > 0:
            lines.append(f"å¤±è´¥æµ‹è¯•æ•°: {failed_tests}\n")

        if validation_errors:
            lines.append("### é”™è¯¯åˆ—è¡¨")
            for error in validation_errors:
                lines.append(f"- {error}")

        if previous_sql:
            lines.append("\n### ä¸Šä¸€è½®ç”Ÿæˆçš„é”™è¯¯ SQLï¼ˆä¸è¦é‡å¤è¿™äº›é”™è¯¯ï¼ï¼‰")
            lines.append(f"```sql\n{previous_sql[:1500]}\n```")

        lines.append("")
        return "\n".join(lines)

    async def _generate_job_sql(
        self,
        *,
        user_query: str,
        job: Job,
        test_feedback: str = "",
    ) -> tuple[str, bool, list[str]]:
        """ä¸ºæ•´ä¸ª Job ç”Ÿæˆ SQL è„šæœ¬ï¼ˆé€šè¿‡å·¥å…·è·å–çŸ¥è¯†ï¼‰"""
        all_input_tables = set(job.input_tables or [])
        output_table = job.output_table

        table_schemas = await self._fetch_table_schemas(list(all_input_tables))
        column_lineage = await self._fetch_column_lineage(list(all_input_tables), output_table)
        reference_sql = await self._fetch_reference_sql(list(all_input_tables), output_table)

        stages_info = self._format_stages(job.stages)

        for attempt in range(self.max_retries):
            try:
                task_payload = {
                    "user_query": user_query,
                    "current_job": {
                        "id": job.id,
                        "name": job.name,
                        "description": job.description,
                        "type": job.type,
                        "input_tables": job.input_tables,
                        "output_table": job.output_table,
                        "stages_info": stages_info,
                        "stages": [
                            {
                                "stage_id": st.stage_id,
                                "name": st.name,
                                "description": st.description,
                                "input_tables": st.input_tables,
                                "output_table": st.output_table,
                                "is_temp_table": st.is_temp_table,
                            }
                            for st in sorted((job.stages or []), key=lambda s: s.stage_id)
                        ],
                    },
                    "evidence": {
                        "table_schemas": table_schemas,
                        "column_lineage": column_lineage,
                        "reference_sql": reference_sql,
                    },
                    "test_feedback": test_feedback,
                }

                sql = await self._generate_sql(
                    user_query=user_query,
                    task_payload=task_payload,
                )

                if not sql or len(sql) < 20:
                    continue

                if not any(kw in sql.upper() for kw in ["SELECT", "INSERT", "CREATE"]):
                    continue

                return sql, True, []

            except Exception as e:
                logger.error(f"Job {job.id} SQL ç”Ÿæˆå¤±è´¥ (å°è¯• {attempt + 1}): {e}")

        return "", False, [f"Job {job.id} SQL ç”Ÿæˆå¤±è´¥"]

    async def _generate_sql(
        self,
        *,
        user_query: str,
        task_payload: dict,
    ) -> str:
        """ä½¿ç”¨å·¥å…·ç”Ÿæˆ SQL"""
        llm_with_tools = self._bind_tools()
        messages = build_llm_messages(
            system_instructions=DEVELOPER_AGENT_SYSTEM_INSTRUCTIONS,
            agent_id="developer_agent",
            user_query=user_query,
            task_payload=task_payload,
        )
        tool_call_count = 0

        while tool_call_count < self.max_tool_calls:
            response = await llm_with_tools.ainvoke(messages)
            messages.append(response)

            if not response.tool_calls:
                return self._clean_sql(response.content)

            for tool_call in response.tool_calls:
                tool_call_count += 1
                tool_name = tool_call["name"]
                tool_args = tool_call["args"]
                tool_id = tool_call["id"]

                logger.info(f"ğŸ”§ DeveloperAgent è°ƒç”¨å·¥å…·: {tool_name}({tool_args})")

                tool_result = await self._execute_tool(tool_name, tool_args)

                messages.append(ToolMessage(content=tool_result, tool_call_id=tool_id))

                if tool_call_count >= self.max_tool_calls:
                    break

        response = await self.llm.ainvoke(messages)
        return self._clean_sql(response.content)

    def _bind_tools(self):
        """ç»‘å®šå·¥å…·åˆ° LLM"""
        tool_registry = {
            "get_table_columns": get_table_columns,
            "get_column_valuedomain": get_column_valuedomain,
            "get_table_lineage": get_table_lineage,
            "get_lineage_sql": get_lineage_sql,
        }
        tools = [tool_registry[name] for name in self.allowlist if name in tool_registry]
        return self.llm.bind_tools(tools)

    @staticmethod
    def _tool_error(message: str, **extra: object) -> str:
        payload: dict[str, object] = {"status": "error", "message": message}
        payload.update(extra)
        return json.dumps(payload, ensure_ascii=False)

    # å·¥å…·å¤„ç†å™¨æ˜ å°„
    _TOOL_HANDLERS: dict[str, str] = {
        "get_table_columns": "_exec_columns",
        "get_column_valuedomain": "_exec_valuedomain",
        "get_table_lineage": "_exec_lineage",
        "get_lineage_sql": "_exec_lineagesql",
    }

    async def _execute_tool(self, tool_name: str, tool_args: dict) -> str:
        """
        æ‰§è¡Œå·¥å…·è°ƒç”¨ï¼ˆæŒ‰éœ€è·å–æŒ‡é’ˆ + æƒé™æ ¡éªŒï¼‰

        æµç¨‹ï¼š
        1. è°ƒç”¨ query_pointers è·å–å¯¹åº”ç±»å‹çš„æŒ‡é’ˆ
        2. æ£€æŸ¥æŒ‡é’ˆä¸Šçš„ tools æ˜¯å¦åŒ…å«è¦è°ƒç”¨çš„å·¥å…·
        3. ç”¨æŒ‡é’ˆçš„ä¿¡æ¯è°ƒç”¨å·¥å…·
        """
        try:
            if tool_name not in self.allowlist:
                return self._tool_error(f"å·¥å…·ä¸åœ¨ allowlist ä¸­: {tool_name}")

            if not self._knowledge_agent:
                return self._tool_error("æ— æ³•æŸ¥è¯¢æŒ‡é’ˆï¼šknowledge_agent æœªæ³¨å…¥")

            handler_name = self._TOOL_HANDLERS.get(tool_name)
            if not handler_name:
                return self._tool_error(f"æœªçŸ¥å·¥å…·: {tool_name}")

            handler = getattr(self, handler_name)
            return await handler(tool_args or {})
        except Exception as e:
            logger.error(f"å·¥å…· {tool_name} æ‰§è¡Œå¤±è´¥: {e}")
            return self._tool_error(str(e))

    async def _exec_columns(self, args: dict) -> str:
        """æ‰§è¡Œ get_table_columns å·¥å…·"""
        table_name = args.get("table_name") or ""
        if not table_name:
            return self._tool_error("ç¼ºå°‘ table_name å‚æ•°")

        pointers = await self._knowledge_agent.query_pointers(
            table_name, node_types=["Table"], top_k=5
        )
        pointer = self._find_matching_pointer(pointers, table_name)
        if not pointer:
            return self._tool_error("æœªæ‰¾åˆ°æŒ‡é’ˆ", table_name=table_name)
        if "get_table_columns" not in (pointer.tools or []):
            return self._tool_error("æŒ‡é’ˆæœªæˆæƒæ­¤å·¥å…·", table_name=table_name)

        logger.info(f"ğŸ“Š è°ƒç”¨ get_table_columns: {pointer.qualified_name}")
        return await get_table_columns.ainvoke({"table_name": pointer.qualified_name})

    async def _exec_valuedomain(self, args: dict) -> str:
        """æ‰§è¡Œ get_column_valuedomain å·¥å…·"""
        column_name = args.get("column_name") or ""
        if not column_name:
            return self._tool_error("ç¼ºå°‘ column_name å‚æ•°")

        pointers = await self._knowledge_agent.query_pointers(
            column_name, node_types=["Column"], top_k=5
        )
        pointer = self._find_matching_pointer(pointers, column_name)
        if not pointer:
            return self._tool_error("æœªæ‰¾åˆ°æŒ‡é’ˆ", column_name=column_name)
        if "get_column_valuedomain" not in (pointer.tools or []):
            return self._tool_error("æŒ‡é’ˆæœªæˆæƒæ­¤å·¥å…·", column_name=column_name)

        logger.info(f"ğŸ“Š è°ƒç”¨ get_column_valuedomain: {pointer.qualified_name}")
        return await get_column_valuedomain.ainvoke({"column_name": pointer.qualified_name})

    async def _exec_lineage(self, args: dict) -> str:
        """æ‰§è¡Œ get_table_lineage å·¥å…·"""
        table_name = args.get("table_name") or ""
        direction = args.get("direction") or "both"
        if not table_name:
            return self._tool_error("ç¼ºå°‘ table_name å‚æ•°")

        pointers = await self._knowledge_agent.query_pointers(
            table_name, node_types=["Table"], top_k=5
        )
        pointer = self._find_matching_pointer(pointers, table_name)
        if not pointer:
            return self._tool_error("æœªæ‰¾åˆ°æŒ‡é’ˆ", table_name=table_name)
        if "get_table_lineage" not in (pointer.tools or []):
            return self._tool_error("æŒ‡é’ˆæœªæˆæƒæ­¤å·¥å…·", table_name=table_name)

        logger.info(f"ğŸ“Š è°ƒç”¨ get_table_lineage: {pointer.qualified_name}")
        return await get_table_lineage.ainvoke(
            {"table_name": pointer.qualified_name, "direction": direction}
        )

    async def _exec_lineagesql(self, args: dict) -> str:
        """æ‰§è¡Œ get_lineage_sql å·¥å…·"""
        source_tables = args.get("source_tables") or []
        target_table = args.get("target_table") or ""
        if not source_tables or not target_table:
            return self._tool_error("ç¼ºå°‘ source_tables æˆ– target_table å‚æ•°")

        target_pointers = await self._knowledge_agent.query_pointers(
            target_table, node_types=["Table"], top_k=3
        )
        target_ptr = self._find_matching_pointer(target_pointers, target_table)
        if not target_ptr:
            return self._tool_error("æœªæ‰¾åˆ°æŒ‡é’ˆ", target_table=target_table)
        if "get_lineage_sql" not in (target_ptr.tools or []):
            return self._tool_error("æŒ‡é’ˆæœªæˆæƒæ­¤å·¥å…·", target_table=target_table)

        validated_sources = []
        for src in source_tables:
            src_pointers = await self._knowledge_agent.query_pointers(
                src, node_types=["Table"], top_k=3
            )
            src_ptr = self._find_matching_pointer(src_pointers, src)
            if src_ptr:
                validated_sources.append(src_ptr.qualified_name)

        logger.info(f"ğŸ“Š è°ƒç”¨ get_lineage_sql: {validated_sources} -> {target_ptr.qualified_name}")
        return await get_lineage_sql.ainvoke(
            {"source_tables": validated_sources, "target_table": target_ptr.qualified_name}
        )

    def _find_matching_pointer(self, pointers: list, name: str):
        """ä»æŒ‡é’ˆåˆ—è¡¨ä¸­æ‰¾åˆ°åŒ¹é…çš„æŒ‡é’ˆ"""
        if not pointers:
            return None
        # ç²¾ç¡®åŒ¹é…
        for p in pointers:
            if p.qualified_name == name:
                return p
        # éƒ¨åˆ†åŒ¹é…
        for p in pointers:
            if name in (p.qualified_name or ""):
                return p
        # è¿”å›ç¬¬ä¸€ä¸ª
        return pointers[0] if pointers else None

    def _format_stages(self, stages: list[Stage]) -> str:
        """æ ¼å¼åŒ– Stage åˆ—è¡¨"""
        lines = []
        for stage in sorted(stages, key=lambda s: s.stage_id):
            lines.append(f"### Stage {stage.stage_id}: {stage.name}")
            lines.append(f"- æè¿°: {stage.description}")
            lines.append(f"- è¾“å…¥è¡¨: {', '.join(stage.input_tables)}")
            lines.append(f"- è¾“å‡ºè¡¨: {stage.output_table}")
            lines.append(f"- æ˜¯å¦ä¸´æ—¶è¡¨: {stage.is_temp_table}")
            lines.append("")
        return "\n".join(lines)

    async def _fetch_table_schemas(self, input_tables: list[str]) -> str:
        """é€šè¿‡å·¥å…·è·å–è¡¨ç»“æ„ä¿¡æ¯"""
        lines = []
        for table_name in input_tables:
            try:
                result = await self._execute_tool(
                    "get_table_columns",
                    {"table_name": table_name},
                )
                data = json.loads(result)
                if data.get("status") == "success":
                    columns = data.get("columns", [])
                    col_info = [
                        f"{c.get('name')} ({c.get('data_type', 'string')})" for c in columns[:20]
                    ]
                    lines.append(f"### {table_name}")
                    lines.append(f"å­—æ®µ: {', '.join(col_info)}")
                    if len(columns) > 20:
                        lines.append(f"...å…± {len(columns)} ä¸ªå­—æ®µ")
                    lines.append("")
            except Exception as e:
                logger.warning(f"è·å–è¡¨ {table_name} ç»“æ„å¤±è´¥: {e}")
        return "\n".join(lines) if lines else "ï¼ˆæ— ï¼‰"

    async def _fetch_column_lineage(
        self,
        input_tables: list[str],
        output_table: str | None,
    ) -> str:
        """é€šè¿‡ get_table_lineage è·å–åˆ—çº§è¡€ç¼˜ä¿¡æ¯"""
        if not output_table or not input_tables:
            return "ï¼ˆæ— ï¼‰"
        lines = []
        try:
            # è°ƒç”¨ get_table_lineage è·å–ç›®æ ‡è¡¨çš„ä¸Šæ¸¸è¡€ç¼˜ï¼ˆå«åˆ—æ˜ å°„ï¼‰
            result = await self._execute_tool(
                "get_table_lineage",
                {"table_name": output_table, "direction": "upstream"},
            )
            data = json.loads(result)
            if data.get("status") == "success":
                lineage_edges = data.get("lineage_edges", [])
                input_set = set(input_tables)
                for edge in lineage_edges:
                    source = edge.get("source_table", "")
                    # åŒ¹é…è¾“å…¥è¡¨
                    if source in input_set or any(source.endswith(f".{t}") for t in input_set):
                        mappings = edge.get("column_mappings", [])
                        if mappings:
                            lines.append(f"### {source} â†’ {output_table}")
                            for m in mappings[:20]:
                                src_col = m.get("source_column", "")
                                tgt_col = m.get("target_column", "")
                                transform = m.get("transformation", "direct")
                                if src_col and tgt_col:
                                    lines.append(f"- {src_col} â†’ {tgt_col} ({transform})")
                            lines.append("")
        except Exception as e:
            logger.warning(f"è·å–åˆ—çº§è¡€ç¼˜å¤±è´¥: {e}")
        return "\n".join(lines) if lines else "ï¼ˆæ— ï¼‰"

    async def _fetch_reference_sql(
        self,
        input_tables: list[str],
        output_table: str | None,
    ) -> str:
        """é€šè¿‡å·¥å…·ç²¾å‡†åŒ¹é…å†å² SQLï¼ˆæ ¹æ®è¡€ç¼˜å…³ç³»ï¼‰"""
        if not input_tables or not output_table:
            return "ï¼ˆæ— å†å² SQLï¼‰"
        try:
            result = await self._execute_tool(
                "get_lineage_sql",
                {"source_tables": input_tables, "target_table": output_table},
            )
            data = json.loads(result)
            if data.get("status") == "success":
                sql_content = data.get("sql_content")
                sql_id = data.get("sql_id")
                if sql_id:
                    self._referenced_sql_ids.append(sql_id)
                    logger.info(f"ğŸ“Œ å‚è€ƒå†å² SQL: {sql_id}")
                if sql_content:
                    sql_name = data.get("sql_name", "")
                    engine = data.get("engine", "")
                    return f"""### å†å² SQLï¼ˆ{sql_name}ï¼Œå¼•æ“: {engine}ï¼‰
ç›´æ¥å‚è€ƒæ­¤ SQL çš„ JOIN æ¡ä»¶å’Œå†™æ³•é£æ ¼ï¼

```sql
{sql_content}
```
"""
        except Exception as e:
            logger.warning(f"è·å–å†å² SQL å¤±è´¥: {e}")
        return "ï¼ˆæ— å†å² SQLï¼‰"

    @staticmethod
    def _clean_sql(content: str) -> str:
        """æ¸…ç† SQLï¼ˆå»æ‰ markdown ä»£ç å—ï¼‰"""
        sql_match = re.search(r"```sql\s*([\s\S]*?)\s*```", content)
        if sql_match:
            return sql_match.group(1).strip()
        code_match = re.search(r"```\s*([\s\S]*?)\s*```", content)
        if code_match:
            return code_match.group(1).strip()
        return content.strip()
