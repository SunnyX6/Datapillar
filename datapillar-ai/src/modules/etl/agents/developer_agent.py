"""
Developer Agentï¼ˆæ•°æ®å¼€å‘ï¼‰

èŒè´£ï¼šä¸ºæ¯ä¸ª Stage ç”Ÿæˆ SQL
- æ¯ä¸ª Job åŒ…å«å¤šä¸ª Stageï¼ˆæ¥è‡ª AnalystAgent çš„æ‹†åˆ†ï¼‰
- ä¸ºæ¯ä¸ª Stage ç”Ÿæˆ SQL
- å°†æ‰€æœ‰ Stage çš„ SQL ç»„åˆä¸ºå®Œæ•´è„šæœ¬
"""

import json
import logging
from typing import Optional, List, Dict, Any

from langchain_core.messages import AIMessage, HumanMessage
from langgraph.types import Command

from src.modules.etl.schemas.state import AgentState
from src.modules.etl.schemas.plan import Workflow, Job
from src.infrastructure.repository import ComponentRepository
from src.infrastructure.llm.client import call_llm

logger = logging.getLogger(__name__)


STAGE_SQL_PROMPT = """ä½ æ˜¯èµ„æ·±æ•°æ®å¼€å‘å·¥ç¨‹å¸ˆï¼Œè¯·ä¸ºä»¥ä¸‹ Stage ç”Ÿæˆ SQLã€‚

## Stage ä¿¡æ¯
- åç§°: {stage_name}
- æè¿°: {stage_description}
- è¾“å…¥è¡¨: {input_tables}
- è¾“å‡ºè¡¨: {output_table}
- æ˜¯å¦ä¸´æ—¶è¡¨: {is_temp_table}

## ç›¸å…³è¡¨ç»“æ„
{table_schemas}

## JOIN å…³ç³»
{join_hints}

## ç”Ÿæˆè¦æ±‚

### å¦‚æœæ˜¯ä¸´æ—¶è¡¨ (is_temp_table=true)
```sql
CREATE TEMPORARY TABLE {output_table} AS
SELECT ...
FROM ...
WHERE ...;
```

### å¦‚æœæ˜¯æœ€ç»ˆè¡¨ (is_temp_table=false)
```sql
INSERT OVERWRITE TABLE {output_table} PARTITION(dt='${{bizdate}}')
SELECT ...
FROM ...
WHERE ...;
```

## æ³¨æ„äº‹é¡¹
1. æ ¹æ® Stage æè¿°ç”Ÿæˆå®Œæ•´çš„ SQL
2. å­—æ®µåå¿…é¡»ä¸è¡¨ç»“æ„ä¸€è‡´
3. åªè¾“å‡º SQLï¼Œä¸è¦è§£é‡Š

è¯·è¾“å‡º SQLï¼š
"""


class DeveloperAgent:
    """
    æ•°æ®å¼€å‘

    èŒè´£ï¼š
    1. è¯»å–æ¯ä¸ª Job ä¸­çš„ stages ä¿¡æ¯
    2. ä¸ºæ¯ä¸ª Stage ç”Ÿæˆ SQL
    3. å°†æ‰€æœ‰ Stage SQL ç»„åˆä¸ºå®Œæ•´è„šæœ¬
    """

    def __init__(self):
        self.llm = call_llm(temperature=0.0)
        self.max_retries = 2

    async def __call__(self, state: AgentState) -> Command:
        """æ‰§è¡Œé…ç½®ç”Ÿæˆ"""
        architecture_plan = state.architecture_plan
        knowledge_context = state.knowledge_context

        if not architecture_plan:
            return Command(
                update={
                    "messages": [AIMessage(content="ç¼ºå°‘æ¶æ„æ–¹æ¡ˆï¼Œæ— æ³•ç”Ÿæˆé…ç½®")],
                    "current_agent": "developer_agent",
                    "error": "ç¼ºå°‘æ¶æ„æ–¹æ¡ˆ",
                }
            )

        logger.info("ğŸ’» DeveloperAgent å¼€å§‹ç”Ÿæˆ SQL")

        # è½¬æ¢ä¸º Workflow
        if isinstance(architecture_plan, dict):
            plan = Workflow(**architecture_plan)
        else:
            plan = architecture_plan

        # ç¼“å­˜ç»„ä»¶ä¿¡æ¯
        component_cache: Dict[str, Dict] = {}

        all_errors: List[str] = []
        generated_count = 0

        try:
            # æŒ‰æ‹“æ‰‘é¡ºåºå¤„ç†èŠ‚ç‚¹
            sorted_nodes = plan.topological_sort()

            for node in sorted_nodes:
                # è·å–ç»„ä»¶é…ç½®
                if node.type not in component_cache:
                    component = ComponentRepository.get_component_by_id(node.type)
                    if component:
                        if isinstance(component.get("config_schema"), str):
                            component["config_schema"] = json.loads(component["config_schema"])
                        component_cache[node.type] = component
                    else:
                        all_errors.append(f"èŠ‚ç‚¹ {node.id} çš„ç»„ä»¶ {node.type} ä¸å­˜åœ¨")
                        continue

                component = component_cache[node.type]

                # è·å– stages
                stages = node.config.get("stages", [])
                if not stages:
                    all_errors.append(f"èŠ‚ç‚¹ {node.id} æ²¡æœ‰ stages ä¿¡æ¯")
                    continue

                # ä¸ºæ¯ä¸ª Stage ç”Ÿæˆ SQL
                sql_script, success, errors = await self._generate_sql_script(
                    node=node,
                    stages=stages,
                    component=component,
                    knowledge_context=knowledge_context,
                )

                # æ›´æ–°èŠ‚ç‚¹é…ç½®
                node.config = {
                    "sql": sql_script,
                    "stages": stages,  # ä¿ç•™ stages ä¿¡æ¯
                }
                node.config_generated = success

                if success:
                    generated_count += 1
                    logger.info(f"âœ… èŠ‚ç‚¹ {node.id} SQL è„šæœ¬ç”ŸæˆæˆåŠŸ ({len(stages)} ä¸ª Stage)")
                else:
                    all_errors.extend(errors)
                    logger.warning(f"âŒ èŠ‚ç‚¹ {node.id} SQL ç”Ÿæˆå¤±è´¥: {errors}")

            # æ›´æ–° plan
            plan_dict = plan.model_dump()

            logger.info(
                f"âœ… DeveloperAgent å®Œæˆ: {generated_count}/{len(sorted_nodes)} æˆåŠŸ"
            )

            if all_errors:
                return Command(
                    update={
                        "messages": [AIMessage(content=f"SQL ç”Ÿæˆå®Œæˆï¼Œä½†æœ‰ {len(all_errors)} ä¸ªé—®é¢˜")],
                        "architecture_plan": plan_dict,
                        "current_agent": "developer_agent",
                        "error": "\n".join(all_errors[:5]),
                    }
                )

            return Command(
                update={
                    "messages": [AIMessage(content=f"SQL ç”Ÿæˆå®Œæˆ: {generated_count} ä¸ªèŠ‚ç‚¹")],
                    "architecture_plan": plan_dict,
                    "current_agent": "developer_agent",
                }
            )

        except Exception as e:
            logger.error(f"DeveloperAgent ç”Ÿæˆå¤±è´¥: {e}", exc_info=True)
            return Command(
                update={
                    "messages": [AIMessage(content=f"SQL ç”Ÿæˆå¤±è´¥: {str(e)}")],
                    "current_agent": "developer_agent",
                    "error": str(e),
                }
            )

    async def _generate_sql_script(
        self,
        node: Job,
        stages: List[Dict],
        component: Dict[str, Any],
        knowledge_context: Optional[dict],
    ) -> tuple[str, bool, List[str]]:
        """ä¸ºæ‰€æœ‰ Stage ç”Ÿæˆ SQL å¹¶ç»„åˆ"""
        sql_parts = []
        errors = []

        for stage in stages:
            stage_sql, success, stage_errors = await self._generate_stage_sql(
                stage=stage,
                knowledge_context=knowledge_context,
            )

            if success:
                sql_parts.append(f"-- Stage {stage.get('stage_id')}: {stage.get('name')}")
                sql_parts.append(stage_sql)
                sql_parts.append("")
            else:
                errors.extend(stage_errors)

        if errors:
            return "\n".join(sql_parts), False, errors

        return "\n".join(sql_parts), True, []

    async def _generate_stage_sql(
        self,
        stage: Dict,
        knowledge_context: Optional[dict],
    ) -> tuple[str, bool, List[str]]:
        """ä¸ºå•ä¸ª Stage ç”Ÿæˆ SQL"""
        table_schemas = self._format_table_schemas(stage.get("input_tables", []), knowledge_context)
        join_hints = self._format_join_hints(knowledge_context)

        for attempt in range(self.max_retries):
            try:
                prompt = STAGE_SQL_PROMPT.format(
                    stage_name=stage.get("name", ""),
                    stage_description=stage.get("description", ""),
                    input_tables=", ".join(stage.get("input_tables", [])),
                    output_table=stage.get("output_table", ""),
                    is_temp_table=stage.get("is_temp_table", True),
                    table_schemas=table_schemas,
                    join_hints=join_hints,
                )

                response = await self.llm.ainvoke([HumanMessage(content=prompt)])
                sql = self._clean_sql(response.content)

                if not sql or len(sql) < 20:
                    continue

                if not any(kw in sql.upper() for kw in ["SELECT", "INSERT", "CREATE"]):
                    continue

                return sql, True, []

            except Exception as e:
                logger.error(f"Stage {stage.get('name')} SQL ç”Ÿæˆå¤±è´¥: {e}")

        return "", False, [f"Stage {stage.get('name')} SQL ç”Ÿæˆå¤±è´¥"]

    def _format_table_schemas(self, input_tables: List[str], context: Optional[dict]) -> str:
        """æ ¼å¼åŒ–è¡¨ç»“æ„ä¿¡æ¯"""
        if not context:
            return "ï¼ˆæ— ï¼‰"

        tables = context.get("tables", {})
        lines = []

        for table_name in input_tables:
            # è·³è¿‡ä¸´æ—¶è¡¨
            if table_name.startswith("tmp."):
                continue

            if table_name in tables:
                table = tables[table_name]
                key_columns = table.get("key_columns", [])
                col_info = [f"{c.get('name')} ({c.get('data_type', 'string')})" for c in key_columns]
                lines.append(f"### {table_name}")
                lines.append(f"å­—æ®µ: {', '.join(col_info)}")
                lines.append("")

        return "\n".join(lines) if lines else "ï¼ˆæ— ï¼‰"

    def _format_join_hints(self, context: Optional[dict]) -> str:
        """æ ¼å¼åŒ– JOIN å…³ç³»"""
        if not context:
            return "ï¼ˆæ— ï¼‰"

        join_hints = context.get("join_hints", [])
        if not join_hints:
            return "ï¼ˆæ— ï¼‰"

        lines = []
        for j in join_hints:
            lines.append(
                f"- {j.get('left_table')}.{j.get('left_column')} = "
                f"{j.get('right_table')}.{j.get('right_column')}"
            )

        return "\n".join(lines)

    @staticmethod
    def _clean_sql(content: str) -> str:
        """æ¸…ç† SQLï¼ˆå»æ‰ markdown ä»£ç å—ï¼‰"""
        import re

        # æå– SQL ä»£ç å—
        sql_match = re.search(r'```sql\s*([\s\S]*?)\s*```', content)
        if sql_match:
            return sql_match.group(1).strip()

        # æå–æ™®é€šä»£ç å—
        code_match = re.search(r'```\s*([\s\S]*?)\s*```', content)
        if code_match:
            return code_match.group(1).strip()

        return content.strip()
