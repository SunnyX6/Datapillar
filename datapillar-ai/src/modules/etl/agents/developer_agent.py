"""
Developer Agentï¼ˆæ•°æ®å¼€å‘ï¼‰

èŒè´£ï¼šä¸ºæ¯ä¸ª Job çš„ Stage ç”Ÿæˆ SQL
- æŒ‰ Job å¤„ç†ï¼Œæ¯ä¸ª Job åŒ…å«å¤šä¸ª Stage
- ä¸ºæ¯ä¸ª Stage ç”Ÿæˆ SQL
- å°†æ‰€æœ‰ Stage çš„ SQL ç»„åˆæˆå®Œæ•´è„šæœ¬
- é€šè¿‡å·¥å…·è·å–è¡¨ç»“æ„ã€åˆ—çº§è¡€ç¼˜ã€å†å² SQLï¼ˆç²¾å‡†åŒ¹é…ï¼‰
"""

import json
import logging
import re
import uuid

from langchain_core.messages import AIMessage, HumanMessage, SystemMessage, ToolMessage
from langgraph.types import Command

from src.infrastructure.llm.client import call_llm
from src.modules.etl.schemas.kg_context import AgentScopedContext, AgentType
from src.modules.etl.schemas.plan import Job, Stage, Workflow
from src.modules.etl.schemas.requests import BlackboardRequest
from src.modules.etl.schemas.state import AgentState
from src.modules.etl.tools.agent_tools import (
    get_table_columns,
    get_column_lineage,
    get_sql_by_lineage,
    get_column_value_domain,
    recommend_guidance,
)

logger = logging.getLogger(__name__)


DEVELOPER_AGENT_SYSTEM_INSTRUCTIONS = """ä½ æ˜¯ Datapillar çš„ DeveloperAgentï¼ˆæ•°æ®å¼€å‘ï¼‰ã€‚

## ä»»åŠ¡
æ ¹æ®â€œä»»åŠ¡å‚æ•° JSONâ€å’Œâ€œçŸ¥è¯†ä¸Šä¸‹æ–‡ JSONâ€ï¼Œä¸ºæŒ‡å®š Job ç”Ÿæˆå®Œæ•´ SQL è„šæœ¬ã€‚

## ä»»åŠ¡å‚æ•°ï¼ˆç³»ç»Ÿæ³¨å…¥ï¼Œä¸æ˜¯ç”¨æˆ·è¾“å…¥ï¼‰
ç³»ç»Ÿä¼šæä¾›ä¸€æ®µâ€œä»»åŠ¡å‚æ•° JSONâ€ï¼ˆSystemMessageï¼‰ï¼Œå…¶ä¸­åŒ…å«ï¼š
- user_queryï¼šç”¨æˆ·åŸå§‹éœ€æ±‚ï¼ˆä»…ç”¨äºç†è§£ä¸šåŠ¡ï¼‰
- current_jobï¼šæœ¬æ¬¡éœ€è¦ç”Ÿæˆ SQL çš„ Jobï¼ˆå« stagesï¼‰
- evidenceï¼šå·²é€šè¿‡å·¥å…·è·å–çš„è¯æ®ï¼ˆè¡¨ç»“æ„/åˆ—çº§è¡€ç¼˜/å†å² SQLï¼‰
- tools_descriptionï¼šå¯ç”¨å·¥å…·è¯´æ˜
- test_feedbackï¼šä¸Šä¸€è½®æµ‹è¯•åé¦ˆï¼ˆå¦‚æœ‰ï¼‰

## çŸ¥è¯†ä¸Šä¸‹æ–‡ï¼ˆç³»ç»Ÿæ³¨å…¥ï¼Œä¸æ˜¯ç”¨æˆ·è¾“å…¥ï¼‰
ç³»ç»Ÿä¼šæä¾›ä¸€æ®µâ€œçŸ¥è¯†ä¸Šä¸‹æ–‡ JSONâ€ï¼ˆSystemMessageï¼‰ï¼Œå…¶ä¸­åŒ…å«ï¼š
- tablesï¼šå¯ç”¨çš„ schema.table åˆ—è¡¨ï¼ˆå¯¼èˆªæŒ‡é’ˆï¼‰
- etl_pointersï¼šå¯éªŒè¯çš„ ETL æŒ‡é’ˆï¼ˆå« qualified_name/element_id/toolsï¼‰
- allowlist_toolsï¼šä½ å…è®¸è°ƒç”¨çš„å·¥å…·ååˆ—è¡¨

ä½ å¿…é¡»æŠŠè¯¥ JSON è§†ä¸ºå”¯ä¸€å¯ä¿¡çŸ¥è¯†å…¥å£ï¼š
- ç¦æ­¢è‡†é€ ä»»ä½• schema.table
- å·¥å…·è°ƒç”¨åªèƒ½ä½¿ç”¨è¯¥ JSON ä¸­å‡ºç°çš„è¡¨æŒ‡é’ˆï¼ˆæŒ‰ qualified_name ç²¾ç¡®åŒ¹é…ï¼‰
- ä»…å½“ ETLPointer.tools åŒ…å«å·¥å…·åæ—¶ï¼Œæ‰å…è®¸å¯¹è¯¥è¡¨è°ƒç”¨è¯¥å·¥å…·

## ç”Ÿæˆè¦æ±‚ï¼ˆä¸¥æ ¼ï¼‰

### 1. åˆ—åˆ«åè§„èŒƒï¼ˆä¸¥æ ¼æ‰§è¡Œï¼‰
æ‰€æœ‰ SELECT å­—æ®µå¿…é¡»ä½¿ç”¨ AS åˆ«åï¼š
- æ™®é€šå­—æ®µï¼š`t.order_id AS order_id`
- è®¡ç®—å­—æ®µï¼š`t.amount * 2 AS double_amount`
- èšåˆå‡½æ•°ï¼š`SUM(t.amount) AS total_amount`
- ä¸å…è®¸æ— åˆ«åå­—æ®µï¼š`t.order_id` âŒ â†’ `t.order_id AS order_id` âœ…

ç›®æ ‡è¡¨åˆ—å¯¹é½ï¼š
- SELECT çš„åˆ«åå¿…é¡»ä¸ç›®æ ‡è¡¨åˆ—åå®Œå…¨ä¸€è‡´
- ä¾‹ï¼šç›®æ ‡è¡¨æœ‰åˆ— `adjusted_amount` â†’ å†™ `t.amount AS adjusted_amount`

ä¸´æ—¶è¡¨åˆ—å¼•ç”¨ï¼š
- ä¸´æ—¶è¡¨çš„ SELECT åˆ—å¿…é¡»å…¨éƒ¨æœ‰æ˜ç¡®åˆ«å
- åç»­ Stage é€šè¿‡åˆ«åå¼•ç”¨ä¸´æ—¶è¡¨åˆ—

### 2. ä¸´æ—¶è¡¨è§„èŒƒ
- åˆ›å»ºä¸´æ—¶è¡¨å‰å¿…é¡»å…ˆåˆ é™¤ï¼š`DROP TABLE IF EXISTS temp.xxx;` ç„¶åå† `CREATE TABLE temp.xxx AS ...`
- ä¸´æ—¶è¡¨å¿…é¡»æ”¾åœ¨ temp åº“ä¸‹ï¼Œæ ¼å¼ä¸º `temp.tmp_<æè¿°æ€§åç§°>`

### 3. å‚è€ƒè¯æ®ï¼ˆä¸¥æ ¼ï¼‰
- å¿…é¡»å‚è€ƒå†å² SQL ä¸­çš„ JOIN æ¡ä»¶ï¼Œä¸è¦è‡ªå·±çŒœæµ‹å…³è”å­—æ®µ
- å‚è€ƒåˆ—çº§è¡€ç¼˜ä¸­çš„å­—æ®µæ˜ å°„å…³ç³»ï¼Œç¡®ä¿å­—æ®µè½¬æ¢æ­£ç¡®
- ä¿æŒä¸å†å² SQL ç›¸åŒçš„å†™æ³•é£æ ¼

### 4. è¾“å‡ºæ ¼å¼å‚è€ƒï¼ˆä»…ç¤ºä¾‹ï¼‰
```sql
-- Stage 1: xxx
DROP TABLE IF EXISTS temp.tmp_step1;
CREATE TABLE temp.tmp_step1 AS
SELECT
    t.order_id AS order_id,
    t.user_id AS user_id,
    t.amount AS amount,
    SUM(t.amount) AS total_amount
FROM source_table t
GROUP BY t.order_id, t.user_id, t.amount;

-- Stage 2: xxx
INSERT OVERWRITE TABLE schema.target_table
SELECT
    tmp.order_id AS order_id,
    tmp.user_id AS user_id,
    tmp.total_amount AS total_amount
FROM temp.tmp_step1 tmp;
```

åªè¾“å‡º SQLï¼Œä¸è¦è§£é‡Šã€‚
"""


class DeveloperAgent:
    """
    æ•°æ®å¼€å‘

    èŒè´£ï¼š
    1. è¯»å–æ¯ä¸ª Job ä¸­çš„ Stage ä¿¡æ¯
    2. é€šè¿‡å·¥å…·è·å–è¡¨ç»“æ„ã€åˆ—çº§è¡€ç¼˜ã€å‚è€ƒ SQL
    3. ä¸ºæ¯ä¸ª Stage ç”Ÿæˆ SQL
    4. å°†æ‰€æœ‰ Stage SQL ç»„åˆä¸ºå®Œæ•´è„šæœ¬
    5. è®°å½•å‚è€ƒçš„ SQL IDï¼Œç”¨äºåç»­æ‰“åˆ†
    """

    def __init__(self):
        self.llm = call_llm(temperature=0.0)
        self.max_retries = 2
        self.max_tool_calls = 6
        # è®°å½•æœ¬æ¬¡å‚è€ƒçš„ SQL ID
        self._referenced_sql_ids: list[str] = []

    async def __call__(self, state: AgentState) -> Command:
        """æ‰§è¡Œ SQL ç”Ÿæˆ"""
        architecture_plan = state.architecture_plan
        test_result = state.test_result

        # æ¸…ç©ºå‚è€ƒ SQL ID åˆ—è¡¨ï¼ˆæ¯æ¬¡æ‰§è¡Œé‡æ–°æ”¶é›†ï¼‰
        self._referenced_sql_ids = []

        if not architecture_plan:
            req = BlackboardRequest(
                request_id=f"req_{uuid.uuid4().hex}",
                kind="delegate",
                created_by="developer_agent",
                target_agent="architect_agent",
                resume_to="developer_agent",
                payload={
                    "type": "need_architecture_plan",
                    "message": "SQL ç”Ÿæˆéœ€è¦æ¶æ„æ–¹æ¡ˆï¼Œå·²å§”æ´¾æ•°æ®æ¶æ„å¸ˆå…ˆå®Œæˆå·¥ä½œæµè®¾è®¡ã€‚",
                },
            )
            pending = list(state.pending_requests or [])
            pending.append(req)
            return Command(
                update={
                    "messages": [AIMessage(content="ç¼ºå°‘æ¶æ„æ–¹æ¡ˆï¼Œå·²å§”æ´¾æ•°æ®æ¶æ„å¸ˆ")],
                    "current_agent": "developer_agent",
                    "pending_requests": [r.model_dump() for r in pending],
                }
            )

        # æ£€æŸ¥æ˜¯å¦æ˜¯è¿­ä»£ï¼ˆæœ‰æµ‹è¯•åé¦ˆï¼‰
        is_iteration = test_result is not None
        if is_iteration:
            logger.info("ğŸ’» DeveloperAgent æ ¹æ®æµ‹è¯•åé¦ˆé‡æ–°ç”Ÿæˆ SQL")
        else:
            logger.info("ğŸ’» DeveloperAgent å¼€å§‹ç”Ÿæˆ SQL")

        # è·å–ä¸Šä¸‹æ–‡
        agent_context = state.get_agent_context(AgentType.DEVELOPER)

        if not agent_context:
            agent_context = AgentScopedContext.create_for_agent(
                agent_type=AgentType.DEVELOPER,
                tables=[],
            )
        context_payload = self._build_context_payload(agent_context=agent_context)

        # è½¬æ¢ä¸º Workflow
        if isinstance(architecture_plan, dict):
            plan = Workflow(**architecture_plan)
        else:
            plan = architecture_plan

        allowed_tables = self._build_allowed_tables(agent_context.etl_pointers)
        unknown_tables = self._find_unknown_tables(plan, allowed_tables=allowed_tables)
        if unknown_tables:
            counters = dict(state.delegation_counters or {})
            counter_key = "developer_agent:delegate:knowledge_agent:unknown_tables"
            delegated = int(counters.get(counter_key) or 0)
            if delegated < 1:
                counters[counter_key] = delegated + 1
                req = BlackboardRequest(
                    request_id=f"req_{uuid.uuid4().hex}",
                    kind="delegate",
                    created_by="developer_agent",
                    target_agent="knowledge_agent",
                    resume_to="developer_agent",
                    payload={
                        "type": "refresh_knowledge",
                        "reason": "unknown_tables",
                        "unknown_tables": unknown_tables,
                        "message": "SQL ç”Ÿæˆé˜¶æ®µå‘ç°æœªçŸ¥è¡¨ï¼Œå·²å§”æ´¾çŸ¥è¯†æ£€ç´¢åˆ·æ–°ä¸Šä¸‹æ–‡åå†ç»§ç»­ã€‚",
                    },
                )
                pending = list(state.pending_requests or [])
                pending.append(req)
                return Command(
                    update={
                        "messages": [AIMessage(content="æ£€æµ‹åˆ°æœªçŸ¥è¡¨ï¼Œå·²å§”æ´¾çŸ¥è¯†æ£€ç´¢åˆ·æ–°ä¸Šä¸‹æ–‡")],
                        "current_agent": "developer_agent",
                        "pending_requests": [r.model_dump() for r in pending],
                        "delegation_counters": counters,
                    }
                )
            request_id = f"req_{uuid.uuid4().hex}"
            guidance = await self._try_recommend_guidance(state.user_input)
            payload = {
                "type": "clarification",
                "message": "SQL ç”Ÿæˆæ— æ³•ç»§ç»­ï¼šçŸ¥è¯†åº“æ— æ³•å®šä½æ¶æ„æ–¹æ¡ˆä¸­å¼•ç”¨çš„è¡¨ï¼Œè¯·è¡¥å……å¯éªŒè¯çº¿ç´¢ã€‚",
                "questions": [
                    f"è¯·ç¡®è®¤è¿™äº›è¡¨çš„å‡†ç¡®åç§°ï¼ˆæ¨è schema.tableï¼‰ï¼š{', '.join(unknown_tables[:12])}",
                    "å¦‚æœä½ ä¸ç¡®å®šè¡¨åï¼šè¯·ç²˜è´´ç°æœ‰ SQL/DDL/å­—æ®µæ¸…å•ï¼Œæˆ–è¯´æ˜ä¸Šæ¸¸æ¥æºç³»ç»Ÿä¸ç›®æ ‡è¡¨ã€‚",
                ],
            }
            if guidance:
                payload["guidance"] = guidance
            req = BlackboardRequest(
                request_id=request_id,
                kind="human",
                created_by="developer_agent",
                resume_to="blackboard_router",
                payload=payload,
            )
            pending = list(state.pending_requests or [])
            pending.append(req)
            return Command(
                update={
                    "messages": [AIMessage(content="æ— æ³•å®šä½è¡¨æŒ‡é’ˆï¼šéœ€è¦ä½ è¡¥å……ä¸Šä¸‹æ–‡ä¿¡æ¯åæ‰èƒ½ç»§ç»­")],
                    "current_agent": "developer_agent",
                    "pending_requests": [r.model_dump() for r in pending],
                    "delegation_counters": counters,
                }
            )

        all_errors: list[str] = []
        generated_count = 0

        try:
            # æŒ‰æ‹“æ‰‘é¡ºåºå¤„ç† Job
            sorted_jobs = plan.topological_sort()

            for job in sorted_jobs:
                if not job.stages:
                    all_errors.append(f"Job {job.id} æ²¡æœ‰ Stage ä¿¡æ¯")
                    break  # æœ‰é”™è¯¯ç«‹å³åœæ­¢

                # è·å–ä¸Šä¸€è½®ç”Ÿæˆçš„ SQLï¼ˆå¦‚æœæœ‰ï¼‰
                previous_sql = job.config.get("content") if job.config else None

                # æ ¼å¼åŒ–æµ‹è¯•åé¦ˆï¼ˆå¸¦ä¸Šé”™è¯¯ SQLï¼‰
                job_test_feedback = self._format_test_feedback(test_result, previous_sql)

                # ä¸ºæ•´ä¸ª Job ç”Ÿæˆ SQL è„šæœ¬
                sql_script, success, errors = await self._generate_job_sql(
                    user_query=state.user_input,
                    job=job,
                    agent_context=agent_context,
                    context_payload=context_payload,
                    test_feedback=job_test_feedback,
                )

                if success:
                    # æ›´æ–° Job é…ç½®
                    job.config = {"content": sql_script}
                    job.config_generated = True
                    generated_count += 1
                    logger.info(f"âœ… Job {job.id} SQL ç”ŸæˆæˆåŠŸ ({len(job.stages)} ä¸ª Stage)")
                else:
                    all_errors.extend(errors)
                    logger.error(f"âŒ Job {job.id} SQL ç”Ÿæˆå¤±è´¥: {errors}")
                    break  # æœ‰é”™è¯¯ç«‹å³åœæ­¢ï¼Œä¸ç»§ç»­ç”Ÿæˆ

            # éƒ¨åˆ†æˆåŠŸ = æ•´ä½“å¤±è´¥
            if all_errors or generated_count < len(sorted_jobs):
                logger.error(f"âŒ DeveloperAgent å¤±è´¥: {generated_count}/{len(sorted_jobs)} æˆåŠŸ")
                return Command(
                    update={
                        "messages": [AIMessage(content=f"SQL ç”Ÿæˆå¤±è´¥: {all_errors[0] if all_errors else 'éƒ¨åˆ† Job æœªç”Ÿæˆ'}")],
                        "architecture_plan": plan.model_dump(),
                        "current_agent": "developer_agent",
                        "test_result": None,
                        "error": "\n".join(all_errors) if all_errors else "éƒ¨åˆ† Job ç”Ÿæˆå¤±è´¥",
                    }
                )

            logger.info(f"âœ… DeveloperAgent å®Œæˆ: å…¨éƒ¨ {generated_count} ä¸ª Job æˆåŠŸ")

            # è®°å½•å‚è€ƒçš„ SQL IDï¼ˆå»é‡ï¼‰
            unique_sql_ids = list(set(self._referenced_sql_ids))
            if unique_sql_ids:
                logger.info(f"ğŸ“ å‚è€ƒäº† {len(unique_sql_ids)} ä¸ªå†å² SQL: {unique_sql_ids}")

            return Command(
                update={
                    "messages": [AIMessage(content=f"SQL ç”Ÿæˆå®Œæˆ: {generated_count} ä¸ª Job")],
                    "architecture_plan": plan.model_dump(),
                    "current_agent": "developer_agent",
                    "test_result": None,
                    "referenced_sql_ids": unique_sql_ids,
                }
            )

        except Exception as e:
            logger.error(f"DeveloperAgent ç”Ÿæˆå¤±è´¥: {e}", exc_info=True)
            return Command(
                update={
                    "messages": [AIMessage(content=f"SQL ç”Ÿæˆå¤±è´¥: {str(e)}")],
                    "current_agent": "developer_agent",
                    "error": str(e),
                }
            )

    def _format_test_feedback(self, test_result, previous_sql: str | None = None) -> str:
        """æ ¼å¼åŒ–æµ‹è¯•åé¦ˆï¼ˆåŒ…å«ä¸Šä¸€è½®é”™è¯¯ SQLï¼‰"""
        if not test_result:
            return ""

        # è§£æ test_result
        if isinstance(test_result, dict):
            validation_errors = test_result.get("validation_errors", [])
            failed_tests = test_result.get("failed_tests", 0)
            notes = test_result.get("notes", "")
        else:
            validation_errors = getattr(test_result, "validation_errors", [])
            failed_tests = getattr(test_result, "failed_tests", 0)
            notes = getattr(test_result, "notes", "")

        if not validation_errors and failed_tests == 0:
            return ""

        lines = ["\n## âš ï¸ ä¸Šä¸€è½®æµ‹è¯•åé¦ˆï¼ˆå¿…é¡»ä¿®å¤ï¼‰\n"]

        if failed_tests > 0:
            lines.append(f"å¤±è´¥æµ‹è¯•æ•°: {failed_tests}\n")

        if validation_errors:
            lines.append("### é”™è¯¯åˆ—è¡¨")
            for error in validation_errors:
                lines.append(f"- {error}")

        # å±•ç¤ºä¸Šä¸€è½®é”™è¯¯çš„ SQLï¼Œè®© LLM çŸ¥é“ä¸è¦å†è¿™æ ·å†™
        if previous_sql:
            lines.append("\n### ä¸Šä¸€è½®ç”Ÿæˆçš„é”™è¯¯ SQLï¼ˆä¸è¦é‡å¤è¿™äº›é”™è¯¯ï¼ï¼‰")
            lines.append(f"```sql\n{previous_sql[:1500]}\n```")

        if notes:
            lines.append(f"\nå¤‡æ³¨: {notes}")

        lines.append("")
        return "\n".join(lines)

    @staticmethod
    async def _try_recommend_guidance(user_query: str) -> dict | None:
        """
        no-hit/éœ€æ¾„æ¸…åœºæ™¯çš„è½»é‡å¼•å¯¼æ•°æ®ï¼ˆtag/catalog å¯¼èˆªï¼‰

        çº¦æŸï¼š
        - åªè¿”å›å¯¼èˆªä¿¡æ¯ï¼Œä¸è¿”å› element_id/æŒ‡é’ˆ
        - å¤±è´¥æ—¶é™é»˜é™çº§ï¼Œä¸å½±å“ä¸»é“¾è·¯
        """
        try:
            raw = await recommend_guidance.ainvoke({"user_query": user_query})
            parsed = json.loads(raw or "")
            if isinstance(parsed, dict) and parsed.get("status") == "success":
                return parsed
            return None
        except Exception:
            return None

    async def _generate_job_sql(
        self,
        *,
        user_query: str,
        job: Job,
        agent_context: AgentScopedContext,
        context_payload: dict,
        test_feedback: str = "",
    ) -> tuple[str, bool, list[str]]:
        """ä¸ºæ•´ä¸ª Job ç”Ÿæˆ SQL è„šæœ¬ï¼ˆé€šè¿‡å·¥å…·è·å–çŸ¥è¯†ï¼‰"""
        # æ”¶é›†æŒä¹…åŒ–è¾“å…¥è¡¨ï¼ˆè·³è¿‡ä¸´æ—¶è¡¨ï¼Œä¸´æ—¶è¡¨åœ¨ temp åº“ä¸‹ï¼‰
        all_input_tables = set(job.input_tables or [])
        output_table = job.output_table

        # é€šè¿‡å·¥å…·è·å–è¡¨ç»“æ„
        table_schemas = await self._get_table_schemas_via_tool(list(all_input_tables), agent_context=agent_context)

        # é€šè¿‡å·¥å…·è·å–åˆ—çº§è¡€ç¼˜
        column_lineage = await self._get_column_lineage_via_tool(
            list(all_input_tables), output_table, agent_context=agent_context
        )

        # é€šè¿‡å·¥å…·ç²¾å‡†åŒ¹é…å†å² SQLï¼ˆæ ¹æ®è¡€ç¼˜å…³ç³»ï¼‰
        reference_sql = await self._get_reference_sql_via_tool(
            list(all_input_tables), output_table, agent_context=agent_context
        )

        # æ ¼å¼åŒ– Stage ä¿¡æ¯ï¼ˆç”¨äºæ¨¡å‹å¿«é€Ÿæ‰«è¯»ï¼›ç»“æ„åŒ–æ•°æ®ä»åœ¨ task_payload.current_job.stagesï¼‰
        stages_info = self._format_stages(job.stages)

        for attempt in range(self.max_retries):
            try:
                task_payload = {
                    "user_query": user_query,
                    "current_job": {
                        "id": job.id,
                        "name": job.name,
                        "description": job.description,
                        "type": job.type,
                        "input_tables": job.input_tables,
                        "output_table": job.output_table,
                        "stages_info": stages_info,
                        "stages": [
                            {
                                "stage_id": st.stage_id,
                                "name": st.name,
                                "description": st.description,
                                "input_tables": st.input_tables,
                                "output_table": st.output_table,
                                "is_temp_table": st.is_temp_table,
                            }
                            for st in sorted((job.stages or []), key=lambda s: s.stage_id)
                        ],
                    },
                    "evidence": {
                        "table_schemas": table_schemas,
                        "column_lineage": column_lineage,
                        "reference_sql": reference_sql,
                    },
                    "tools_description": agent_context.get_tools_description(),
                    "test_feedback": test_feedback,
                }

                # ä½¿ç”¨å¸¦å·¥å…·çš„ LLM ç”Ÿæˆ SQL
                sql = await self._generate_sql_with_tools(
                    user_query=user_query,
                    task_payload=task_payload,
                    agent_context=agent_context,
                    context_payload=context_payload,
                )

                if not sql or len(sql) < 20:
                    continue

                if not any(kw in sql.upper() for kw in ["SELECT", "INSERT", "CREATE"]):
                    continue

                return sql, True, []

            except Exception as e:
                logger.error(f"Job {job.id} SQL ç”Ÿæˆå¤±è´¥ (å°è¯• {attempt + 1}): {e}")

        return "", False, [f"Job {job.id} SQL ç”Ÿæˆå¤±è´¥"]

    async def _generate_sql_with_tools(
        self,
        *,
        user_query: str,
        task_payload: dict,
        agent_context: AgentScopedContext,
        context_payload: dict,
    ) -> str:
        """ä½¿ç”¨å·¥å…·ç”Ÿæˆ SQL"""
        llm_with_tools = self._bind_tools_by_allowlist(agent_context)
        messages = [
            SystemMessage(content=DEVELOPER_AGENT_SYSTEM_INSTRUCTIONS),
            SystemMessage(content=json.dumps(task_payload, ensure_ascii=False)),
            SystemMessage(content=json.dumps(context_payload, ensure_ascii=False)),
            HumanMessage(content=user_query),
        ]
        tool_call_count = 0

        while tool_call_count < self.max_tool_calls:
            response = await llm_with_tools.ainvoke(messages)
            messages.append(response)

            # å¦‚æœæ²¡æœ‰å·¥å…·è°ƒç”¨ï¼Œè¿”å› SQL
            if not response.tool_calls:
                return self._clean_sql(response.content)

            # æ‰§è¡Œå·¥å…·è°ƒç”¨
            for tool_call in response.tool_calls:
                tool_call_count += 1
                tool_name = tool_call["name"]
                tool_args = tool_call["args"]
                tool_id = tool_call["id"]

                logger.info(f"ğŸ”§ DeveloperAgent è°ƒç”¨å·¥å…·: {tool_name}({tool_args})")

                tool_result = await self._execute_tool(tool_name, tool_args, agent_context=agent_context)

                messages.append(
                    ToolMessage(content=tool_result, tool_call_id=tool_id)
                )

                if tool_call_count >= self.max_tool_calls:
                    break

        # è¾¾åˆ°æœ€å¤§å·¥å…·è°ƒç”¨æ¬¡æ•°ï¼Œè·å–æœ€ç»ˆå“åº”
        response = await self.llm.ainvoke(messages)
        return self._clean_sql(response.content)

    def _bind_tools_by_allowlist(self, agent_context: AgentScopedContext):
        """
        æŒ‰ allowlist åŠ¨æ€ç»‘å®šå·¥å…·ï¼Œé¿å…ç¡¬ç¼–ç å¯¼è‡´çš„â€œè¶Šæƒ/è¯¯å¯¼â€ã€‚

        è¯´æ˜ï¼š
        - bind_tools å†³å®š LLM èƒ½å¦å‘èµ·å·¥å…·è°ƒç”¨ï¼ˆèƒ½åŠ›é¢ï¼‰
        - allowlist å†³å®šè¯¥ Agent æ˜¯å¦å…è®¸è°ƒç”¨ï¼ˆæƒé™é¢ï¼‰
        """
        allowlist = set(agent_context.tools or [])
        tool_registry = {
            "get_table_columns": get_table_columns,
            "get_column_value_domain": get_column_value_domain,
            "get_column_lineage": get_column_lineage,
            "get_sql_by_lineage": get_sql_by_lineage,
        }
        tools = [tool_registry[name] for name in allowlist if name in tool_registry]
        return self.llm.bind_tools(tools)

    async def _execute_tool(self, tool_name: str, tool_args: dict, *, agent_context: AgentScopedContext) -> str:
        """æ‰§è¡Œå·¥å…·è°ƒç”¨"""
        try:
            allowlist = set(agent_context.tools or [])
            if tool_name not in allowlist:
                return json.dumps(
                    {"status": "error", "message": f"å·¥å…·ä¸åœ¨ allowlist ä¸­: {tool_name}"},
                    ensure_ascii=False,
                )

            table_index = self._build_allowed_table_index(agent_context.etl_pointers)
            column_index = self._build_allowed_column_index(agent_context.etl_pointers)

            if tool_name == "get_table_columns":
                table_name = (tool_args or {}).get("table_name") or ""
                pointer = table_index.get(table_name)
                if not pointer:
                    return json.dumps(
                        {
                            "status": "error",
                            "message": "ç¦æ­¢å¯¹æœªä¸‹å‘çš„è¡¨æŒ‡é’ˆè°ƒç”¨å·¥å…·",
                            "table_name": table_name,
                        },
                        ensure_ascii=False,
                    )
                if tool_name not in set(pointer.tools or []):
                    return json.dumps(
                        {
                            "status": "error",
                            "message": "è¯¥è¡¨æŒ‡é’ˆæœªæˆæƒæ­¤å·¥å…·ï¼ˆETLPointer.toolsï¼‰",
                            "table_name": table_name,
                            "pointer_element_id": pointer.element_id,
                        },
                        ensure_ascii=False,
                    )
                return await get_table_columns.ainvoke({"table_name": table_name})

            if tool_name == "get_column_value_domain":
                column_element_id = (tool_args or {}).get("column_element_id") or ""
                pointer = column_index.get(column_element_id)
                if not pointer:
                    return json.dumps(
                        {
                            "status": "error",
                            "message": "ç¦æ­¢å¯¹æœªä¸‹å‘çš„åˆ—æŒ‡é’ˆè°ƒç”¨å·¥å…·",
                            "column_element_id": column_element_id,
                        },
                        ensure_ascii=False,
                    )
                if tool_name not in set(pointer.tools or []):
                    return json.dumps(
                        {
                            "status": "error",
                            "message": "è¯¥åˆ—æŒ‡é’ˆæœªæˆæƒæ­¤å·¥å…·ï¼ˆETLPointer.toolsï¼‰",
                            "column_element_id": column_element_id,
                            "pointer_element_id": pointer.element_id,
                        },
                        ensure_ascii=False,
                    )
                return await get_column_value_domain.ainvoke({"column_element_id": column_element_id})

            if tool_name == "get_column_lineage":
                source_table = (tool_args or {}).get("source_table") or ""
                target_table = (tool_args or {}).get("target_table") or ""
                missing = [t for t in [source_table, target_table] if not table_index.get(t)]
                if missing:
                    return json.dumps(
                        {
                            "status": "error",
                            "message": "ç¦æ­¢å¯¹æœªä¸‹å‘çš„è¡¨æŒ‡é’ˆè°ƒç”¨å·¥å…·",
                            "tables": missing,
                        },
                        ensure_ascii=False,
                    )
                for t in [source_table, target_table]:
                    pointer = table_index[t]
                    if tool_name not in set(pointer.tools or []):
                        return json.dumps(
                            {
                                "status": "error",
                                "message": "è¯¥è¡¨æŒ‡é’ˆæœªæˆæƒæ­¤å·¥å…·ï¼ˆETLPointer.toolsï¼‰",
                                "table_name": t,
                                "pointer_element_id": pointer.element_id,
                            },
                            ensure_ascii=False,
                        )
                return await get_column_lineage.ainvoke({"source_table": source_table, "target_table": target_table})

            if tool_name == "get_sql_by_lineage":
                source_tables = (tool_args or {}).get("source_tables") or []
                target_table = (tool_args or {}).get("target_table") or ""
                if not isinstance(source_tables, list):
                    source_tables = []
                all_tables = list(source_tables) + ([target_table] if target_table else [])
                missing = [t for t in all_tables if t and not table_index.get(t)]
                if missing:
                    return json.dumps(
                        {
                            "status": "error",
                            "message": "ç¦æ­¢å¯¹æœªä¸‹å‘çš„è¡¨æŒ‡é’ˆè°ƒç”¨å·¥å…·",
                            "tables": missing,
                        },
                        ensure_ascii=False,
                    )
                for t in all_tables:
                    if not t:
                        continue
                    pointer = table_index[t]
                    if tool_name not in set(pointer.tools or []):
                        return json.dumps(
                            {
                                "status": "error",
                                "message": "è¯¥è¡¨æŒ‡é’ˆæœªæˆæƒæ­¤å·¥å…·ï¼ˆETLPointer.toolsï¼‰",
                                "table_name": t,
                                "pointer_element_id": pointer.element_id,
                            },
                            ensure_ascii=False,
                        )
                return await get_sql_by_lineage.ainvoke({"source_tables": source_tables, "target_table": target_table})

            return json.dumps({"status": "error", "message": f"æœªçŸ¥å·¥å…·: {tool_name}"}, ensure_ascii=False)
        except Exception as e:
            logger.error(f"å·¥å…· {tool_name} æ‰§è¡Œå¤±è´¥: {e}")
            return json.dumps({"status": "error", "message": str(e)}, ensure_ascii=False)

    def _format_stages(self, stages: list[Stage]) -> str:
        """æ ¼å¼åŒ– Stage åˆ—è¡¨"""
        lines = []
        for stage in sorted(stages, key=lambda s: s.stage_id):
            lines.append(f"### Stage {stage.stage_id}: {stage.name}")
            lines.append(f"- æè¿°: {stage.description}")
            lines.append(f"- è¾“å…¥è¡¨: {', '.join(stage.input_tables)}")
            lines.append(f"- è¾“å‡ºè¡¨: {stage.output_table}")
            lines.append(f"- æ˜¯å¦ä¸´æ—¶è¡¨: {stage.is_temp_table}")
            lines.append("")
        return "\n".join(lines)

    async def _get_table_schemas_via_tool(self, input_tables: list[str], *, agent_context: AgentScopedContext) -> str:
        """é€šè¿‡å·¥å…·è·å–è¡¨ç»“æ„ä¿¡æ¯"""
        lines = []

        for table_name in input_tables:
            try:
                result = await self._execute_tool(
                    "get_table_columns",
                    {"table_name": table_name},
                    agent_context=agent_context,
                )
                data = json.loads(result)

                if data.get("status") == "success":
                    columns = data.get("columns", [])
                    col_info = [
                        f"{c.get('name')} ({c.get('data_type', 'string')})"
                        for c in columns[:20]
                    ]
                    lines.append(f"### {table_name}")
                    lines.append(f"å­—æ®µ: {', '.join(col_info)}")
                    if len(columns) > 20:
                        lines.append(f"...å…± {len(columns)} ä¸ªå­—æ®µ")
                    lines.append("")
            except Exception as e:
                logger.warning(f"è·å–è¡¨ {table_name} ç»“æ„å¤±è´¥: {e}")

        return "\n".join(lines) if lines else "ï¼ˆæ— ï¼‰"

    async def _get_column_lineage_via_tool(
        self, input_tables: list[str], output_table: str | None, *, agent_context: AgentScopedContext
    ) -> str:
        """é€šè¿‡å·¥å…·è·å–åˆ—çº§è¡€ç¼˜ä¿¡æ¯"""
        if not output_table or not input_tables:
            return "ï¼ˆæ— ï¼‰"

        lines = []
        for source_table in input_tables:
            try:
                result = await self._execute_tool(
                    "get_column_lineage",
                    {"source_table": source_table, "target_table": output_table},
                    agent_context=agent_context,
                )
                data = json.loads(result)

                if data.get("status") == "success":
                    lineage = data.get("lineage", [])
                    if lineage:
                        lines.append(f"### {source_table} â†’ {output_table}")
                        for item in lineage:
                            mappings = item.get("column_mappings", [])
                            for m in mappings[:20]:
                                src_col = m.get("source_column", "")
                                tgt_col = m.get("target_column", "")
                                transform = m.get("transformation", "direct")
                                if src_col and tgt_col:
                                    lines.append(f"- {src_col} â†’ {tgt_col} ({transform})")
                        lines.append("")
            except Exception as e:
                logger.warning(f"è·å–åˆ—çº§è¡€ç¼˜å¤±è´¥ {source_table} â†’ {output_table}: {e}")

        return "\n".join(lines) if lines else "ï¼ˆæ— ï¼‰"

    async def _get_reference_sql_via_tool(
        self, input_tables: list[str], output_table: str | None, *, agent_context: AgentScopedContext
    ) -> str:
        """é€šè¿‡å·¥å…·ç²¾å‡†åŒ¹é…å†å² SQLï¼ˆæ ¹æ®è¡€ç¼˜å…³ç³»ï¼‰"""
        if not input_tables or not output_table:
            return "ï¼ˆæ— å†å² SQLï¼‰"

        try:
            result = await self._execute_tool(
                "get_sql_by_lineage",
                {"source_tables": input_tables, "target_table": output_table},
                agent_context=agent_context,
            )
            data = json.loads(result)

            if data.get("status") == "success":
                sql_content = data.get("sql_content")
                sql_id = data.get("sql_id")

                # è®°å½•å‚è€ƒçš„ SQL IDï¼ˆç”¨äºåç»­æ‰“åˆ†ï¼‰
                if sql_id:
                    self._referenced_sql_ids.append(sql_id)
                    logger.info(f"ğŸ“Œ å‚è€ƒå†å² SQL: {sql_id}")

                if sql_content:
                    sql_name = data.get("sql_name", "")
                    engine = data.get("engine", "")
                    return f"""### å†å² SQLï¼ˆ{sql_name}ï¼Œå¼•æ“: {engine}ï¼‰
ç›´æ¥å‚è€ƒæ­¤ SQL çš„ JOIN æ¡ä»¶å’Œå†™æ³•é£æ ¼ï¼

```sql
{sql_content}
```
"""

        except Exception as e:
            logger.warning(f"è·å–å†å² SQL å¤±è´¥: {e}")

        return "ï¼ˆæ— å†å² SQLï¼‰"

    @staticmethod
    def _build_context_payload(*, agent_context: AgentScopedContext) -> dict:
        """
        æ„é€ â€œçŸ¥è¯†ä¸Šä¸‹æ–‡JSONâ€ï¼ˆä¸‹å‘ç»™ LLM çš„ SystemMessageï¼‰

        çº¦æŸï¼š
        - åªä¼ é€’æŒ‡é’ˆä¸å¯¼èˆªä¿¡æ¯ï¼Œä¸ä¼ é€’è¡¨æ˜ç»†
        """
        node_pointers = agent_context.etl_pointers or []
        table_pointers = [
            {
                "element_id": p.element_id,
                "qualified_name": p.qualified_name,
                "path": p.path,
                "display_name": p.display_name,
                "description": p.description,
                "tools": p.tools,
            }
            for p in node_pointers
            if "Table" in set(p.labels or []) and p.qualified_name
        ]
        return {
            "agent_type": agent_context.agent_type,
            "allowlist_tools": agent_context.tools,
            "tables": agent_context.tables,
            "table_pointers": table_pointers,
            "etl_pointers": [p.model_dump() for p in node_pointers],
            "doc_pointers": [p.model_dump() for p in (agent_context.doc_pointers or [])],
        }

    @staticmethod
    def _build_allowed_table_index(node_pointers) -> dict:
        table_index: dict[str, object] = {}
        for p in node_pointers or []:
            if "Table" not in set(getattr(p, "labels", None) or []):
                continue
            qualified_name = getattr(p, "qualified_name", None)
            if not qualified_name:
                continue
            table_index[qualified_name] = p
        return table_index

    @staticmethod
    def _build_allowed_column_index(node_pointers) -> dict:
        column_index: dict[str, object] = {}
        for p in node_pointers or []:
            if "Column" not in set(getattr(p, "labels", None) or []):
                continue
            element_id = getattr(p, "element_id", None)
            if element_id:
                column_index[element_id] = p
        return column_index

    @staticmethod
    def _build_allowed_tables(node_pointers) -> set[str]:
        allowed: set[str] = set()
        for p in node_pointers or []:
            if "Table" not in set(getattr(p, "labels", None) or []):
                continue
            qualified_name = getattr(p, "qualified_name", None)
            if qualified_name:
                allowed.add(qualified_name)
        return allowed

    @staticmethod
    def _find_unknown_tables(plan: Workflow, *, allowed_tables: set[str]) -> list[str]:
        unknown: list[str] = []
        seen: set[str] = set()
        for job in plan.jobs or []:
            for t in job.input_tables or []:
                if not t or t.startswith("temp."):
                    continue
                if t not in allowed_tables and t not in seen:
                    seen.add(t)
                    unknown.append(t)
            if job.output_table and not job.output_table.startswith("temp."):
                t = job.output_table
                if t not in allowed_tables and t not in seen:
                    seen.add(t)
                    unknown.append(t)
        return unknown

    @staticmethod
    def _clean_sql(content: str) -> str:
        """æ¸…ç† SQLï¼ˆå»æ‰ markdown ä»£ç å—ï¼‰"""
        sql_match = re.search(r'```sql\s*([\s\S]*?)\s*```', content)
        if sql_match:
            return sql_match.group(1).strip()

        code_match = re.search(r'```\s*([\s\S]*?)\s*```', content)
        if code_match:
            return code_match.group(1).strip()

        return content.strip()
