"""
Analyst Agentï¼ˆéœ€æ±‚åˆ†æå¸ˆï¼‰

èŒè´£ï¼šä¸šåŠ¡å±‚é¢çš„éœ€æ±‚åˆ†æä¸æ”¶æ•›
- å°†ç”¨æˆ·éœ€æ±‚æ‹†åˆ†ä¸ºä¸šåŠ¡æ­¥éª¤ï¼ˆStepï¼‰
- åŸºäºçŸ¥è¯†åº“éªŒè¯éœ€æ±‚çš„å¯è¡Œæ€§
- éœ€æ±‚å¿…é¡»åœ¨æ­¤é˜¶æ®µæ”¶æ•›æ¸…æ¥šï¼Œä¸å…è®¸æ¨¡ç³Šéœ€æ±‚å¾€åä¼ 
- é€šè¿‡å·¥å…·éªŒè¯è¡¨æ˜¯å¦å­˜åœ¨
"""

import json
import logging

from langchain_core.messages import ToolMessage

from src.infrastructure.llm.client import call_llm
from src.modules.etl.agents.knowledge_agent import AgentType, get_agent_tools
from src.modules.etl.agents.prompt_messages import build_llm_messages
from src.modules.etl.schemas.agent_result import AgentResult
from src.modules.etl.schemas.requirement import Ambiguity, AnalysisResult, DataTarget, Step
from src.modules.etl.tools.agent_tools import get_table_columns, recommend_guidance

logger = logging.getLogger(__name__)


def _tool_error(message: str, **extra: object) -> str:
    """æ„é€ å·¥å…·é”™è¯¯å“åº”"""
    payload: dict[str, object] = {"status": "error", "message": message}
    payload.update(extra)
    return json.dumps(payload, ensure_ascii=False)


ANALYST_AGENT_SYSTEM_INSTRUCTIONS = """ä½ æ˜¯ Datapillar çš„ AnalystAgentï¼ˆéœ€æ±‚åˆ†æä¸æ”¶æ•›ï¼‰ã€‚

## ä»»åŠ¡
æŠŠç”¨æˆ·éœ€æ±‚æ”¶æ•›æˆå¯æ‰§è¡Œçš„ä¸šåŠ¡æ­¥éª¤ï¼ˆStepï¼‰ï¼Œè¾“å‡ºä¸¥æ ¼ JSONã€‚

## æ ¸å¿ƒåŸåˆ™
1. ä½ åªåš"åšä»€ä¹ˆ"ï¼ˆä¸šåŠ¡æ‹†è§£ï¼‰ï¼Œä¸åš"æ€ä¹ˆåš"ï¼ˆä¸å†™ SQLï¼Œä¸é€‰ç»„ä»¶ï¼Œä¸ç”» DAGï¼‰ã€‚
2. ä¸å…è®¸è‡†é€ è¡¨åï¼Œå¦‚æœä¸ç¡®å®šï¼Œå¿…é¡»æå‡ºæ¾„æ¸…é—®é¢˜ã€‚

## è¾“å‡ºæ ¼å¼
{{
  "summary": "ä¸€å¥è¯æ¦‚æ‹¬éœ€æ±‚ï¼ˆå¿…é¡»å…·ä½“ï¼Œä¸èƒ½æ¨¡ç³Šï¼‰",
  "steps": [
    {{
      "step_id": "step_1",
      "step_name": "ä¸šåŠ¡æ­¥éª¤åç§°",
      "description": "è¿™ä¸€æ­¥åšä»€ä¹ˆï¼ˆä¸šåŠ¡æè¿°ï¼‰",
      "input_tables": ["schema.table"],
      "output_table": "schema.table",
      "depends_on": []
    }}
  ],
  "final_target": {{
    "table_name": "æœ€ç»ˆç›®æ ‡è¡¨ï¼ˆå¿…é¡»æ˜ç¡®ï¼‰",
    "write_mode": "overwrite",
    "partition_by": ["dt"]
  }},
  "ambiguities": [
    {{
      "question": "éœ€è¦ç”¨æˆ·æ¾„æ¸…çš„å…·ä½“é—®é¢˜",
      "context": "ä¸ºä»€ä¹ˆéœ€è¦æ¾„æ¸…",
      "options": ["å¯èƒ½çš„é€‰é¡¹1", "å¯èƒ½çš„é€‰é¡¹2"]
    }}
  ],
  "confidence": 0.85
}}

é‡è¦ï¼š
- **å¿…é¡»è¾“å‡ºçº¯ JSON**ï¼šä¸å¾—è¾“å‡º Markdownã€ä¸å¾—è¾“å‡º ```json ä»£ç å—ã€ä¸å¾—è¾“å‡ºè§£é‡Šæ€§æ–‡å­—
- ambiguities ä¸­çš„æ¯æ¡ question å¿…é¡»å”¯ä¸€ï¼Œä¸å…è®¸åŒä¹‰é‡å¤
- å¦‚æœæ— æ³•æ˜ç¡® input_tables æˆ– output_tableï¼Œå¿…é¡»åœ¨ ambiguities ä¸­æé—®
- confidence åæ˜ éœ€æ±‚çš„æ˜ç¡®ç¨‹åº¦ï¼Œæ¨¡ç³Šéœ€æ±‚å¿…é¡» < 0.7

åªè¾“å‡º JSONï¼Œä¸è¦è§£é‡Šã€‚
"""


class AnalystAgent:
    """
    éœ€æ±‚åˆ†æå¸ˆ

    èŒè´£ï¼š
    1. åŸºäºçŸ¥è¯†åº“æ”¶æ•›ç”¨æˆ·éœ€æ±‚
    2. é€šè¿‡å·¥å…·éªŒè¯æ¶‰åŠçš„è¡¨æ˜¯å¦å­˜åœ¨
    3. éœ€æ±‚ä¸æ˜ç¡®æ—¶å¼ºåˆ¶è¦æ±‚æ¾„æ¸…
    4. ä¸å…è®¸æ¨¡ç³Šéœ€æ±‚å¾€åä¼ 
    """

    def __init__(self):
        self.llm = call_llm(temperature=0.0)
        self.llm_json = call_llm(temperature=0.0, enable_json_mode=True)
        self.max_tool_calls = 4
        self.allowlist = get_agent_tools(AgentType.ANALYST)

    async def run(
        self,
        *,
        user_query: str,
        knowledge_agent=None,
    ) -> AgentResult:
        """
        æ‰§è¡Œéœ€æ±‚åˆ†æ

        å‚æ•°ï¼š
        - user_query: ç”¨æˆ·è¾“å…¥
        - knowledge_agent: KnowledgeAgent å®ä¾‹ï¼ˆç”¨äºæŒ‰éœ€æŸ¥è¯¢æŒ‡é’ˆï¼‰

        è¿”å›ï¼š
        - AgentResult: æ‰§è¡Œç»“æœ
        """
        self._knowledge_agent = knowledge_agent

        if not user_query:
            return AgentResult.failed(
                summary="ç¼ºå°‘ç”¨æˆ·è¾“å…¥",
                error="ç¼ºå°‘ç”¨æˆ·è¾“å…¥ï¼Œæ— æ³•åˆ†æéœ€æ±‚",
            )

        logger.info(f"ğŸ“‹ AnalystAgent å¼€å§‹åˆ†æéœ€æ±‚: {user_query}")

        try:
            llm_with_tools = self._bind_tools()

            result_dict = await self._analyze_with_tools(
                user_query=user_query,
                llm_with_tools=llm_with_tools,
            )

            analysis_result = self._build_analysis_result(result_dict, user_query)

            plan_summary = analysis_result.plan_summary()
            logger.info(f"âœ… AnalystAgent å®Œæˆåˆ†æ:\n{plan_summary}")

            if analysis_result.needs_clarification() or analysis_result.confidence < 0.7:
                questions = [a.question for a in analysis_result.ambiguities if a.question]
                if not questions:
                    return AgentResult.failed(
                        summary="éœ€æ±‚æœªæ”¶æ•›ï¼ŒLLM æœªç”Ÿæˆæœ‰æ•ˆæ¾„æ¸…é—®é¢˜",
                        error="éœ€æ±‚æœªæ”¶æ•›ä¸” ambiguities ä¸ºç©º",
                    )
                guidance = await self._try_recommend_guidance(user_query)
                return AgentResult.needs_clarification(
                    summary="éœ€æ±‚ä¸å¤Ÿæ˜ç¡®ï¼Œéœ€è¦è¡¥å……å…³é”®ä¿¡æ¯",
                    message="è¯·å›ç­”ä»¥ä¸‹é—®é¢˜ä»¥ä¾¿ç»§ç»­åˆ†æ",
                    questions=questions,
                    guidance=guidance,
                )

            if not self._is_converged(analysis_result):
                return AgentResult.failed(
                    summary="éœ€æ±‚æœªæ”¶æ•›ï¼šç¼ºå°‘ steps æˆ– input/output æˆ– final_target",
                    error="éœ€æ±‚æœªæ”¶æ•›ï¼šè¾“å‡ºä¸æ»¡è¶³æ­¥éª¤/è¾“å…¥è¾“å‡º/ç›®æ ‡è¡¨ç­‰çº¦æŸ",
                )

            return AgentResult.completed(
                summary=f"éœ€æ±‚åˆ†æå®Œæˆ: {analysis_result.summary}",
                deliverable=analysis_result,
                deliverable_type="analysis",
            )

        except Exception as e:
            logger.error(f"AnalystAgent åˆ†æå¤±è´¥: {e}", exc_info=True)
            return AgentResult.failed(
                summary=f"éœ€æ±‚åˆ†æå¤±è´¥: {str(e)}",
                error=str(e),
            )

    @staticmethod
    async def _try_recommend_guidance(user_query: str) -> dict | None:
        """no-hit/éœ€æ¾„æ¸…åœºæ™¯çš„è½»é‡å¼•å¯¼æ•°æ®"""
        try:
            raw = await recommend_guidance.ainvoke({"user_query": user_query})
            parsed = json.loads(raw or "")
            if isinstance(parsed, dict) and parsed.get("status") == "success":
                return parsed
            return None
        except Exception:
            return None

    async def _analyze_with_tools(
        self,
        user_query: str,
        llm_with_tools,
    ) -> dict:
        """æ‰§è¡Œå¸¦å·¥å…·è°ƒç”¨çš„åˆ†æ"""
        messages = build_llm_messages(
            system_instructions=ANALYST_AGENT_SYSTEM_INSTRUCTIONS,
            agent_id="analyst_agent",
            user_query=user_query,
        )
        tool_call_count = 0

        while tool_call_count < self.max_tool_calls:
            response = await llm_with_tools.ainvoke(messages)
            messages.append(response)

            if not response.tool_calls:
                return self._parse_response(response.content)

            for tool_call in response.tool_calls:
                tool_call_count += 1
                tool_name = tool_call["name"]
                tool_args = tool_call["args"]
                tool_id = tool_call["id"]

                logger.info(f"ğŸ”§ AnalystAgent è°ƒç”¨å·¥å…·: {tool_name}({tool_args})")

                tool_result = await self._execute_tool(tool_name, tool_args)

                messages.append(ToolMessage(content=tool_result, tool_call_id=tool_id))

                if tool_call_count >= self.max_tool_calls:
                    break

        response = await self.llm_json.ainvoke(messages)
        return self._parse_response(response.content)

    async def _execute_tool(self, tool_name: str, tool_args: dict) -> str:
        """æ‰§è¡Œå·¥å…·è°ƒç”¨ï¼ˆæŒ‰éœ€è·å–æŒ‡é’ˆ + æƒé™æ ¡éªŒï¼‰"""
        try:
            if tool_name not in self.allowlist:
                return _tool_error(f"å·¥å…·ä¸åœ¨ allowlist ä¸­: {tool_name}")

            if not self._knowledge_agent:
                return _tool_error("æ— æ³•æŸ¥è¯¢æŒ‡é’ˆï¼šknowledge_agent æœªæ³¨å…¥")

            if tool_name == "get_table_columns":
                table_name = (tool_args or {}).get("table_name") or ""
                if not table_name:
                    return _tool_error("ç¼ºå°‘ table_name å‚æ•°")

                pointers = await self._knowledge_agent.query_pointers(
                    table_name,
                    node_types=["Table"],
                    top_k=5,
                )
                pointer = self._find_matching_pointer(pointers, table_name)
                if not pointer:
                    return _tool_error("æœªæ‰¾åˆ°æŒ‡é’ˆ", table_name=table_name)
                if "get_table_columns" not in (pointer.tools or []):
                    return _tool_error("æŒ‡é’ˆæœªæˆæƒæ­¤å·¥å…·", table_name=table_name)

                logger.info(f"ğŸ“Š è°ƒç”¨ get_table_columns: {pointer.qualified_name}")
                return await get_table_columns.ainvoke({"table_name": pointer.qualified_name})

            return _tool_error(f"æœªçŸ¥å·¥å…·: {tool_name}")
        except Exception as e:
            logger.error(f"å·¥å…· {tool_name} æ‰§è¡Œå¤±è´¥: {e}")
            return _tool_error(str(e))

    def _find_matching_pointer(self, pointers: list, name: str):
        """ä»æŒ‡é’ˆåˆ—è¡¨ä¸­æ‰¾åˆ°åŒ¹é…çš„æŒ‡é’ˆ"""
        if not pointers:
            return None
        for p in pointers:
            if p.qualified_name == name:
                return p
        for p in pointers:
            if name in (p.qualified_name or ""):
                return p
        return pointers[0] if pointers else None

    def _is_converged(self, analysis: AnalysisResult) -> bool:
        """åªåšç»“æ„æ€§æ”¶æ•›æ ¡éªŒ"""
        if not analysis.steps:
            return False
        for step in analysis.steps:
            if not step.input_tables:
                return False
            if not step.output_table:
                return False
        if not analysis.final_target:
            return False
        return bool(analysis.final_target.table_name)

    def _bind_tools(self):
        """ç»‘å®šå·¥å…·åˆ° LLM"""
        tool_registry = {
            "get_table_columns": get_table_columns,
        }
        tools = [tool_registry[name] for name in self.allowlist if name in tool_registry]
        return self.llm.bind_tools(tools)

    def _parse_response(self, content: str) -> dict:
        """ä¸¥æ ¼è§£æ LLM å“åº”"""
        text = (content or "").strip()
        try:
            parsed = json.loads(text)
        except json.JSONDecodeError as e:
            raise ValueError("LLM è¾“å‡ºä¸æ˜¯åˆæ³• JSON") from e
        if not isinstance(parsed, dict):
            raise ValueError("LLM è¾“å‡ºå¿…é¡»æ˜¯ JSON object")
        return parsed

    def _build_analysis_result(self, result_dict: dict, user_query: str) -> AnalysisResult:
        """æ„å»º AnalysisResult"""
        steps = []
        for step_dict in result_dict.get("steps", []):
            step = Step(
                step_id=step_dict.get("step_id", ""),
                step_name=step_dict.get("step_name", ""),
                description=step_dict.get("description", ""),
                input_tables=step_dict.get("input_tables", []),
                output_table=step_dict.get("output_table"),
                depends_on=step_dict.get("depends_on", []),
            )
            steps.append(step)

        ambiguities = []
        for amb_dict in result_dict.get("ambiguities", []):
            if isinstance(amb_dict, dict):
                ambiguities.append(
                    Ambiguity(
                        question=amb_dict.get("question", ""),
                        context=amb_dict.get("context"),
                        options=amb_dict.get("options", []),
                    )
                )
            elif isinstance(amb_dict, str):
                ambiguities.append(Ambiguity(question=amb_dict, context=None))

        final_target = None
        final_target_dict = result_dict.get("final_target")
        if final_target_dict and isinstance(final_target_dict, dict):
            final_target = DataTarget(
                table_name=final_target_dict.get("table_name", ""),
                write_mode=final_target_dict.get("write_mode", "overwrite"),
                partition_by=final_target_dict.get("partition_by", []),
                description=final_target_dict.get("description"),
            )

        return AnalysisResult(
            user_query=user_query,
            summary=result_dict.get("summary", ""),
            steps=steps,
            final_target=final_target,
            ambiguities=ambiguities,
            confidence=result_dict.get("confidence", 0.5),
        )
