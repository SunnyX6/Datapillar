"""
Analyst Agentï¼ˆéœ€æ±‚åˆ†æå¸ˆï¼‰

èŒè´£ï¼šä¸šåŠ¡å±‚é¢çš„éœ€æ±‚åˆ†æä¸æ”¶æ•›
- å°†ç”¨æˆ·éœ€æ±‚æ‹†åˆ†ä¸ºä¸šåŠ¡æ­¥éª¤ï¼ˆStepï¼‰
- åŸºäºçŸ¥è¯†åº“éªŒè¯éœ€æ±‚çš„å¯è¡Œæ€§
- éœ€æ±‚å¿…é¡»åœ¨æ­¤é˜¶æ®µæ”¶æ•›æ¸…æ¥šï¼Œä¸å…è®¸æ¨¡ç³Šéœ€æ±‚å¾€åä¼ 
- é€šè¿‡å·¥å…·éªŒè¯è¡¨æ˜¯å¦å­˜åœ¨
"""

import json
import logging
import uuid

from langchain_core.messages import AIMessage, HumanMessage, SystemMessage, ToolMessage
from langgraph.types import Command

from src.infrastructure.llm.client import call_llm
from src.modules.etl.schemas.kg_context import AgentScopedContext, AgentType, ETLPointer
from src.modules.etl.schemas.requirement import AnalysisResult, Ambiguity, DataTarget, Step
from src.modules.etl.schemas.requests import BlackboardRequest
from src.modules.etl.schemas.state import AgentState
from src.modules.etl.tools.agent_tools import get_table_columns, recommend_guidance

logger = logging.getLogger(__name__)


ANALYST_AGENT_SYSTEM_INSTRUCTIONS = """ä½ æ˜¯ Datapillar çš„ AnalystAgentï¼ˆéœ€æ±‚åˆ†æä¸æ”¶æ•›ï¼‰ã€‚

## ä»»åŠ¡
æŠŠç”¨æˆ·éœ€æ±‚æ”¶æ•›æˆå¯æ‰§è¡Œçš„ä¸šåŠ¡æ­¥éª¤ï¼ˆStepï¼‰ï¼Œè¾“å‡ºä¸¥æ ¼ JSONã€‚

## æ ¸å¿ƒåŸåˆ™
1. ä½ åªåšâ€œåšä»€ä¹ˆâ€ï¼ˆä¸šåŠ¡æ‹†è§£ï¼‰ï¼Œä¸åšâ€œæ€ä¹ˆåšâ€ï¼ˆä¸å†™ SQLï¼Œä¸é€‰ç»„ä»¶ï¼Œä¸ç”» DAGï¼‰ã€‚
2. ä½ å¿…é¡»åŸºäº KnowledgeAgent ä¸‹å‘çš„â€œETL æŒ‡é’ˆï¼ˆetl_pointers / ETLPointerï¼‰â€å®Œæˆè¡¨çº§æ”¶æ•›ã€‚
3. ä¸å…è®¸è‡†é€ ï¼šä½ åªèƒ½å¼•ç”¨ä¸Šä¸‹æ–‡ä¸­å·²ç»™å‡ºçš„è¡¨ï¼ˆschema.tableï¼‰ï¼Œå¦åˆ™å¿…é¡»æå‡ºæ¾„æ¸…é—®é¢˜ã€‚

## çŸ¥è¯†ä¸Šä¸‹æ–‡ï¼ˆç³»ç»Ÿæ³¨å…¥ï¼Œä¸æ˜¯ç”¨æˆ·è¾“å…¥ï¼‰
ç³»ç»Ÿä¼šå‘ä½ æä¾›ä¸€ä»½â€œçŸ¥è¯†ä¸Šä¸‹æ–‡ JSONâ€ï¼Œå…¶ä¸­åŒ…å«ï¼š
- etl_pointersï¼šå¯éªŒè¯çš„ ETL æŒ‡é’ˆï¼ˆå« element_idã€qualified_nameã€tools ç­‰ï¼‰
- allowlist_toolsï¼šè¯¥ Agent å…è®¸è°ƒç”¨çš„å·¥å…·ååˆ—è¡¨

ä½ å¿…é¡»æŠŠè¯¥ JSON è§†ä¸ºå¯ä¿¡è¾“å…¥ï¼›å¹¶ä»¥å®ƒä¸ºå”¯ä¸€çŸ¥è¯†æ¥æºæ¥æ”¶æ•›è¡¨åä¸å·¥å…·è°ƒç”¨ã€‚

## å·¥å…·ä½¿ç”¨è§„åˆ™ï¼ˆä¸¥æ ¼ï¼‰
ä½ åªèƒ½è°ƒç”¨ allowlist ä¸­å‡ºç°çš„å·¥å…·ï¼›å¹¶ä¸”ä»…å½“æŸä¸ª ETLPointer.tools åŒ…å«è¯¥å·¥å…·åæ—¶ï¼Œæ‰å…è®¸å¯¹è¯¥èŠ‚ç‚¹è°ƒç”¨è¯¥å·¥å…·ã€‚

## è¾“å‡ºæ ¼å¼
{{
  "summary": "ä¸€å¥è¯æ¦‚æ‹¬éœ€æ±‚ï¼ˆå¿…é¡»å…·ä½“ï¼Œä¸èƒ½æ¨¡ç³Šï¼‰",
  "steps": [
    {{
      "step_id": "step_1",
      "step_name": "ä¸šåŠ¡æ­¥éª¤åç§°",
      "description": "è¿™ä¸€æ­¥åšä»€ä¹ˆï¼ˆä¸šåŠ¡æè¿°ï¼‰",
      "input_tables": ["schema.table"],
      "output_table": "schema.table",
      "depends_on": []
    }}
  ],
  "final_target": {{
    "table_name": "æœ€ç»ˆç›®æ ‡è¡¨ï¼ˆå¿…é¡»æ˜ç¡®ï¼‰",
    "write_mode": "overwrite",
    "partition_by": ["dt"]
  }},
  "ambiguities": [
    {{
      "question": "éœ€è¦ç”¨æˆ·æ¾„æ¸…çš„å…·ä½“é—®é¢˜",
      "context": "ä¸ºä»€ä¹ˆéœ€è¦æ¾„æ¸…",
      "options": ["å¯èƒ½çš„é€‰é¡¹1", "å¯èƒ½çš„é€‰é¡¹2"]
    }}
  ],
  "confidence": 0.85
}}

é‡è¦ï¼š
- **å¿…é¡»è¾“å‡ºçº¯ JSON**ï¼šä¸å¾—è¾“å‡º Markdownã€ä¸å¾—è¾“å‡º ```json ä»£ç å—ã€ä¸å¾—è¾“å‡ºè§£é‡Šæ€§æ–‡å­—
- ambiguities ä¸­çš„æ¯æ¡ question å¿…é¡»å”¯ä¸€ï¼Œä¸å…è®¸åŒä¹‰é‡å¤
- å¦‚æœæ— æ³•åœ¨ä¸Šä¸‹æ–‡ä¸­å®šä½ç”¨æˆ·æåˆ°çš„æºå¤´è¾“å…¥è¡¨æˆ–æœ€ç»ˆç›®æ ‡è¡¨ï¼Œå¿…é¡»æå‡ºæ¾„æ¸…ï¼ˆç¦æ­¢è‡†é€ è¡¨åï¼‰ï¼Œconfidence è®¾ä¸º 0
- å¦‚æœæ— æ³•æ˜ç¡® input_tables æˆ– output_tableï¼Œå¿…é¡»åœ¨ ambiguities ä¸­æé—®
- confidence åæ˜ éœ€æ±‚çš„æ˜ç¡®ç¨‹åº¦ï¼Œæ¨¡ç³Šéœ€æ±‚å¿…é¡» < 0.7

åªè¾“å‡º JSONï¼Œä¸è¦è§£é‡Šã€‚
"""


class AnalystAgent:
    """
    éœ€æ±‚åˆ†æå¸ˆ

    èŒè´£ï¼š
    1. åŸºäºçŸ¥è¯†åº“æ”¶æ•›ç”¨æˆ·éœ€æ±‚
    2. é€šè¿‡å·¥å…·éªŒè¯æ¶‰åŠçš„è¡¨æ˜¯å¦å­˜åœ¨
    3. éœ€æ±‚ä¸æ˜ç¡®æ—¶å¼ºåˆ¶è¦æ±‚æ¾„æ¸…
    4. ä¸å…è®¸æ¨¡ç³Šéœ€æ±‚å¾€åä¼ 
    """

    def __init__(self):
        self.llm = call_llm(temperature=0.0)
        self.llm_json = call_llm(temperature=0.0, enable_json_mode=True)
        self.max_tool_calls = 4

    async def __call__(self, state: AgentState) -> Command:
        """æ‰§è¡Œéœ€æ±‚åˆ†æ"""
        user_query = state.user_input

        if not user_query:
            return Command(
                update={
                    "messages": [AIMessage(content="ç¼ºå°‘ç”¨æˆ·è¾“å…¥ï¼Œæ— æ³•åˆ†æéœ€æ±‚")],
                    "current_agent": "analyst_agent",
                    "error": "ç¼ºå°‘ç”¨æˆ·è¾“å…¥",
                }
            )

        logger.info(f"ğŸ“‹ AnalystAgent å¼€å§‹åˆ†æéœ€æ±‚: {user_query}")

        try:
            agent_context = state.get_agent_context(AgentType.ANALYST)

            if not agent_context:
                agent_context = AgentScopedContext.create_for_agent(
                    agent_type=AgentType.ANALYST,
                    tables=[],
                )

            context_payload = self._build_context_payload(
                agent_context=agent_context,
            )

            llm_with_tools = self._bind_tools_by_allowlist(agent_context)

            # æ‰§è¡Œåˆ†æï¼ˆå¸¦å·¥å…·è°ƒç”¨ï¼‰
            result_dict = await self._analyze_with_tools(
                user_query=user_query,
                context_payload=context_payload,
                agent_context=agent_context,
                llm_with_tools=llm_with_tools,
            )

            analysis_result = self._build_analysis_result(result_dict, user_query)

            plan_summary = analysis_result.get_execution_plan_summary()
            logger.info(f"âœ… AnalystAgent å®Œæˆåˆ†æ:\n{plan_summary}")

            allowed_tables = self._build_allowed_tables(agent_context.etl_pointers)
            unknown_tables = self._find_unknown_tables(analysis_result, allowed_tables=allowed_tables)
            if unknown_tables:
                # é»‘æ¿æ¨¡å¼ï¼šé‡åˆ°æœªçŸ¥è¡¨ï¼Œä¼˜å…ˆå§”æ´¾ KnowledgeAgent åˆ·æ–°ä¸Šä¸‹æ–‡ï¼Œè€Œä¸æ˜¯ç›´æ¥æŠ¥é”™ç»ˆæ­¢
                counters = dict(state.delegation_counters or {})
                counter_key = "analyst_agent:delegate:knowledge_agent:unknown_tables"
                delegated = int(counters.get(counter_key) or 0)
                if delegated < 1:
                    counters[counter_key] = delegated + 1
                    req = BlackboardRequest(
                        request_id=f"req_{uuid.uuid4().hex}",
                        kind="delegate",
                        created_by="analyst_agent",
                        target_agent="knowledge_agent",
                        resume_to="analyst_agent",
                        payload={
                            "type": "refresh_knowledge",
                            "reason": "unknown_tables",
                            "unknown_tables": unknown_tables,
                            "message": "éœ€æ±‚åˆ†æé˜¶æ®µå‘ç°æœªçŸ¥è¡¨ï¼Œå·²å§”æ´¾çŸ¥è¯†æ£€ç´¢åˆ·æ–°ä¸Šä¸‹æ–‡åå†ç»§ç»­ã€‚",
                        },
                    )
                    pending = list(state.pending_requests or [])
                    pending.append(req)
                    return Command(
                        update={
                            "messages": [AIMessage(content="æ£€æµ‹åˆ°æœªçŸ¥è¡¨ï¼Œå·²å§”æ´¾çŸ¥è¯†æ£€ç´¢åˆ·æ–°ä¸Šä¸‹æ–‡")],
                            "current_agent": "analyst_agent",
                            "pending_requests": [r.model_dump() for r in pending],
                            "delegation_counters": counters,
                        }
                    )
                request_id = f"req_{uuid.uuid4().hex}"
                guidance = await self._try_recommend_guidance(user_query)
                payload = {
                    "type": "clarification",
                    "message": "çŸ¥è¯†åº“æ— æ³•å®šä½ä½ æåˆ°çš„è¡¨ï¼Œè¯·è¡¥å……å¯éªŒè¯çº¿ç´¢ï¼ˆé¿å…ç³»ç»Ÿè‡†é€ ï¼‰ã€‚",
                    "questions": [
                        f"è¯·ç¡®è®¤è¿™äº›è¡¨çš„å‡†ç¡®åç§°ï¼ˆæ¨è schema.tableï¼‰ï¼š{', '.join(unknown_tables[:12])}",
                        "å¦‚æœä½ ä¸ç¡®å®šè¡¨åï¼šè¯·ç²˜è´´ä¸€æ®µç°æœ‰ SQL/DDL/å­—æ®µæ¸…å•ï¼Œæˆ–è¯´æ˜æ•°æ®æ¥æºç³»ç»Ÿä¸ç›®æ ‡è¡¨ã€‚",
                    ],
                }
                if guidance:
                    payload["guidance"] = guidance
                req = BlackboardRequest(
                    request_id=request_id,
                    kind="human",
                    created_by="analyst_agent",
                    resume_to="blackboard_router",
                    payload=payload,
                )
                pending = list(state.pending_requests or [])
                pending.append(req)
                return Command(
                    update={
                        "messages": [AIMessage(content="æ— æ³•å®šä½è¡¨æŒ‡é’ˆï¼šéœ€è¦ä½ è¡¥å……ä¸Šä¸‹æ–‡ä¿¡æ¯åæ‰èƒ½ç»§ç»­")],
                        "current_agent": "analyst_agent",
                        "pending_requests": [r.model_dump() for r in pending],
                        "delegation_counters": counters,
                    }
                )

            # éœ€æ±‚ä¸æ˜ç¡®æ—¶ï¼Œå¼ºåˆ¶è¦æ±‚æ¾„æ¸…ï¼ˆä»¥ LLM è¾“å‡ºä¸ºå‡†ï¼Œä¸åšç¨‹åºâ€œåè¡¥é—®é¢˜â€ï¼‰
            if analysis_result.needs_clarification() or analysis_result.confidence < 0.7:
                questions = [a.question for a in analysis_result.ambiguities if a.question]
                if not questions:
                    return Command(
                        update={
                            "messages": [AIMessage(content="éœ€æ±‚æœªæ”¶æ•›ï¼Œä½†æœªç”Ÿæˆå¯æ‰§è¡Œçš„æ¾„æ¸…é—®é¢˜ï¼ˆLLM è¾“å‡ºä¸åˆæ ¼ï¼‰")],
                            "current_agent": "analyst_agent",
                            "error": "éœ€æ±‚æœªæ”¶æ•›ä¸” ambiguities ä¸ºç©º",
                        }
                    )
                request_id = f"req_{uuid.uuid4().hex}"
                guidance = await self._try_recommend_guidance(user_query)
                payload = {
                    "type": "clarification",
                    "message": "è¯·å›ç­”ä»¥ä¸‹é—®é¢˜ä»¥ä¾¿ç»§ç»­åˆ†æ",
                    "questions": questions,
                }
                if guidance:
                    payload["guidance"] = guidance
                req = BlackboardRequest(
                    request_id=request_id,
                    kind="human",
                    created_by="analyst_agent",
                    resume_to="blackboard_router",
                    payload=payload,
                )
                pending = list(state.pending_requests or [])
                pending.append(req)
                return Command(
                    update={
                        "messages": [AIMessage(content="éœ€æ±‚ä¸å¤Ÿæ˜ç¡®ï¼Œéœ€è¦ä½ è¡¥å……å…³é”®ä¿¡æ¯åæ‰èƒ½ç»§ç»­")],
                        "current_agent": "analyst_agent",
                        "pending_requests": [r.model_dump() for r in pending],
                    }
                )

            # ç»“æ„æ€§æ”¶æ•›æ ¡éªŒï¼ˆåªåšæ ¡éªŒï¼Œä¸åšåè¡¥ï¼‰
            if not self._is_converged(analysis_result):
                return Command(
                    update={
                        "messages": [AIMessage(content="éœ€æ±‚æœªæ”¶æ•›ï¼šè¾“å‡ºä¸æ»¡è¶³æ­¥éª¤/è¾“å…¥è¾“å‡º/ç›®æ ‡è¡¨ç­‰çº¦æŸï¼ˆLLM è¾“å‡ºä¸åˆæ ¼ï¼‰")],
                        "analysis_result": analysis_result.model_dump(),
                        "current_agent": "analyst_agent",
                        "error": "éœ€æ±‚æœªæ”¶æ•›ï¼šç¼ºå°‘ steps æˆ– input/output æˆ– final_target",
                    }
                )

            return Command(
                update={
                    "messages": [AIMessage(content=f"éœ€æ±‚åˆ†æå®Œæˆ: {analysis_result.summary}")],
                    "analysis_result": analysis_result.model_dump(),
                    "current_agent": "analyst_agent",
                }
            )

        except Exception as e:
            logger.error(f"AnalystAgent åˆ†æå¤±è´¥: {e}", exc_info=True)
            return Command(
                update={
                    "messages": [AIMessage(content=f"éœ€æ±‚åˆ†æå¤±è´¥: {str(e)}")],
                    "current_agent": "analyst_agent",
                    "error": str(e),
                }
            )

    @staticmethod
    async def _try_recommend_guidance(user_query: str) -> dict | None:
        """
        no-hit/éœ€æ¾„æ¸…åœºæ™¯çš„è½»é‡å¼•å¯¼æ•°æ®ï¼ˆtag/catalog å¯¼èˆªï¼‰

        çº¦æŸï¼š
        - åªè¿”å›å¯¼èˆªä¿¡æ¯ï¼Œä¸è¿”å› element_id/æŒ‡é’ˆ
        - å¤±è´¥æ—¶é™é»˜é™çº§ï¼Œä¸å½±å“ä¸»é“¾è·¯
        """
        try:
            raw = await recommend_guidance.ainvoke({"user_query": user_query})
            parsed = json.loads(raw or "")
            if isinstance(parsed, dict) and parsed.get("status") == "success":
                return parsed
            return None
        except Exception:
            return None

    async def _analyze_with_tools(
        self,
        user_query: str,
        context_payload: dict,
        agent_context: AgentScopedContext,
        llm_with_tools,
    ) -> dict:
        """æ‰§è¡Œå¸¦å·¥å…·è°ƒç”¨çš„åˆ†æ"""
        messages = [
            SystemMessage(content=ANALYST_AGENT_SYSTEM_INSTRUCTIONS),
            SystemMessage(content=json.dumps(context_payload, ensure_ascii=False)),
            HumanMessage(content=user_query),
        ]
        tool_call_count = 0

        while tool_call_count < self.max_tool_calls:
            response = await llm_with_tools.ainvoke(messages)
            messages.append(response)

            # å¦‚æœæ²¡æœ‰å·¥å…·è°ƒç”¨ï¼Œè§£æå“åº”
            if not response.tool_calls:
                return self._parse_response(response.content)

            # æ‰§è¡Œå·¥å…·è°ƒç”¨
            for tool_call in response.tool_calls:
                tool_call_count += 1
                tool_name = tool_call["name"]
                tool_args = tool_call["args"]
                tool_id = tool_call["id"]

                logger.info(f"ğŸ”§ AnalystAgent è°ƒç”¨å·¥å…·: {tool_name}({tool_args})")

                tool_result = await self._execute_tool(
                    tool_name=tool_name,
                    tool_args=tool_args,
                    agent_context=agent_context,
                )

                messages.append(
                    ToolMessage(content=tool_result, tool_call_id=tool_id)
                )

                if tool_call_count >= self.max_tool_calls:
                    break

        # è¾¾åˆ°æœ€å¤§å·¥å…·è°ƒç”¨æ¬¡æ•°ï¼Œè·å–æœ€ç»ˆå“åº”
        response = await self.llm_json.ainvoke(messages)
        return self._parse_response(response.content)

    @staticmethod
    def _build_allowed_table_index(node_pointers: list[ETLPointer]) -> dict[str, ETLPointer]:
        """
        ä» etl_pointers æ„å»ºå¯è°ƒç”¨å·¥å…·çš„è¡¨ç´¢å¼•ï¼ˆæŒ‰ qualified_nameï¼‰

        è¯´æ˜ï¼š
        - AnalystAgent åªåšè¡¨çº§æ”¶æ•›ï¼Œå› æ­¤è¿™é‡Œåªå…³å¿ƒ Table æŒ‡é’ˆ
        - ä¸‹æ¸¸åªå…è®¸å¯¹â€œä¸Šä¸‹æ–‡å·²ç»™å‡ºçš„è¡¨æŒ‡é’ˆâ€è°ƒç”¨ get_table_columns
        """
        table_index: dict[str, ETLPointer] = {}
        for p in node_pointers or []:
            if "Table" not in set(p.labels or []):
                continue
            if not p.qualified_name:
                continue
            table_index[p.qualified_name] = p
        return table_index

    async def _execute_tool(self, *, tool_name: str, tool_args: dict, agent_context: AgentScopedContext) -> str:
        """æ‰§è¡Œå·¥å…·è°ƒç”¨"""
        try:
            allowlist = set(agent_context.tools or [])
            if tool_name not in allowlist:
                return json.dumps(
                    {"status": "error", "message": f"å·¥å…·ä¸åœ¨ allowlist ä¸­: {tool_name}"},
                    ensure_ascii=False,
                )

            if tool_name == "get_table_columns":
                table_name = (tool_args or {}).get("table_name") or ""
                table_index = self._build_allowed_table_index(agent_context.etl_pointers)
                pointer = table_index.get(table_name)
                if not pointer:
                    return json.dumps(
                        {
                            "status": "error",
                            "message": "ç¦æ­¢å¯¹æœªä¸‹å‘çš„è¡¨æŒ‡é’ˆè°ƒç”¨å·¥å…·",
                            "table_name": table_name,
                        },
                        ensure_ascii=False,
                    )
                if tool_name not in set(pointer.tools or []):
                    return json.dumps(
                        {
                            "status": "error",
                            "message": "è¯¥è¡¨æŒ‡é’ˆæœªæˆæƒæ­¤å·¥å…·ï¼ˆETLPointer.toolsï¼‰",
                            "table_name": table_name,
                            "pointer_element_id": pointer.element_id,
                        },
                        ensure_ascii=False,
                    )
                return await get_table_columns.ainvoke({"table_name": table_name})

            return json.dumps({"status": "error", "message": f"æœªçŸ¥å·¥å…·: {tool_name}"}, ensure_ascii=False)
        except Exception as e:
            logger.error(f"å·¥å…· {tool_name} æ‰§è¡Œå¤±è´¥: {e}")
            return json.dumps({"status": "error", "message": str(e)})

    def _is_converged(self, analysis: AnalysisResult) -> bool:
        """åªåšç»“æ„æ€§æ”¶æ•›æ ¡éªŒï¼Œä¸åšä»»ä½•â€œè¡¥å…¨/è¿½åŠ â€"""
        if not analysis.steps:
            return False
        for step in analysis.steps:
            if not step.input_tables:
                return False
            if not step.output_table:
                return False
        if not analysis.final_target:
            return False
        if not analysis.final_target.table_name:
            return False
        return True

    @staticmethod
    def _build_allowed_tables(node_pointers: list[ETLPointer]) -> set[str]:
        allowed: set[str] = set()
        for p in node_pointers or []:
            if "Table" not in set(p.labels or []):
                continue
            if p.qualified_name:
                allowed.add(p.qualified_name)
        return allowed

    @staticmethod
    def _find_unknown_tables(analysis: AnalysisResult, *, allowed_tables: set[str]) -> list[str]:
        referenced = set(analysis.get_all_tables())
        unknown: list[str] = []
        for t in referenced:
            if not t or t.startswith("temp."):
                continue
            if t not in allowed_tables:
                unknown.append(t)
        return sorted(set(unknown))

    def _bind_tools_by_allowlist(self, agent_context: AgentScopedContext):
        """
        æŒ‰ allowlist åŠ¨æ€ç»‘å®šå·¥å…·ï¼Œé¿å…ç¡¬ç¼–ç å¯¼è‡´çš„â€œè¶Šæƒ/è¯¯å¯¼â€ã€‚

        è¯´æ˜ï¼š
        - bind_tools å†³å®š LLM èƒ½å¦å‘èµ·å·¥å…·è°ƒç”¨ï¼ˆèƒ½åŠ›é¢ï¼‰
        - allowlist å†³å®šè¯¥ Agent æ˜¯å¦å…è®¸è°ƒç”¨ï¼ˆæƒé™é¢ï¼‰
        """
        allowlist = set(agent_context.tools or [])
        tool_registry = {
            "get_table_columns": get_table_columns,
        }
        tools = [tool_registry[name] for name in allowlist if name in tool_registry]
        return self.llm.bind_tools(tools)

    def _parse_response(self, content: str) -> dict:
        """ä¸¥æ ¼è§£æ LLM å“åº”ï¼ˆå¿…é¡»æ˜¯çº¯ JSONï¼‰"""
        text = (content or "").strip()
        logger.info(f"ğŸ” è§£æ LLM JSON (é•¿åº¦: {len(text)}): {text[:500]}...")
        try:
            parsed = json.loads(text)
        except json.JSONDecodeError as e:
            logger.error("LLM è¾“å‡ºä¸æ˜¯åˆæ³• JSON: %s", e)
            raise ValueError("LLM è¾“å‡ºä¸æ˜¯åˆæ³• JSONï¼ˆå¿…é¡»è¾“å‡ºçº¯ JSONï¼‰") from e
        if not isinstance(parsed, dict):
            raise ValueError("LLM è¾“å‡ºå¿…é¡»æ˜¯ JSON object")
        return parsed

    def _build_analysis_result(self, result_dict: dict, user_query: str) -> AnalysisResult:
        """æ„å»º AnalysisResult"""
        steps = []
        for step_dict in result_dict.get("steps", []):
            step = Step(
                step_id=step_dict.get("step_id", ""),
                step_name=step_dict.get("step_name", ""),
                description=step_dict.get("description", ""),
                input_tables=step_dict.get("input_tables", []),
                output_table=step_dict.get("output_table"),
                depends_on=step_dict.get("depends_on", []),
            )
            steps.append(step)

        # è§£æ ambiguities
        ambiguities = []
        for amb_dict in result_dict.get("ambiguities", []):
            if isinstance(amb_dict, dict):
                ambiguities.append(Ambiguity(
                    question=amb_dict.get("question", ""),
                    context=amb_dict.get("context"),
                    options=amb_dict.get("options", []),
                ))
            elif isinstance(amb_dict, str):
                ambiguities.append(Ambiguity(question=amb_dict))

        # è§£æ final_target ä¸º DataTarget å¯¹è±¡
        final_target = None
        final_target_dict = result_dict.get("final_target")
        if final_target_dict and isinstance(final_target_dict, dict):
            final_target = DataTarget(
                table_name=final_target_dict.get("table_name", ""),
                write_mode=final_target_dict.get("write_mode", "overwrite"),
                partition_by=final_target_dict.get("partition_by", []),
                description=final_target_dict.get("description"),
            )

        return AnalysisResult(
            user_query=user_query,
            summary=result_dict.get("summary", ""),
            steps=steps,
            final_target=final_target,
            ambiguities=ambiguities,
            confidence=result_dict.get("confidence", 0.5),
        )

    @staticmethod
    def _build_context_payload(
        *,
        agent_context: AgentScopedContext,
    ) -> dict:
        """
        æ„é€ â€œçŸ¥è¯†ä¸Šä¸‹æ–‡JSONâ€ï¼ˆä¸‹å‘ç»™ LLM çš„ SystemMessageï¼‰

        çº¦æŸï¼š
        - åªä¼ é€’æŒ‡é’ˆä¸å¯¼èˆªä¿¡æ¯ï¼Œä¸ä¼ é€’è¡¨æ˜ç»†ï¼ˆåˆ—æ˜ç»†å¿…é¡»é€šè¿‡å·¥å…·è·å–ï¼‰
        """
        node_pointers = agent_context.etl_pointers or []
        table_pointers = [
            {
                "element_id": p.element_id,
                "qualified_name": p.qualified_name,
                "path": p.path,
                "display_name": p.display_name,
                "description": p.description,
                "tools": p.tools,
            }
            for p in node_pointers
            if "Table" in set(p.labels or []) and p.qualified_name
        ]

        return {
            "agent_type": agent_context.agent_type,
            "allowlist_tools": agent_context.tools,
            "tables": agent_context.tables,
            "table_pointers": table_pointers,
            "etl_pointers": [p.model_dump() for p in node_pointers],
            "doc_pointers": [p.model_dump() for p in (agent_context.doc_pointers or [])],
        }
