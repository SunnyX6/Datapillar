"""
Knowledge Agentï¼ˆçŸ¥è¯†æ£€ç´¢ä¸“å®¶ï¼‰

é€šè¿‡ LLM + Tools çš„æ–¹å¼ä» Neo4j çŸ¥è¯†åº“æ£€ç´¢ä¿¡æ¯ã€‚
LLM è‡ªä¸»å†³å®šè°ƒç”¨å“ªäº›å·¥å…·ï¼Œæ”¯æŒå¤šè½®æ£€ç´¢ã€‚
"""

import json
import logging
from typing import List, Dict, Any, Optional

from langchain_core.messages import AIMessage, HumanMessage, ToolMessage
from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder
from langgraph.types import Command

from src.modules.etl.schemas.state import AgentState
from src.modules.etl.schemas.kg_context import (
    KnowledgeContext,
    TableSchema,
    ColumnInfo,
    TableLineage,
    JoinHint,
    BusinessContext,
    ReferenceCase,
    Component,
)
from src.modules.etl.memory import MemoryManager
from src.infrastructure.llm.client import call_llm
from src.modules.etl.tools.agent_tools import (
    search_assets,
    get_table_lineage,
    kg_join_hints,
    kg_quality_rules,
    search_reference_cases,
    list_component,
)

logger = logging.getLogger(__name__)

# çŸ¥è¯†æ£€ç´¢å·¥å…·åˆ—è¡¨
KNOWLEDGE_TOOLS = [
    search_assets,
    get_table_lineage,
    kg_join_hints,
    kg_quality_rules,
    search_reference_cases,
    list_component,
]

# ç³»ç»Ÿæç¤ºè¯
KNOWLEDGE_AGENT_PROMPT = """ä½ æ˜¯æ•°ä»“çŸ¥è¯†æ£€ç´¢ä¸“å®¶ï¼Œè´Ÿè´£ä»çŸ¥è¯†åº“ä¸­æ£€ç´¢ç”¨æˆ·æ‰€éœ€çš„è¡¨ç»“æ„ã€è¡€ç¼˜å…³ç³»ã€JOIN å…³ç³»ç­‰ä¿¡æ¯ã€‚

## ä½ çš„èŒè´£
1. åˆ†æç”¨æˆ·æŸ¥è¯¢ï¼Œç†è§£ç”¨æˆ·æƒ³è¦å¤„ç†å“ªäº›æ•°æ®
2. è°ƒç”¨åˆé€‚çš„å·¥å…·æ£€ç´¢ç›¸å…³çŸ¥è¯†
3. æ ¹æ®æ£€ç´¢ç»“æœå†³å®šæ˜¯å¦éœ€è¦è¡¥å……æŸ¥è¯¢
4. æ£€ç´¢å†å²æˆåŠŸæ¡ˆä¾‹ï¼Œä¸ºåç»­ SQL ç”Ÿæˆæä¾›å‚è€ƒ
5. è·å–å¯ç”¨ç»„ä»¶åˆ—è¡¨ï¼Œä¸ºåç»­æ¶æ„è®¾è®¡æä¾›çº¦æŸ
6. æ•´ç†æ£€ç´¢ç»“æœï¼Œæ ‡æ³¨çŸ¥è¯†ç¼ºå£

## å¯ç”¨å·¥å…·
- search_assets: æœç´¢ç›¸å…³è¡¨ï¼ˆå‘é‡+å…¨æ–‡æ£€ç´¢ï¼‰ï¼Œè¿”å›è¡¨åã€åˆ—ä¿¡æ¯ã€ä¸šåŠ¡ä¸Šä¸‹æ–‡
- get_table_lineage: è·å–è¡¨çš„è¯¦ç»†ä¿¡æ¯å’Œè¡€ç¼˜å…³ç³»
- kg_join_hints: è·å–è¡¨çš„ JOIN å…³ç³»ï¼ˆå·¦è¡¨ã€å³è¡¨ã€å…³è”å­—æ®µï¼‰
- kg_quality_rules: è·å–è¡¨çš„æ•°æ®è´¨é‡è§„åˆ™
- search_reference_cases: æ£€ç´¢å†å²æˆåŠŸçš„ ETL æ¡ˆä¾‹ï¼Œè·å–å¯å¤ç”¨çš„ SQL æ¨¡æ¿
- list_component: ã€å¿…é¡»è°ƒç”¨ã€‘è·å–ä¼ä¸šæ”¯æŒçš„å¤§æ•°æ®ç»„ä»¶åˆ—è¡¨ï¼ˆdatax/hive/spark/flinkç­‰ï¼‰

## æ£€ç´¢ç­–ç•¥
1. é¦–å…ˆè°ƒç”¨ search_assets æ‰¾åˆ°ä¸ç”¨æˆ·æŸ¥è¯¢ç›¸å…³çš„è¡¨
2. å¦‚æœæ‰¾åˆ°å¤šä¸ªè¡¨ï¼Œè°ƒç”¨ kg_join_hints è·å–å®ƒä»¬çš„ JOIN å…³ç³»
3. å¦‚æœç”¨æˆ·æåˆ°äº†æºè¡¨å’Œç›®æ ‡è¡¨ï¼Œè°ƒç”¨ get_table_lineage è·å–è¡€ç¼˜
4. å¦‚æœæ¶‰åŠæ•°æ®è´¨é‡ï¼Œè°ƒç”¨ kg_quality_rules è·å– DQ è§„åˆ™
5. è°ƒç”¨ search_reference_cases æ£€ç´¢å†å²æˆåŠŸæ¡ˆä¾‹
6. ã€å¿…é¡»ã€‘è°ƒç”¨ list_component è·å–å¯ç”¨ç»„ä»¶åˆ—è¡¨

## æ³¨æ„äº‹é¡¹
- æ¯æ¬¡è°ƒç”¨å·¥å…·åï¼Œåˆ†æç»“æœæ˜¯å¦è¶³å¤Ÿ
- å¦‚æœä¿¡æ¯ä¸è¶³ï¼Œç»§ç»­è°ƒç”¨å…¶ä»–å·¥å…·è¡¥å……
- æœ€å¤šè°ƒç”¨ 6 æ¬¡å·¥å…·
- å¦‚æœæ— æ³•æ‰¾åˆ°ç›¸å…³è¡¨ï¼Œæ˜ç¡®å‘ŠçŸ¥ç”¨æˆ·
- list_component å¿…é¡»è°ƒç”¨ï¼Œå¦åˆ™åç»­æ¶æ„è®¾è®¡æ— æ³•è¿›è¡Œ

## å½“å‰ç”¨æˆ·æŸ¥è¯¢
{user_query}
"""


class KnowledgeAgent:
    """
    çŸ¥è¯†æ£€ç´¢ä¸“å®¶ï¼ˆTool-basedï¼‰

    ä½¿ç”¨ LLM + Tools çš„æ–¹å¼æ£€ç´¢çŸ¥è¯†ï¼š
    1. LLM åˆ†æç”¨æˆ·æŸ¥è¯¢ï¼Œå†³å®šæ£€ç´¢ç­–ç•¥
    2. LLM è°ƒç”¨å·¥å…·æ‰§è¡Œæ£€ç´¢
    3. LLM æ ¹æ®ç»“æœå†³å®šæ˜¯å¦éœ€è¦è¡¥å……æŸ¥è¯¢
    4. æ•´åˆç»“æœæ„å»º KnowledgeContext
    """

    def __init__(self, memory: MemoryManager):
        self.memory = memory
        self.llm = call_llm(temperature=0.0)
        self.llm_with_tools = self.llm.bind_tools(KNOWLEDGE_TOOLS)
        self.max_tool_calls = 6

    async def __call__(self, state: AgentState) -> Command:
        """æ‰§è¡ŒçŸ¥è¯†æ£€ç´¢"""
        user_query = state.user_input
        if not user_query:
            return Command(
                update={
                    "messages": [AIMessage(content="ç¼ºå°‘ç”¨æˆ·è¾“å…¥ï¼Œæ— æ³•æ£€ç´¢çŸ¥è¯†")],
                    "current_agent": "knowledge_agent",
                    "error": "ç¼ºå°‘ç”¨æˆ·è¾“å…¥",
                }
            )

        logger.info(f"ğŸ” KnowledgeAgent å¼€å§‹æ£€ç´¢: {user_query}")

        try:
            # æ‰§è¡Œ Tool-based æ£€ç´¢
            tool_results = await self._execute_tool_loop(user_query)

            # è§£æå·¥å…·è°ƒç”¨ç»“æœï¼Œæ„å»º KnowledgeContext
            context = self._build_context_from_results(user_query, tool_results)

            # ç¼“å­˜åˆ° Memory
            if context.tables:
                self.memory.cache_tables(context.tables)

            logger.info(
                f"âœ… KnowledgeAgent å®Œæˆæ£€ç´¢: {len(context.tables)} è¡¨, "
                f"{len(context.join_hints)} JOIN, {len(context.gaps)} ç¼ºå£"
            )

            return Command(
                update={
                    "messages": [AIMessage(content=f"çŸ¥è¯†æ£€ç´¢å®Œæˆï¼Œæ‰¾åˆ° {len(context.tables)} ä¸ªç›¸å…³è¡¨")],
                    "knowledge_context": context.model_dump(),
                    "current_agent": "knowledge_agent",
                }
            )

        except Exception as e:
            logger.error(f"KnowledgeAgent æ£€ç´¢å¤±è´¥: {e}", exc_info=True)
            return Command(
                update={
                    "messages": [AIMessage(content=f"çŸ¥è¯†æ£€ç´¢å¤±è´¥: {str(e)}")],
                    "current_agent": "knowledge_agent",
                    "error": str(e),
                }
            )

    async def _execute_tool_loop(self, user_query: str) -> Dict[str, Any]:
        """
        æ‰§è¡Œ Tool è°ƒç”¨å¾ªç¯

        LLM è‡ªä¸»å†³å®šè°ƒç”¨å“ªäº›å·¥å…·ï¼Œæœ€å¤šè°ƒç”¨ max_tool_calls æ¬¡ã€‚

        Returns:
            {"search_results": [...], "lineage_results": [...], "join_results": [...], "dq_results": [...], "case_results": [...]}
        """
        results = {
            "search_results": [],
            "lineage_results": [],
            "join_results": [],
            "dq_results": [],
            "case_results": [],
            "component_results": [],
        }

        # åˆå§‹æ¶ˆæ¯
        messages = [
            HumanMessage(content=KNOWLEDGE_AGENT_PROMPT.format(user_query=user_query))
        ]

        tool_call_count = 0

        while tool_call_count < self.max_tool_calls:
            # è°ƒç”¨ LLMï¼Œè®©å®ƒå†³å®šä¸‹ä¸€æ­¥è¡ŒåŠ¨
            response = await self.llm_with_tools.ainvoke(messages)
            messages.append(response)

            # æ£€æŸ¥æ˜¯å¦æœ‰å·¥å…·è°ƒç”¨
            if not response.tool_calls:
                logger.info("LLM å†³å®šåœæ­¢å·¥å…·è°ƒç”¨")
                break

            # æ‰§è¡Œå·¥å…·è°ƒç”¨
            for tool_call in response.tool_calls:
                tool_call_count += 1
                tool_name = tool_call["name"]
                tool_args = tool_call["args"]
                tool_id = tool_call["id"]

                logger.info(f"ğŸ”§ è°ƒç”¨å·¥å…· [{tool_call_count}/{self.max_tool_calls}]: {tool_name}({tool_args})")

                # æ‰§è¡Œå·¥å…·
                tool_result = await self._execute_tool(tool_name, tool_args)

                # è®°å½•ç»“æœ
                self._record_tool_result(results, tool_name, tool_result)

                # æ·»åŠ å·¥å…·ç»“æœåˆ°æ¶ˆæ¯åˆ—è¡¨
                messages.append(ToolMessage(
                    content=tool_result,
                    tool_call_id=tool_id,
                ))

                if tool_call_count >= self.max_tool_calls:
                    logger.info(f"å·²è¾¾åˆ°æœ€å¤§å·¥å…·è°ƒç”¨æ¬¡æ•° {self.max_tool_calls}")
                    break

        return results

    async def _execute_tool(self, tool_name: str, tool_args: Dict[str, Any]) -> str:
        """æ‰§è¡Œå•ä¸ªå·¥å…·è°ƒç”¨"""
        try:
            if tool_name == "search_assets":
                return await search_assets.ainvoke(tool_args)
            elif tool_name == "get_table_lineage":
                return await get_table_lineage.ainvoke(tool_args)
            elif tool_name == "kg_join_hints":
                return await kg_join_hints.ainvoke(tool_args)
            elif tool_name == "kg_quality_rules":
                return await kg_quality_rules.ainvoke(tool_args)
            elif tool_name == "search_reference_cases":
                return await search_reference_cases.ainvoke(tool_args)
            elif tool_name == "list_component":
                return list_component.invoke(tool_args)
            else:
                return json.dumps({"status": "error", "message": f"æœªçŸ¥å·¥å…·: {tool_name}"})
        except Exception as e:
            logger.error(f"å·¥å…· {tool_name} æ‰§è¡Œå¤±è´¥: {e}")
            return json.dumps({"status": "error", "message": str(e)})

    def _record_tool_result(self, results: Dict, tool_name: str, tool_result: str) -> None:
        """è®°å½•å·¥å…·è°ƒç”¨ç»“æœ"""
        try:
            data = json.loads(tool_result)
            if data.get("status") == "error":
                logger.warning(f"å·¥å…· {tool_name} è¿”å›é”™è¯¯: {data.get('message')}")
                return

            if tool_name == "search_assets":
                results["search_results"].extend(data.get("tables", []))
            elif tool_name == "get_table_lineage":
                results["lineage_results"].append(data)
            elif tool_name == "kg_join_hints":
                results["join_results"].extend(data.get("join_keys", []))
            elif tool_name == "kg_quality_rules":
                results["dq_results"].extend(data.get("dq_rules", []))
            elif tool_name == "search_reference_cases":
                results["case_results"].extend(data.get("cases", []))
            elif tool_name == "list_component":
                results["component_results"].extend(data.get("components", []))

        except json.JSONDecodeError:
            logger.error(f"å·¥å…· {tool_name} è¿”å›æ— æ•ˆ JSON: {tool_result}")

    def _build_context_from_results(self, user_query: str, results: Dict) -> KnowledgeContext:
        """ä»å·¥å…·è°ƒç”¨ç»“æœæ„å»º KnowledgeContextï¼ˆç²¾ç®€ç‰ˆï¼‰"""

        # 1ï¸âƒ£ æ„å»ºè¡¨ä¿¡æ¯ï¼ˆç²¾ç®€ç‰ˆï¼‰
        tables: Dict[str, TableSchema] = {}

        for table_data in results["search_results"]:
            table_name = table_data.get("table_name")
            if not table_name:
                continue

            # æå–åˆ—ä¿¡æ¯
            all_columns = table_data.get("columns", [])

            # åˆ†ç¦»ä¸»é”®åˆ—å’Œæ™®é€šåˆ—
            pk_columns = [c for c in all_columns if c.get("isPrimaryKey")]
            other_columns = [c for c in all_columns if not c.get("isPrimaryKey")]

            # åªä¿ç•™ä¸»é”® + å‰ 10 ä¸ªæ™®é€šåˆ—
            selected_columns = pk_columns + other_columns[:10]

            key_columns = [
                ColumnInfo(
                    name=c.get("name", ""),
                    data_type=c.get("dataType", "string"),
                    description=c.get("description"),
                    is_primary_key=c.get("isPrimaryKey", False),
                )
                for c in selected_columns
                if c.get("name")
            ]

            # æå–ä¸šåŠ¡ä¸Šä¸‹æ–‡
            biz_ctx = table_data.get("business_context", {})

            tables[table_name] = TableSchema(
                name=table_name,
                display_name=table_data.get("table_display_name"),
                description=table_data.get("description"),
                key_columns=key_columns,
                column_count=len(all_columns),
                layer=biz_ctx.get("layer"),
                schema_name=biz_ctx.get("schema"),
                subject_name=biz_ctx.get("subject"),
                catalog_name=biz_ctx.get("catalog"),
                domain_name=biz_ctx.get("domain"),
            )

        # 2ï¸âƒ£ æ„å»ºè¡¨çº§è¡€ç¼˜ï¼ˆåªä¿ç•™è¡¨çº§ï¼Œä¸ä¿ç•™åˆ—çº§ï¼‰
        table_lineage: List[TableLineage] = []

        for lineage_data in results["lineage_results"]:
            source_table = lineage_data.get("source_table", {}).get("name")
            target_table = lineage_data.get("target_table", {}).get("name")

            if source_table and target_table:
                table_lineage.append(TableLineage(
                    source_table=source_table,
                    target_table=target_table,
                    confidence=0.8 if lineage_data.get("has_lineage") else 0.5,
                ))

        # ä» search_results ä¸­æå–è¡¨çº§è¡€ç¼˜
        for table_data in results["search_results"]:
            source = table_data.get("table_name")
            for target in table_data.get("downstream_lineage", []):
                if source and target:
                    # é¿å…é‡å¤
                    if not any(l.source_table == source and l.target_table == target for l in table_lineage):
                        table_lineage.append(TableLineage(
                            source_table=source,
                            target_table=target,
                            confidence=0.7,
                        ))

        # 3ï¸âƒ£ æ„å»º JOIN ä¿¡æ¯
        join_hints: List[JoinHint] = []
        for join_data in results["join_results"]:
            if join_data.get("left_table") and join_data.get("right_table"):
                join_hints.append(JoinHint(
                    left_table=join_data["left_table"],
                    left_column=join_data.get("left_column", ""),
                    right_table=join_data["right_table"],
                    right_column=join_data.get("right_column", ""),
                    join_type=join_data.get("join_type", "LEFT"),
                ))

        # 4ï¸âƒ£ æå–ä¸šåŠ¡ä¸Šä¸‹æ–‡
        business_context = None
        if tables:
            first_table = list(tables.values())[0]
            business_context = BusinessContext(
                domain=first_table.domain_name,
                catalog=first_table.catalog_name,
                subject=first_table.subject_name,
                schema=first_table.schema_name,
                layer=first_table.layer,
            )

        # 5ï¸âƒ£ è¯†åˆ«çŸ¥è¯†ç¼ºå£
        gaps = self._identify_gaps(tables, join_hints, table_lineage)

        # 6ï¸âƒ£ æ„å»ºå†å²å‚è€ƒæ¡ˆä¾‹
        reference_cases: List[ReferenceCase] = []
        for case_data in results.get("case_results", []):
            if case_data.get("case_id"):
                reference_cases.append(ReferenceCase(
                    case_id=case_data["case_id"],
                    user_query=case_data.get("user_query", ""),
                    sql_text=case_data.get("sql_text"),
                    intent=case_data.get("intent", ""),
                    source_tables=case_data.get("source_tables", []),
                    target_tables=case_data.get("target_tables", []),
                    tags=case_data.get("tags", []),
                ))

        if reference_cases:
            logger.info(f"ğŸ“š æ‰¾åˆ° {len(reference_cases)} ä¸ªå†å²å‚è€ƒæ¡ˆä¾‹")

        # 7ï¸âƒ£ æ„å»ºç»„ä»¶åˆ—è¡¨
        components: List[Component] = []
        for comp_data in results.get("component_results", []):
            if comp_data.get("component_id"):
                components.append(Component(
                    component_id=comp_data["component_id"],
                    component_name=comp_data.get("component_name", ""),
                    description=comp_data.get("description"),
                ))

        if components:
            logger.info(f"ğŸ“¦ æ‰¾åˆ° {len(components)} ä¸ªå¯ç”¨ç»„ä»¶")

        return KnowledgeContext(
            tables=tables,
            table_lineage=table_lineage,
            join_hints=join_hints,
            business_context=business_context,
            reference_cases=reference_cases,
            components=components,
            gaps=gaps,
        )

    def _identify_gaps(
        self,
        tables: Dict[str, TableSchema],
        join_hints: List[JoinHint],
        table_lineage: List[TableLineage],
    ) -> List[str]:
        """è¯†åˆ«çŸ¥è¯†ç¼ºå£"""
        gaps = []

        if not tables:
            gaps.append("æœªæ‰¾åˆ°ä¸æŸ¥è¯¢ç›¸å…³çš„è¡¨ï¼Œè¯·ç¡®è®¤è¡¨åæˆ–æè¿°")
            return gaps

        # æ¨æ–­æºè¡¨å’Œç›®æ ‡è¡¨
        source_tables = [name for name, t in tables.items() if t.layer in ("SRC", "ODS")]
        target_tables = [name for name, t in tables.items() if t.layer in ("DWD", "DWS", "ADS")]

        if not source_tables:
            gaps.append("æœªè¯†åˆ«åˆ°æ˜ç¡®çš„æºè¡¨ï¼Œè¯·ç¡®è®¤æ•°æ®æ¥æº")

        if not target_tables:
            gaps.append("æœªè¯†åˆ«åˆ°æ˜ç¡®çš„ç›®æ ‡è¡¨ï¼Œè¯·ç¡®è®¤æ•°æ®ç›®æ ‡")

        # å¤šè¡¨åœºæ™¯æ£€æŸ¥ JOIN
        if len(tables) > 1 and not join_hints:
            gaps.append("å¤šè¡¨åœºæ™¯ä½†æœªæ‰¾åˆ° JOIN å…³ç³»ï¼Œè¯·ç¡®è®¤è¡¨å…³è”æ–¹å¼")

        # æ£€æŸ¥ä¸»é”®ï¼ˆé€šè¿‡ key_columns ä¸­çš„ is_primary_key åˆ¤æ–­ï¼‰
        tables_without_pk = [
            name for name, t in tables.items()
            if not any(col.is_primary_key for col in t.key_columns)
        ]
        if tables_without_pk and len(tables_without_pk) < len(tables):
            gaps.append(f"éƒ¨åˆ†è¡¨ç¼ºå°‘ä¸»é”®ä¿¡æ¯: {', '.join(tables_without_pk[:3])}")

        return gaps
