"""
ETL å¤šæ™ºèƒ½ä½“ç¼–æ’å™¨

ä½¿ç”¨ LangGraph å®ç°æ™ºèƒ½ä½“åä½œï¼š
- é»‘æ¿æ¨¡å¼ï¼ˆBlackboardï¼‰ï¼šæ‰€æœ‰äº§ç‰©å†™å…¥å…±äº« stateï¼Œç”±ç¼–æ’å™¨ç»Ÿä¸€è·¯ç”±
- åŠ¨æ€å§”æ´¾ï¼ˆDelegationï¼‰ï¼šä»»æ„ Agent å¯åˆ›å»ºè¯·æ±‚ï¼Œç¼–æ’å™¨æŠ¢å å¤„ç†
- å…¨å±€å¯æŠ¢å äººæœºäº¤äº’ï¼ˆHITLï¼‰ï¼šè¯·æ±‚é˜Ÿåˆ—ä¸ä¸ºç©ºæ—¶ä¼˜å…ˆä¸­æ–­ç­‰å¾…ç”¨æˆ·è¾“å…¥
"""

import logging
import json
import time
import uuid
from typing import Any, AsyncGenerator, Literal

from langchain_core.messages import AIMessage, HumanMessage
from langgraph.checkpoint.base import BaseCheckpointSaver
from langgraph.checkpoint.memory import InMemorySaver
from langgraph.graph import END, StateGraph
from langgraph.types import Command, interrupt

from src.modules.etl.agents import (
    AnalystAgent,
    ArchitectAgent,
    DeveloperAgent,
    KnowledgeAgent,
    TesterAgent,
)
from src.modules.etl.memory import MemoryManager
from src.modules.etl.schemas.dag import WorkflowResponse
from src.modules.etl.schemas.kg_context import AgentScopedContext, AgentType
from src.modules.etl.schemas.plan import Workflow
from src.modules.etl.schemas.requirement import AnalysisResult
from src.modules.etl.schemas.requests import BlackboardRequest
from src.modules.etl.schemas.state import AgentState
from src.modules.etl.schemas.sse_msg import SseEvent
from src.shared.config.settings import settings

logger = logging.getLogger(__name__)


class EtlOrchestrator:
    """
    ETL å¤šæ™ºèƒ½ä½“ç¼–æ’å™¨

    é»‘æ¿åä½œï¼ˆé‡è¦ï¼‰ï¼š
    - ç¼–æ’å™¨ä¸å†ä¾èµ–å›ºå®šæµæ°´çº¿è¾¹
    - ç»Ÿä¸€å…¥å£ blackboard_routerï¼šæ ¹æ® state äº§ç‰©ä¸ pending_requests åŠ¨æ€é€‰æ‹©ä¸‹ä¸€æ­¥
    - ä»»æ„ Agent éƒ½å¯ä»¥é€šè¿‡ state.pending_requests å‘èµ·ï¼š
      - äººæœºäº¤äº’ï¼ˆinterruptï¼‰
      - å§”æ´¾ç»™å…¶ä»– Agent çš„å­ä»»åŠ¡ï¼ˆdelegateï¼‰
    """

    def __init__(
        self,
        checkpointer: BaseCheckpointSaver | None = None,
        max_iterations: int | None = None,
        agent_max_retries: int | None = None,
        max_human_requests: int | None = None,
    ):
        """
        åˆå§‹åŒ–ç¼–æ’å™¨

        Args:
            checkpointer: LangGraph checkpoint å­˜å‚¨
            max_iterations: æœ€å¤§è¿­ä»£æ¬¡æ•°ï¼ˆæµ‹è¯•å¾ªç¯ï¼‰
            agent_max_retries: Agent æ‰§è¡Œå¤±è´¥æ—¶çš„æœ€å¤§é‡è¯•æ¬¡æ•°
        """
        self.checkpointer = checkpointer or InMemorySaver()
        self.max_iterations = int(
            max_iterations
            if max_iterations is not None
            else settings.get("etl_orchestrator_max_iterations", 3)
        )
        self.agent_max_retries = int(
            agent_max_retries
            if agent_max_retries is not None
            else settings.get("etl_orchestrator_agent_max_retries", 2)
        )
        self.max_human_requests = int(
            max_human_requests
            if max_human_requests is not None
            else settings.get("etl_orchestrator_max_human_requests", 6)
        )

        # åˆå§‹åŒ– Memory
        self.memory = MemoryManager()

        # åˆå§‹åŒ–æ‰€æœ‰ Agent
        self.knowledge_agent = KnowledgeAgent()
        self.analyst_agent = AnalystAgent()
        self.architect_agent = ArchitectAgent()
        self.developer_agent = DeveloperAgent()
        self.tester_agent = TesterAgent()

        # æ„å»º LangGraph
        self.graph = self._build_graph()

        logger.info("âœ… EtlOrchestrator åˆå§‹åŒ–å®Œæˆ")

    def _wrap_agent_with_retry(self, agent, agent_name: str):
        """
        åŒ…è£… Agentï¼Œæ·»åŠ é‡è¯•æœºåˆ¶

        Args:
            agent: Agent å®ä¾‹
            agent_name: Agent åç§°ï¼ˆç”¨äºæ—¥å¿—å’Œé”™è¯¯æç¤ºï¼‰

        Returns:
            åŒ…è£…åçš„ Agent å‡½æ•°
        """
        # ä¸åº”é‡è¯•çš„é”™è¯¯ï¼ˆå‰ç½®ä¾èµ–ç¼ºå¤±ï¼‰
        non_retryable_errors = [
            "ç¼ºå°‘éœ€æ±‚åˆ†æç»“æœ",
            "ç¼ºå°‘æ¶æ„æ–¹æ¡ˆ",
            "ç¼ºå°‘",  # é€šç”¨å‰ç¼€
        ]

        def is_retryable_error(error_str: str) -> bool:
            """åˆ¤æ–­é”™è¯¯æ˜¯å¦å¯é‡è¯•"""
            for pattern in non_retryable_errors:
                if pattern in error_str:
                    return False
            return True

        async def wrapped(state: AgentState) -> Command:
            last_error = None

            for attempt in range(self.agent_max_retries + 1):
                try:
                    if attempt > 0:
                        logger.warning(f"ğŸ”„ {agent_name} ç¬¬ {attempt} æ¬¡é‡è¯•...")

                    result = await agent(state)

                    # æ£€æŸ¥è¿”å›ç»“æœä¸­æ˜¯å¦æœ‰ error å­—æ®µ
                    if isinstance(result, Command) and result.update:
                        error = result.update.get("error")
                        if error:
                            # æ£€æŸ¥æ˜¯å¦å¯é‡è¯•
                            if not is_retryable_error(str(error)):
                                logger.info(f"â„¹ï¸ {agent_name} é”™è¯¯ä¸å¯é‡è¯•: {error}")
                                return result

                            if attempt < self.agent_max_retries:
                                logger.warning(f"âš ï¸ {agent_name} è¿”å›é”™è¯¯: {error}ï¼Œå‡†å¤‡é‡è¯•...")
                                last_error = Exception(error)
                                continue

                    return result

                except Exception as e:
                    # æ£€æŸ¥æ˜¯å¦æ˜¯ LangGraph interrupt å¼‚å¸¸ï¼Œå¦‚æœæ˜¯åˆ™ç›´æ¥ä¼ æ’­
                    # interrupt å¼‚å¸¸ä¸åº”è¢«é‡è¯•æœºåˆ¶æ•è·
                    if "Interrupt" in type(e).__name__ or "interrupt" in str(type(e)).lower():
                        raise

                    last_error = e
                    logger.warning(
                        f"âš ï¸ {agent_name} æ‰§è¡Œå¼‚å¸¸ (å°è¯• {attempt + 1}/{self.agent_max_retries + 1}): {e}"
                    )

                    if attempt < self.agent_max_retries:
                        continue

            # æ‰€æœ‰é‡è¯•éƒ½å¤±è´¥äº†ï¼Œè¿”å›å‹å¥½é”™è¯¯
            error_msg = self._format_agent_error(agent_name, last_error)
            logger.error(f"âŒ {agent_name} æœ€ç»ˆå¤±è´¥: {last_error}")

            return Command(
                update={
                    "messages": [AIMessage(content=error_msg)],
                    "current_agent": agent_name,
                    "error": str(last_error),
                }
            )

        return wrapped

    def _format_agent_error(self, agent_name: str, error: Exception) -> str:
        """æ ¼å¼åŒ– Agent é”™è¯¯ä¸ºç”¨æˆ·å‹å¥½æç¤º"""
        error_str = str(error)

        # JSON è§£æé”™è¯¯
        if "JSON" in error_str or "json" in error_str:
            return f"{agent_name} å¤„ç†å¤±è´¥ï¼šAI å“åº”æ ¼å¼å¼‚å¸¸ï¼Œå·²é‡è¯•å¤šæ¬¡ä»æ— æ³•è§£æã€‚è¯·ç®€åŒ–éœ€æ±‚æè¿°åé‡è¯•ã€‚"

        # è¶…æ—¶é”™è¯¯
        if "timeout" in error_str.lower():
            return f"{agent_name} å¤„ç†å¤±è´¥ï¼šè¯·æ±‚è¶…æ—¶ï¼Œè¯·ç¨åé‡è¯•ã€‚"

        # API é™æµ
        if "rate" in error_str.lower() or "limit" in error_str.lower():
            return f"{agent_name} å¤„ç†å¤±è´¥ï¼šAI æœåŠ¡ç¹å¿™ï¼Œè¯·ç¨åé‡è¯•ã€‚"

        # é€šç”¨é”™è¯¯
        return f"{agent_name} å¤„ç†å¤±è´¥ï¼š{error_str[:100]}ã€‚è¯·é‡è¯•æˆ–ç®€åŒ–éœ€æ±‚ã€‚"

    def _build_graph(self):
        """
        æ„å»º LangGraph çŠ¶æ€å›¾

        ç»“æ„ï¼š
        START â†’ blackboard_router â†’ (åŠ¨æ€è·¯ç”±åˆ°ä»»æ„èŠ‚ç‚¹) â†’ ... â†’ blackboard_router â†’ finalize â†’ END

        è¯´æ˜ï¼š
        - æ‰€æœ‰èŠ‚ç‚¹æ‰§è¡Œç»“æŸåå›åˆ° blackboard_router
        - blackboard_router ä¼˜å…ˆå¤„ç† pending_requestsï¼ˆå…¨å±€å¯æŠ¢å ï¼‰
        - ä¸å†ä½¿ç”¨å›ºå®šçš„ clarification_handler/feedback_handler
        """
        builder = StateGraph(AgentState)

        # ===== æ·»åŠ èŠ‚ç‚¹ =====
        builder.add_node("blackboard_router", self._blackboard_router)
        builder.add_node("human_in_the_loop", self._handle_human_in_the_loop)

        builder.add_node(
            "knowledge_agent",
            self._wrap_agent_with_retry(self.knowledge_agent, "çŸ¥è¯†æ£€ç´¢ä¸“å®¶")
        )
        builder.add_node(
            "analyst_agent",
            self._wrap_agent_with_retry(self.analyst_agent, "éœ€æ±‚åˆ†æå¸ˆ")
        )
        builder.add_node(
            "architect_agent",
            self._wrap_agent_with_retry(self.architect_agent, "æ•°æ®æ¶æ„å¸ˆ")
        )
        builder.add_node(
            "developer_agent",
            self._wrap_agent_with_retry(self.developer_agent, "æ•°æ®å¼€å‘")
        )
        builder.add_node(
            "tester_agent",
            self._wrap_agent_with_retry(self.tester_agent, "æµ‹è¯•éªŒè¯")
        )
        builder.add_node("finalize", self._finalize)

        # ===== è®¾ç½®å…¥å£ =====
        builder.set_entry_point("blackboard_router")

        # ===== router åŠ¨æ€è·¯ç”± =====
        builder.add_conditional_edges(
            "blackboard_router",
            self._route_from_blackboard,
            {
                "human_in_the_loop": "human_in_the_loop",
                "knowledge_agent": "knowledge_agent",
                "analyst_agent": "analyst_agent",
                "architect_agent": "architect_agent",
                "developer_agent": "developer_agent",
                "tester_agent": "tester_agent",
                "finalize": "finalize",
            },
        )

        # æ‰€æœ‰èŠ‚ç‚¹æ‰§è¡Œç»“æŸå›åˆ° routerï¼ˆé»‘æ¿é©±åŠ¨ï¼‰
        builder.add_edge("human_in_the_loop", "blackboard_router")
        builder.add_edge("knowledge_agent", "blackboard_router")
        builder.add_edge("analyst_agent", "blackboard_router")
        builder.add_edge("architect_agent", "blackboard_router")
        builder.add_edge("developer_agent", "blackboard_router")
        builder.add_edge("tester_agent", "blackboard_router")

        # finalize â†’ END
        builder.add_edge("finalize", END)

        # ç¼–è¯‘å›¾
        if self.checkpointer:
            graph = builder.compile(checkpointer=self.checkpointer)
        else:
            graph = builder.compile()

        logger.info("LangGraph çŠ¶æ€å›¾ç¼–è¯‘å®Œæˆ")
        return graph

    # ===== é»‘æ¿è·¯ç”±ä¸äººæœºäº¤äº’ =====

    @staticmethod
    def _now_ms() -> int:
        return int(time.time() * 1000)

    @staticmethod
    def _normalize_node_id(value: str | None) -> str | None:
        if not value:
            return value
        allowed = {
            "blackboard_router",
            "human_in_the_loop",
            "knowledge_agent",
            "analyst_agent",
            "architect_agent",
            "developer_agent",
            "tester_agent",
            "finalize",
        }
        if value in allowed:
            return value

        name_to_node = {
            "é»‘æ¿è·¯ç”±": "blackboard_router",
            "äººæœºäº¤äº’": "human_in_the_loop",
            "çŸ¥è¯†æ£€ç´¢ä¸“å®¶": "knowledge_agent",
            "éœ€æ±‚åˆ†æå¸ˆ": "analyst_agent",
            "æ•°æ®æ¶æ„å¸ˆ": "architect_agent",
            "æ•°æ®å¼€å‘": "developer_agent",
            "æµ‹è¯•éªŒè¯": "tester_agent",
            "å®Œæˆå¤„ç†": "finalize",
        }
        return name_to_node.get(value, value)

    async def _blackboard_router(self, state: AgentState) -> Command:
        """
        é»‘æ¿è·¯ç”±å™¨ï¼šåªè´Ÿè´£å†³å®š next_agentï¼ˆä»¥åŠå¿…è¦çš„æŠ¢å è¯·æ±‚åˆ›å»ºï¼‰
        """
        last_node = state.current_agent
        last_node_id = self._normalize_node_id(last_node)
        next_agent = "finalize"
        metadata = dict(state.metadata or {})
        request_results_update: dict[str, Any] | None = None
        counters = dict(state.delegation_counters or {})
        should_clear_error = False

        pending_requests: list[Any] = list(state.pending_requests or [])

        completed_delegate_resume_to: str | None = None

        # å¦‚æœé˜Ÿé¦–æ˜¯ delegate ä¸”ç›®æ ‡èŠ‚ç‚¹å·²æ‰§è¡Œå®Œæˆï¼Œåˆ™å‡ºé˜Ÿï¼ˆå¹¶æŒ‰ resume_to å›è·³ï¼‰
        if pending_requests:
            req0_raw = pending_requests[0]
            req0 = BlackboardRequest(**req0_raw) if isinstance(req0_raw, dict) else req0_raw
            if req0.kind == "delegate" and req0.target_agent:
                target_id = self._normalize_node_id(req0.target_agent) or req0.target_agent
                if last_node_id == target_id:
                    completed_delegate_resume_to = req0.resume_to
                    request_results = dict((state.request_results or {}))
                    request_results[req0.request_id] = {
                        "kind": "delegate",
                        "created_by": req0.created_by,
                        "target_agent": target_id,
                        "resume_to": req0.resume_to,
                        "completed_by": target_id,
                        "completed_at_ms": self._now_ms(),
                    }
                    request_results_update = request_results
                    pending_requests = pending_requests[1:]

        def has_pending_human(reqs: list[Any]) -> bool:
            for raw in reqs or []:
                req = BlackboardRequest(**raw) if isinstance(raw, dict) else raw
                if getattr(req, "kind", None) == "human" and getattr(req, "status", "pending") == "pending":
                    return True
            return False

        # 1) å…¨å±€å¯æŠ¢å ï¼šhuman è¯·æ±‚ä¼˜å…ˆï¼ˆé¿å… delegate é˜»å¡ç”¨æˆ·äº¤äº’ï¼‰
        if pending_requests and has_pending_human(pending_requests):
            next_agent = "human_in_the_loop"
        elif pending_requests:
            # 1.1) é humanï¼šä»…å¤„ç†é˜Ÿé¦–ï¼ˆä¿æŒ delegate å®Œæˆè¯­ä¹‰ä¾èµ–â€œé˜Ÿé¦–â†’æ‰§è¡Œâ†’å›è·³â€ï¼‰
            req0 = pending_requests[0]
            if isinstance(req0, dict):
                req0 = BlackboardRequest(**req0)
            if req0.kind == "delegate":
                target = req0.target_agent or ""
                target_id = self._normalize_node_id(target) if target else None
                next_agent = target_id if target_id else "finalize"
            else:
                next_agent = "finalize"
        else:
            # 1.2) åˆšå®Œæˆ delegateï¼šä¼˜å…ˆæŒ‰ resume_to å›è·³ï¼ˆä¿è¯â€œå§”æ´¾â†’è¿”å›â€é—­ç¯è¯­ä¹‰ï¼‰
            resume_to = self._normalize_node_id(completed_delegate_resume_to) if completed_delegate_resume_to else None
            if resume_to and resume_to not in {"blackboard_router"} and resume_to in {
                "human_in_the_loop",
                "knowledge_agent",
                "analyst_agent",
                "architect_agent",
                "developer_agent",
                "tester_agent",
                "finalize",
            }:
                next_agent = resume_to
            else:
                # 2) æ—  pending_requestsï¼šä¼˜å…ˆå¤„ç†å¯æ¢å¤é”™è¯¯ï¼ˆé¿å…ç›´æ¥ finalize é€ æˆâ€œå‡å®Œæˆâ€ï¼‰
                if state.error:
                    recover_count = int(counters.get("orchestrator:error_recovery") or 0)
                    if state.human_request_count < state.max_human_requests and recover_count < 1:
                        req = BlackboardRequest(
                            request_id=f"req_{uuid.uuid4().hex}",
                            kind="human",
                            created_by="blackboard_router",
                            resume_to="blackboard_router",
                            payload={
                                "type": "error_recovery",
                                "message": "ç³»ç»Ÿåœ¨ç”Ÿæˆå·¥ä½œæµæ—¶é‡åˆ°å¼‚å¸¸ï¼Œéœ€è¦ä½ è¡¥å……ä¿¡æ¯æˆ–ç®€åŒ–æè¿°åç»§ç»­ã€‚",
                                "questions": [
                                    "è¯·ç”¨æ›´å…·ä½“çš„ä¸€å¥è¯é‡è¿°éœ€æ±‚ï¼ˆå°½é‡æ˜ç¡®æºæ•°æ®èŒƒå›´ä¸ç›®æ ‡äº§ç‰©ï¼‰ã€‚",
                                    "å¦‚æœæ–¹ä¾¿ï¼šè¯·æä¾›ä»»æ„ä¸€é¡¹å¯éªŒè¯çº¿ç´¢ï¼ˆç°æœ‰ SQL/å­—æ®µæ¸…å•/ä¸Šæ¸¸è¡¨å/ç›®æ ‡è¡¨åï¼‰ã€‚",
                                ],
                                "error": str(state.error)[:500],
                            },
                        )
                        pending_requests.append(req)
                        counters["orchestrator:error_recovery"] = recover_count + 1
                        metadata["last_error"] = {
                            "error": str(state.error),
                            "at_ms": self._now_ms(),
                            "recovered_by": "human",
                        }
                        should_clear_error = True
                        next_agent = "human_in_the_loop"
                    else:
                        next_agent = "finalize"
                else:
                    # 3) åŠ¨æ€é€‰æ‹©ä¸‹ä¸€æ­¥ï¼ˆåŸºäºé»‘æ¿äº§ç‰©ï¼‰
                    if not state.analysis_result:
                        next_agent = "analyst_agent"
                    elif not state.architecture_plan:
                        next_agent = "architect_agent"
                    else:
                        # plan å·²å­˜åœ¨ï¼šå¦‚æœ Job è¿˜æ²¡ç”Ÿæˆ SQLï¼Œåˆ™èµ° developer
                        plan = state.architecture_plan
                        jobs = plan.get("jobs", []) if isinstance(plan, dict) else getattr(plan, "jobs", [])
                        has_unbuilt_sql = any(
                            not (
                                j.get("config_generated")
                                if isinstance(j, dict)
                                else getattr(j, "config_generated", False)
                            )
                            for j in jobs
                        )
                        if has_unbuilt_sql:
                            next_agent = "developer_agent"
                        else:
                            test_result = state.test_result
                            passed = False
                            if test_result:
                                passed = (
                                    test_result.get("passed", False)
                                    if isinstance(test_result, dict)
                                    else getattr(test_result, "passed", False)
                                )
                            if not test_result:
                                next_agent = "tester_agent"
                            elif not passed and state.iteration_count < state.max_iterations:
                                next_agent = "developer_agent"
                            else:
                                next_agent = "finalize"

        update: dict[str, Any] = {
            "current_agent": "blackboard_router",
            "next_agent": next_agent,
            "last_node": last_node,
            "metadata": metadata,
        }
        update["pending_requests"] = [r.model_dump() if hasattr(r, "model_dump") else r for r in pending_requests]
        if request_results_update is not None:
            update["request_results"] = request_results_update
        if counters != (state.delegation_counters or {}):
            update["delegation_counters"] = counters
        if should_clear_error:
            update["error"] = None
        return Command(update=update)

    @staticmethod
    def _route_from_blackboard(state: AgentState) -> Literal[
        "human_in_the_loop",
        "knowledge_agent",
        "analyst_agent",
        "architect_agent",
        "developer_agent",
        "tester_agent",
        "finalize",
    ]:
        next_agent = state.next_agent or "finalize"
        allowed = {
            "human_in_the_loop",
            "knowledge_agent",
            "analyst_agent",
            "architect_agent",
            "developer_agent",
            "tester_agent",
            "finalize",
        }
        return next_agent if next_agent in allowed else "finalize"

    async def _handle_human_in_the_loop(self, state: AgentState) -> Command:
        """
        ç»Ÿä¸€çš„äººæœºäº¤äº’å¤„ç†èŠ‚ç‚¹ï¼ˆå…¨å±€å¯æŠ¢å ï¼‰
        - ä¼˜å…ˆå¤„ç†é˜Ÿåˆ—ä¸­æœ€æ—©çš„ human requestï¼ˆå…è®¸ human æŠ¢å ï¼‰
        - interrupt ç­‰å¾…ç”¨æˆ·è¾“å…¥
        - å®Œæˆåä»é˜Ÿåˆ—ç§»é™¤è¯¥è¯·æ±‚å¹¶å›åˆ° blackboard_router
        """
        if not state.pending_requests:
            return Command(update={"current_agent": "human_in_the_loop"})

        if state.human_request_count >= state.max_human_requests:
            return Command(
                update={
                    "current_agent": "human_in_the_loop",
                    "error": f"å·²è¾¾åˆ°æœ€å¤§äººæœºäº¤äº’æ¬¡æ•°é™åˆ¶: {state.max_human_requests}",
                }
            )

        req_index: int | None = None
        req: BlackboardRequest | None = None
        for idx, raw in enumerate(state.pending_requests):
            cand = BlackboardRequest(**raw) if isinstance(raw, dict) else raw
            if cand.kind == "human" and cand.status == "pending":
                req_index = idx
                req = cand
                break
        if req_index is None or req is None:
            return Command(
                update={
                    "current_agent": "human_in_the_loop",
                    "error": "human_in_the_loop æœªæ‰¾åˆ°å¯å¤„ç†çš„ human è¯·æ±‚ï¼ˆå¯èƒ½å·²å®Œæˆæˆ–é˜Ÿåˆ—å¼‚å¸¸ï¼‰",
                }
            )

        interrupt_payload = dict(req.payload or {})
        if "type" not in interrupt_payload:
            interrupt_payload["type"] = "human_input"
        if "message" not in interrupt_payload:
            interrupt_payload["message"] = "è¯·è¡¥å……ä¿¡æ¯ä»¥ä¾¿ç»§ç»­"

        logger.info("â¸ï¸ ç­‰å¾…ç”¨æˆ·è¾“å…¥: request_id=%s, type=%s", req.request_id, interrupt_payload.get("type"))
        user_response = interrupt(interrupt_payload)

        request_results = dict((state.request_results or {}))
        request_results[req.request_id] = {
            "kind": "human",
            "created_by": req.created_by,
            "resume_to": req.resume_to,
            "completed_by": "human_in_the_loop",
            "completed_at_ms": self._now_ms(),
            "payload_type": interrupt_payload.get("type"),
            "writeback_key": interrupt_payload.get("writeback_key"),
            "response_preview": str(user_response)[:200],
        }

        # å®Œæˆå‡ºé˜Ÿï¼ˆä»…ç§»é™¤æœ¬æ¬¡å¤„ç†çš„ human requestï¼‰
        remaining = list(state.pending_requests)
        remaining.pop(req_index)
        responses = dict((state.human_responses or {}))
        responses[req.request_id] = user_response
        writeback_key = interrupt_payload.get("writeback_key")
        writebacks = dict((state.human_writebacks or {}))

        update_selected_component: dict[str, Any] = {}
        if isinstance(writeback_key, str) and writeback_key.strip():
            writebacks[writeback_key] = user_response
            # å…³é”®å­—æ®µæ˜¾å¼åŒ–ï¼šselected_component ç”± human writeback ç»Ÿä¸€å†™å…¥ state å­—æ®µ
            if writeback_key == "selected_component":
                normalized_code: str | None = None
                normalized_id: int | None = None
                if isinstance(user_response, str):
                    normalized_code = user_response.strip()
                elif isinstance(user_response, dict):
                    raw_code = user_response.get("component") or user_response.get("value") or user_response.get("code")
                    if isinstance(raw_code, str) and raw_code.strip():
                        normalized_code = raw_code.strip()
                    raw_id = user_response.get("id") or user_response.get("component_id")
                    if isinstance(raw_id, int):
                        normalized_id = raw_id
                    elif isinstance(raw_id, str) and raw_id.isdigit():
                        normalized_id = int(raw_id)

                if normalized_code:
                    update_selected_component["selected_component"] = normalized_code
                if normalized_id is not None:
                    update_selected_component["selected_component_id"] = normalized_id

        # å¯¹ clarificationsï¼šæŠŠç”¨æˆ·è¡¥å……å¹¶å…¥ user_inputï¼ˆä¿æŒä¸ç°æœ‰ Agent è¯»å–æ–¹å¼ä¸€è‡´ï¼‰
        merged_user_input = state.user_input
        if interrupt_payload.get("type") in {"clarification", "error_recovery"}:
            merged_user_input = f"{state.user_input}\nç”¨æˆ·è¡¥å……: {user_response}"

        return Command(
            update={
                "messages": [HumanMessage(content=f"ç”¨æˆ·è¾“å…¥: {user_response}")],
                "user_input": merged_user_input,
                "pending_requests": [r.model_dump() if hasattr(r, "model_dump") else r for r in remaining],
                "human_request_count": state.human_request_count + 1,
                "current_agent": "human_in_the_loop",
                "human_responses": responses,
                "human_writebacks": writebacks,
                "request_results": request_results,
                **update_selected_component,
            }
        )

    async def _finalize(self, state: AgentState) -> Command:
        """æœ€ç»ˆå¤„ç† - ç”Ÿæˆå¯æ¸²æŸ“çš„ DAG"""
        logger.info("ğŸ‰ å·¥ä½œæµå®Œæˆï¼Œç”Ÿæˆ DAG è¾“å‡º")

        # è·å– plan
        plan = state.architecture_plan
        dag_output = None

        if state.error and not plan:
            summary = f"å·¥ä½œæµç”Ÿæˆå¤±è´¥ï¼š{str(state.error)[:200]}"
            return Command(
                update={
                    "messages": [AIMessage(content=summary)],
                    "dag_output": None,
                    "current_agent": "finalize",
                    "is_completed": True,
                }
            )

        if plan:
            # è½¬æ¢ä¸º Workflow å¯¹è±¡
            if isinstance(plan, dict):
                plan_obj = Workflow(**plan)
            else:
                plan_obj = plan

            # è½¬æ¢ä¸ºå·¥ä½œæµå“åº”æ ¼å¼
            workflow_response = WorkflowResponse.from_workflow(plan_obj)
            dag_output = workflow_response.model_dump()

            # ç”Ÿæˆæ‘˜è¦
            job_count = len(workflow_response.jobs)
            dep_count = len(workflow_response.dependencies)
            summary = f"ç”Ÿæˆå®Œæˆï¼š{workflow_response.workflowName}ï¼Œå…± {job_count} ä¸ªä»»åŠ¡ã€{dep_count} æ¡ä¾èµ–"
            logger.info(f"ğŸ“Š {summary}")
        else:
            summary = "å·¥ä½œæµç”Ÿæˆå®Œæˆï¼Œä½†ç¼ºå°‘æ¶æ„æ–¹æ¡ˆ"

        return Command(
            update={
                "messages": [AIMessage(content=summary)],
                "dag_output": dag_output,
                "current_agent": "finalize",
                "is_completed": True,
            }
        )

    # ===== å…¬å…±æ¥å£ =====

    async def run(
        self,
        user_input: str,
        session_id: str,
        user_id: str,
    ) -> dict[str, Any]:
        """
        åŒæ­¥æ‰§è¡Œï¼ˆç­‰å¾…å®Œæˆï¼‰

        Args:
            user_input: ç”¨æˆ·è¾“å…¥
            session_id: ä¼šè¯ID
            user_id: ç”¨æˆ·ID

        Returns:
            æœ€ç»ˆçŠ¶æ€
        """
        config = self._build_config(session_id, user_id)

        initial_state = {
            "session_id": session_id,
            "user_id": user_id,
            "user_input": user_input,
            "messages": [HumanMessage(content=user_input)],
            "max_iterations": self.max_iterations,
            "max_human_requests": self.max_human_requests,
            "referenced_sql_ids": [],  # æ˜¾å¼æ¸…ç©ºï¼Œé¿å…è·¨ session æ±¡æŸ“
            "pending_requests": [],
            "human_request_count": 0,
            "delegation_counters": {},
            "request_results": {},
            "human_responses": {},
            "human_writebacks": {},
            "selected_component": None,
            "selected_component_id": None,
            "last_node": None,
        }

        final_state = await self.graph.ainvoke(initial_state, config=config)
        return final_state

    async def stream(
        self,
        user_input: str,
        session_id: str,
        user_id: str,
        resume_value: Any | None = None,
    ) -> AsyncGenerator[dict[str, Any], None]:
        """
        æµå¼æ‰§è¡Œï¼ˆç»Ÿä¸€æ¶ˆæ¯æµï¼‰

        äº‹ä»¶ç±»å‹ï¼ˆè§ src/modules/etl/schemas/sse_msg.pyï¼‰ï¼š
        - agent.start / agent.end
        - llm.start / llm.end
        - tool.start / tool.end
        - interrupt / result / error

        Args:
            user_input: ç”¨æˆ·è¾“å…¥
            session_id: ä¼šè¯ID
            user_id: ç”¨æˆ·ID
            resume_value: æ¢å¤å€¼ï¼ˆç”¨äºä¸­æ–­æ¢å¤ï¼‰

        Yields:
            SseEvent.to_dict() æ ¼å¼çš„äº‹ä»¶
        """
        config = self._build_config(session_id, user_id)

        if resume_value is not None:
            input_data = Command(resume=resume_value)
        else:
            input_data = {
                "session_id": session_id,
                "user_id": user_id,
                "user_input": user_input,
                "messages": [HumanMessage(content=user_input)],
                "max_iterations": self.max_iterations,
                "max_human_requests": self.max_human_requests,
                "referenced_sql_ids": [],
                "pending_requests": [],
                "human_request_count": 0,
                "delegation_counters": {},
                "request_results": {},
                "human_responses": {},
                "human_writebacks": {},
                "selected_component": None,
                "selected_component_id": None,
                "last_node": None,
            }

        # å½“å‰æ­£åœ¨æ‰§è¡Œçš„é¡¶å±‚èŠ‚ç‚¹ï¼ˆç”¨äºç»‘å®š tool/llm äº‹ä»¶ï¼‰
        active_node: str | None = None
        active_agent_id: str | None = None
        active_agent_name: str | None = None

        # äº‹ä»¶å»å™ªï¼šè¿ç»­é‡å¤çš„ tool.start/tool.end/llm.start ç›´æ¥è·³è¿‡
        last_event_fingerprint: str | None = None

        def _compact(value: Any) -> str | None:
            if value is None:
                return None
            text = str(value)
            return text[:2000] if len(text) > 2000 else text

        def _fingerprint(payload: dict[str, Any]) -> str:
            tool = payload.get("tool") or {}
            llm = payload.get("llm") or {}
            agent = payload.get("agent") or {}
            span = payload.get("span") or {}
            return json.dumps(
                {
                    "event": payload.get("event"),
                    "agent": agent.get("id"),
                    "run_id": span.get("run_id"),
                    "tool": tool.get("name"),
                    "tool_in": _compact(tool.get("input")),
                    "tool_out": _compact(tool.get("output")),
                    "llm": llm.get("name"),
                },
                ensure_ascii=False,
                sort_keys=True,
                default=str,
            )

        def _emit(evt: SseEvent) -> dict[str, Any] | None:
            nonlocal last_event_fingerprint
            payload = evt.to_dict()
            fp = _fingerprint(payload)
            if fp == last_event_fingerprint:
                return None
            last_event_fingerprint = fp
            return payload

        try:
            async for event in self.graph.astream_events(
                input_data,
                config=config,
                version="v2",
            ):
                kind = event.get("event")
                meta = event.get("metadata", {})
                node = meta.get("langgraph_node")
                run_id = event.get("run_id")
                parent_run_id = event.get("parent_run_id")

                def _bind_agent_from_node(node_id: str) -> tuple[str, str]:
                    return node_id, self._agent_display_name(node_id)

                # åªå…³å¿ƒé¡¶å±‚ç¼–æ’èŠ‚ç‚¹ï¼ˆé¿å…å†…éƒ¨ chain äº‹ä»¶åˆ·å±ï¼‰
                is_top_node = node in {
                    "blackboard_router",
                    "human_in_the_loop",
                    "knowledge_agent",
                    "analyst_agent",
                    "architect_agent",
                    "developer_agent",
                    "tester_agent",
                    "finalize",
                }

                # blackboard_router/human_in_the_loop éƒ½æ˜¯â€œç³»ç»ŸèŠ‚ç‚¹â€ï¼š
                # - blackboard_routerï¼šå†…éƒ¨è°ƒåº¦å™ªå£°
                # - human_in_the_loopï¼šå‰ç«¯åªéœ€è¦å±•ç¤º interrupt äº‹ä»¶ï¼ˆwaitingï¼‰ï¼Œä¸éœ€è¦ agent.start/end
                is_hidden_agent_node = node in {"blackboard_router", "human_in_the_loop"}

                # é¡¶å±‚ Agent å¼€å§‹
                if kind == "on_chain_start" and node and is_top_node:
                    # é˜²æ­¢åŒä¸€èŠ‚ç‚¹çš„é‡å¤ on_chain_start å¯¼è‡´å‰ç«¯å‡ºç°â€œé‡å¤å¼€å§‹â€
                    if active_node == node and active_agent_id:
                        continue
                    active_node = node
                    active_agent_id, active_agent_name = _bind_agent_from_node(node)
                    if is_hidden_agent_node:
                        continue
                    maybe = _emit(
                        SseEvent.agent_start(
                            agent_id=active_agent_id,
                            agent_name=active_agent_name,
                            run_id=run_id,
                            parent_run_id=parent_run_id,
                        )
                    )
                    if maybe:
                        yield maybe
                    continue

                # é¡¶å±‚ Agent ç»“æŸ
                if kind == "on_chain_end" and node and is_top_node:
                    # åªå¯¹å½“å‰ active_node å‘ endï¼Œé¿å…é‡å¤ç»“æŸäº‹ä»¶åˆ·å±
                    if active_node != node:
                        continue
                    agent_id, agent_name = _bind_agent_from_node(node)
                    summary = None
                    data = event.get("data") or {}
                    output = data.get("output")
                    if isinstance(output, dict):
                        msgs = output.get("messages")
                        if isinstance(msgs, list) and msgs:
                            last_msg = msgs[-1]
                            if hasattr(last_msg, "content"):
                                summary = getattr(last_msg, "content", None)
                    if not is_hidden_agent_node:
                        maybe = _emit(
                            SseEvent.agent_end(
                                agent_id=agent_id,
                                agent_name=agent_name,
                                summary=summary,
                                run_id=run_id,
                                parent_run_id=parent_run_id,
                            )
                        )
                        if maybe:
                            yield maybe
                    if active_node == node:
                        active_node = None
                        active_agent_id = None
                        active_agent_name = None
                    continue

                # LLM start/end å¯¹å‰ç«¯ç”¨æˆ·æ˜¯å™ªå£°ï¼šä¸å†ä¸‹å‘
                if kind in {"on_chat_model_start", "on_llm_start", "on_chat_model_end", "on_llm_end"}:
                    continue

                # å·¥å…·è°ƒç”¨
                if kind == "on_tool_start":
                    if active_agent_id and active_agent_name:
                        if not self._should_emit_tool_start_sse(active_agent_id):
                            continue
                        tool_name = event.get("name", "unknown")
                        maybe = _emit(
                            SseEvent.tool_start(
                                agent_id=active_agent_id,
                                agent_name=active_agent_name,
                                tool_name=tool_name,
                                tool_input=None,
                                run_id=run_id,
                                parent_run_id=parent_run_id,
                            )
                        )
                        if maybe:
                            yield maybe
                    continue

                # tool.end å¯¹ç”¨æˆ·æ˜¯å™ªå£°ï¼šä¸å†ä¸‹å‘ï¼ˆåªä¿ç•™ tool.startï¼‰
                if kind == "on_tool_end":
                    continue

            # æ£€æŸ¥ä¸­æ–­
            snapshot = await self.graph.aget_state(config)
            if snapshot.tasks and snapshot.tasks[0].interrupts:
                interrupt_data = snapshot.tasks[0].interrupts[0].value
                # interrupt å‘ç”Ÿæ—¶ current_agent å¯èƒ½æ˜¯ handlerï¼Œè¿™é‡Œä¼˜å…ˆç”¨ interrupt.type æ˜ å°„
                kind = interrupt_data.get("type") or "interrupt"
                agent_id = active_agent_id or "human_in_the_loop"
                agent_name = active_agent_name or self._agent_display_name(agent_id)
                yield SseEvent.interrupt_event(
                    agent_id=agent_id,
                    agent_name=agent_name,
                    kind=kind,
                    message=interrupt_data.get("message", "è¯·å›ç­”ä»¥ä¸‹é—®é¢˜"),
                    questions=interrupt_data.get("questions"),
                    options=interrupt_data.get("options"),
                ).to_dict()
                return

            # å®Œæˆ
            workflow = None
            if snapshot and snapshot.values:
                workflow = snapshot.values.get("dag_output")
                error = snapshot.values.get("error")
                if error:
                    current_agent = snapshot.values.get("current_agent")
                    node_to_name = {
                        "blackboard_router": "é»‘æ¿è·¯ç”±",
                        "human_in_the_loop": "äººæœºäº¤äº’",
                        "knowledge_agent": "çŸ¥è¯†æ£€ç´¢ä¸“å®¶",
                        "analyst_agent": "éœ€æ±‚åˆ†æå¸ˆ",
                        "architect_agent": "æ•°æ®æ¶æ„å¸ˆ",
                        "developer_agent": "æ•°æ®å¼€å‘",
                        "tester_agent": "æµ‹è¯•éªŒè¯",
                        "finalize": "å®Œæˆå¤„ç†",
                    }
                    name_to_node = {v: k for k, v in node_to_name.items()}
                    agent_id = None
                    agent_name = None
                    if isinstance(current_agent, str):
                        if current_agent in node_to_name:
                            agent_id = current_agent
                            agent_name = node_to_name[current_agent]
                        elif current_agent in name_to_node:
                            agent_id = name_to_node[current_agent]
                            agent_name = current_agent
                    yield SseEvent.error_event(
                        message="æ‰§è¡Œå¤±è´¥",
                        detail=str(error),
                        agent_id=agent_id,
                        agent_name=agent_name,
                    ).to_dict()
                    return

            if workflow:
                yield SseEvent.result_event(workflow=workflow, message="ç”Ÿæˆå®Œæˆ").to_dict()
            else:
                yield SseEvent.result_event(workflow=None, message="å¤„ç†å®Œæˆï¼Œä½†æœªç”Ÿæˆå·¥ä½œæµ").to_dict()

        except Exception as e:
            logger.error(f"æµå¼æ‰§è¡Œå¤±è´¥: {e}", exc_info=True)
            yield SseEvent.error_event(message="æ‰§è¡Œå¤±è´¥", detail=str(e)).to_dict()

    @staticmethod
    def _should_emit_tool_start_sse(agent_id: str) -> bool:
        return agent_id != "knowledge_agent"

    def _build_config(self, session_id: str, user_id: str) -> dict[str, Any]:
        """æ„å»ºé…ç½®"""
        thread_id = f"etl:user:{user_id}:session:{session_id}"
        return {
            "configurable": {
                "thread_id": thread_id,
                "session_id": session_id,
                "user_id": user_id,
            }
        }

    @staticmethod
    def _agent_display_name(node: str) -> str:
        """è·å– Agent å±•ç¤ºåç§°"""
        names = {
            "blackboard_router": "é»‘æ¿è·¯ç”±",
            "human_in_the_loop": "äººæœºäº¤äº’",
            "knowledge_agent": "çŸ¥è¯†æ£€ç´¢ä¸“å®¶",
            "analyst_agent": "éœ€æ±‚åˆ†æå¸ˆ",
            "architect_agent": "æ•°æ®æ¶æ„å¸ˆ",
            "developer_agent": "æ•°æ®å¼€å‘",
            "tester_agent": "æµ‹è¯•éªŒè¯",
            "learning_handler": "å­¦ä¹ æ²‰æ·€",
            "finalize": "å®Œæˆå¤„ç†",
        }
        return names.get(node, node)


async def create_etl_orchestrator(
    checkpointer: BaseCheckpointSaver | None = None,
    max_iterations: int = 3,
    agent_max_retries: int = 2,
) -> EtlOrchestrator:
    """
    åˆ›å»º ETL ç¼–æ’å™¨

    Args:
        checkpointer: LangGraph checkpoint å­˜å‚¨
        max_iterations: æœ€å¤§è¿­ä»£æ¬¡æ•°
        agent_max_retries: Agent æ‰§è¡Œå¤±è´¥æ—¶çš„æœ€å¤§é‡è¯•æ¬¡æ•°

    Returns:
        EtlOrchestrator å®ä¾‹
    """
    return EtlOrchestrator(
        checkpointer=checkpointer,
        max_iterations=max_iterations,
        agent_max_retries=agent_max_retries,
    )
