# Datapillar AI 配置文件（企业级标准）
# 配置优先级：环境变量 > settings.local.toml > .secrets.toml > settings.{ENV}.toml > settings.toml

[default]
# ==================== FastAPI 配置 ====================
app_name = "Datapillar AI"
app_version = "1.0.0"
app_host = "0.0.0.0"
app_port = 6003
debug = false

# ==================== Neo4j 配置 ====================
neo4j_uri = "bolt://localhost:7687"
neo4j_username = "neo4j"
neo4j_database = "neo4j"

# ==================== MySQL 配置 ====================
mysql_host = "localhost"
mysql_port = 3306
mysql_database = "datapillar"
mysql_username = "root"

# ==================== Gravitino 元数据库配置 ====================
# 支持 mysql, postgresql, h2
gravitino_db_type = "mysql"
gravitino_db_host = "localhost"
gravitino_db_port = 3306
gravitino_db_database = "gravitino"
gravitino_db_username = "root"
# 只同步指定 metalake 下的数据
gravitino_sync_metalake = "OneMeta"

# ==================== Redis 配置 ====================
redis_host = "127.0.0.1"
redis_port = 6379
redis_db = 0
redis_password = ""
redis_checkpoint_ttl_seconds = 604800  # 7天

# ==================== JWT 认证配置 ====================
jwt_issuer = "datapillar-auth"
auth_enabled = true  # 是否启用认证，开发调试时可设为 false

# ==================== ETL 多智能体配置 ====================
# 说明：
# - 该模块的默认交付物是“ETL 工作流（Job/Stage/SQL）”
# - 阈值允许按环境/租户通过环境变量覆盖（DATAPILLAR_*）
etl_orchestrator_max_iterations = 3
etl_orchestrator_agent_max_retries = 2
etl_orchestrator_max_human_requests = 6

# ==================== ETL 对话记忆与上下文压缩 ====================
# 说明：
# - 对话记忆存放在 AgentState.messages，并由 LangGraph checkpoint（Redis）持久化
# - 这里的参数只影响“喂给 LLM 的历史对话窗口”，不影响持久化的数据本身
etl_conversation_history_max_messages = 12
# 统一用 token 口径（估算 token；真实 token 以厂商 usage 为准）
etl_conversation_history_max_tokens = 512
# OpenAI 兼容模型建议使用 cl100k_base；如需更贴近 gpt-4o 系列，可切到 o200k_base
etl_tokenizer_encoding = "cl100k_base"

# 说明：
# - 对话短记忆（agent_conversations）也会进入 checkpoint，为避免 session 膨胀需要做存储上限
# - 该上限只影响“记忆存储”，不影响 requirement_todo_store / artifact_store 等结构化长期记忆
etl_agent_conversation_max_turns_per_agent = 200
# 单条 turn 的上限同样用 token 口径（估算 token）
etl_agent_conversation_max_content_tokens_per_turn = 800

# ==================== ETL 语义指挥官（用户输入语义分流）====================
# 说明：
# - 前端不传 agent_id，由系统在无 pending human request 时做语义分流
# - 低置信（< 阈值）不允许随便路由：必须转为澄清（clarification）
etl_semantic_router_min_confidence = 0.7

# ==================== OpenLineage Sink 配置 ====================
# Sink 端负责接收事件并写入 Neo4j
# retry、rate_limit、filter 等配置由 Producer 端（Flink/Spark/Airflow）在 openlineage.yml 中配置
[default.openlineage_sink]
graceful_shutdown_timeout = 30.0

# 队列配置 - Sink 端二次保护机制
[default.openlineage_sink.queue]
max_size = 10000              # 最大队列大小
batch_size = 100              # 批量处理大小
flush_interval_seconds = 3.0  # 刷新间隔（秒）

# Neo4j 写入配置
[default.openlineage_sink.neo4j]
batch_size = 50               # 批量写入大小
max_concurrent = 10           # 最大并发写入数


# ==================== 开发环境 ====================
[development]
debug = true
app_name = "Datapillar AI [DEV]"
auth_enabled = false  # 开发环境关闭认证

# 开发环境数据库（可以用不同的数据库）
mysql_database = "datapillar"


# ==================== 生产环境 ====================
[production]
debug = false
app_name = "Datapillar AI"

# 生产环境配置（敏感信息在 .secrets.toml）
mysql_host = "prod-mysql.example.com"
neo4j_uri = "bolt://prod-neo4j.example.com:7687"
redis_host = "prod-redis.example.com"


# ==================== 测试环境 ====================
[testing]
debug = true
app_name = "Datapillar AI [TEST]"

# 测试数据库
mysql_database = "datapillar_test"
