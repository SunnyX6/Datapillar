# Datapillar AI 配置文件（企业级标准）
# 配置优先级：环境变量 > settings.local.toml > .secrets.toml > settings.{ENV}.toml > settings.toml

[default]
# ==================== FastAPI 配置 ====================
app_name = "Datapillar AI"
app_version = "1.0.0"
app_host = "0.0.0.0"
app_port = 6003
debug = false

# ==================== Neo4j 配置 ====================
neo4j_uri = "bolt://localhost:7687"
neo4j_username = "neo4j"
neo4j_database = "neo4j"

# ==================== MySQL 配置 ====================
mysql_host = "localhost"
mysql_port = 3306
mysql_database = "datapillar"
mysql_username = "root"

# ==================== Gravitino 元数据库配置 ====================
# 支持 mysql, postgresql, h2
gravitino_db_type = "mysql"
gravitino_db_host = "localhost"
gravitino_db_port = 3306
gravitino_db_database = "gravitino"
gravitino_db_username = "root"
# 只同步指定 metalake 下的数据
gravitino_sync_metalake = "OneMeta"

# ==================== Redis 配置 ====================
redis_host = "127.0.0.1"
redis_port = 6379
redis_db = 0
redis_password = ""
redis_checkpoint_ttl_seconds = 604800  # 7天

# ==================== JWT 认证配置 ====================
jwt_issuer = "datapillar-auth"
auth_enabled = true  # 是否启用认证，开发调试时可设为 false

# ==================== 弹性机制配置（通用） ====================
# 说明：
# - 适用于所有智能体、所有 LLM 调用场景
# - 技术故障（超时、网络抖动）自动重试，用户无感知
[default.resilience]
# 重试配置
max_retries = 3                    # 最大重试次数
initial_delay_ms = 500             # 初始延迟（毫秒）
max_delay_ms = 30000               # 最大延迟（毫秒）
exponential_base = 2               # 指数基数
jitter = true                      # 是否添加抖动（避免惊群效应）

# 超时配置
llm_timeout_seconds = 120          # LLM 调用超时
tool_timeout_seconds = 30          # 工具调用超时

# Agent 执行配置
max_iterations = 10                # LLM 调用轮次上限（每轮可调用多个工具）

# 熔断配置
circuit_failure_threshold = 5      # 连续失败次数触发熔断
circuit_recovery_timeout_seconds = 60  # 熔断恢复等待时间

# ==================== ETL 多智能体配置 ====================
# 说明：
# - 该模块的默认交付物是"ETL 工作流（Job/Stage/SQL）"
# - 阈值允许按环境/租户通过环境变量覆盖（DATAPILLAR_*）
etl_review_retry_threshold = 3     # Review 打回阈值（连续失败几次后暂停请求用户介入）

# ==================== ETL 对话记忆与上下文压缩 ====================
# 说明：
# - 对话记忆存放在 AgentState.messages，并由 LangGraph checkpoint（Redis）持久化
# - 这里的参数只影响“喂给 LLM 的历史对话窗口”，不影响持久化的数据本身
etl_conversation_history_max_messages = 8
# 统一用 token 口径（估算 token；真实 token 以厂商 usage 为准）
etl_conversation_history_max_tokens = 4096
# OpenAI 兼容模型建议使用 cl100k_base；如需更贴近 gpt-4o 系列，可切到 o200k_base
etl_tokenizer_encoding = "cl100k_base"

# 说明：
# - 对话短记忆（agent_conversations）也会进入 checkpoint，为避免 session 膨胀需要做存储上限
# - 该上限只影响“记忆存储”，不影响 requirement_todo_store / artifact_store 等结构化长期记忆
etl_agent_conversation_max_turns_per_agent = 200
# 单条 turn 的上限同样用 token 口径（估算 token）
etl_agent_conversation_max_content_tokens_per_turn = 800

# ==================== ETL 语义指挥官（用户输入语义分流）====================
# 说明：
# - 前端不传 agent_id，由系统在无 pending human request 时做语义分流
# - 低置信（< 阈值）不允许随便路由：必须转为澄清（clarification）
etl_semantic_router_min_confidence = 0.7

# ==================== ETL 记忆存储配置 ====================
# 说明：
# - BossMemory: Boss 的工作日志（Timeline），记录所有关键事件
# - WorkerMemory: Worker 的短期工作记忆，任务完成后可丢弃
# - 存储在 Redis，通过 TTL 自动清理
[default.etl_memory]
boss_memory_ttl_seconds = 604800      # Boss 记忆 TTL（7天）
worker_memory_ttl_seconds = 3600      # Worker 记忆 TTL（1小时）
timeline_max_entries = 100            # Timeline 最大条目数
timeline_compress_threshold = 80      # 触发压缩的阈值
timeline_compress_keep_recent = 15    # 压缩后保留最近多少条
timeline_entry_max_length = 500       # 单条 Timeline 内容最大长度
worker_turn_max_length = 2000         # Worker 对话单条最大长度
worker_compress_threshold = 20        # Worker 对话压缩阈值（对话轮次超过此值时触发压缩）
worker_keep_recent = 5                # Worker 对话压缩后保留最近多少轮

# ==================== OpenLineage Sink 配置 ====================
# Sink 端负责接收事件并写入 Neo4j
# retry、rate_limit、filter 等配置由 Producer 端（Flink/Spark/Airflow）在 openlineage.yml 中配置
[default.openlineage_sink]
graceful_shutdown_timeout = 30.0

# 队列配置 - Sink 端二次保护机制
[default.openlineage_sink.queue]
max_size = 10000              # 最大队列大小
batch_size = 100              # 批量处理大小
flush_interval_seconds = 3.0  # 刷新间隔（秒）

# Neo4j 写入配置
[default.openlineage_sink.neo4j]
batch_size = 50               # 批量写入大小
max_concurrent = 10           # 最大并发写入数

# ==================== LLM 缓存配置 ====================
# 说明：
# - 精确匹配缓存：相同输入 = 命中，任何差异 = 不命中
# - Redis 存储，支持 TTL，分布式友好
# - 解决 LangChain 动态 ID 问题，规范化后匹配
[default.llm_cache]
enabled = true                      # 是否启用缓存
ttl_seconds = 300                   # 缓存 TTL（秒）
key_prefix = "llm_cache:"           # Redis key 前缀

# ==================== SQL 摘要生成配置 ====================
# 说明：
# - 从 OpenLineage 事件解析的 SQL 可生成语义摘要，用于智能检索
# - 摘要由 LLM 生成，会产生 API 调用成本
# - 通过批量处理和去重机制控制成本
[default.sql_summary]
enabled = true                # 是否启用 SQL 摘要生成
batch_size = 5                # 积累多少条后批量处理（建议 3-10）
flush_interval_seconds = 300  # 最长等待时间（秒），超时自动处理
max_queue_size = 1000         # 队列最大容量，超出则丢弃新任务
max_sql_length = 10000        # SQL 最大长度（字符），超出则截断
min_sql_length = 50           # SQL 最小长度，太短的 SQL 跳过生成


# ==================== 开发环境 ====================
[development]
debug = true
app_name = "Datapillar AI [DEV]"
auth_enabled = false  # 开发环境关闭认证

# 开发环境数据库（可以用不同的数据库）
mysql_database = "datapillar"


# ==================== 生产环境 ====================
[production]
debug = false
app_name = "Datapillar AI"

# 生产环境配置（敏感信息在 .secrets.toml）
mysql_host = "prod-mysql.example.com"
neo4j_uri = "bolt://prod-neo4j.example.com:7687"
redis_host = "prod-redis.example.com"


# ==================== 测试环境 ====================
[testing]
debug = true
app_name = "Datapillar AI [TEST]"

# 测试数据库
mysql_database = "datapillar_test"
