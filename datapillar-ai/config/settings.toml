# Datapillar AI 配置文件（企业级标准）
# 配置优先级：环境变量 > settings.local.toml > .secrets.toml > settings.{ENV}.toml > settings.toml

[default]
# ==================== FastAPI 配置 ====================
app_name = "Datapillar AI"
app_version = "1.0.0"
app_host = "0.0.0.0"
app_port = 6003
debug = false

# ==================== Neo4j 配置 ====================
neo4j_uri = "bolt://localhost:7687"
neo4j_username = "neo4j"
neo4j_database = "neo4j"

# ==================== MySQL 配置 ====================
mysql_host = "localhost"
mysql_port = 3306
mysql_database = "datapillar"
mysql_username = "root"

# ==================== Gravitino 元数据库配置 ====================
# 支持 mysql, postgresql, h2
gravitino_db_type = "mysql"
gravitino_db_host = "localhost"
gravitino_db_port = 3306
gravitino_db_database = "gravitino"
gravitino_db_username = "root"
# 只同步指定 metalake 下的数据
gravitino_sync_metalake = "OneMeta"

# ==================== Redis 配置 ====================
redis_host = "127.0.0.1"
redis_port = 6379
redis_db = 0
redis_password = ""
redis_checkpoint_ttl_seconds = 604800  # 7天

# ==================== JWT 认证配置 ====================
jwt_issuer = "datapillar-auth"
auth_enabled = true  # 是否启用认证，开发调试时可设为 false

# ==================== ETL 多智能体配置 ====================
# 说明：
# - 该模块的默认交付物是“ETL 工作流（Job/Stage/SQL）”
# - 阈值允许按环境/租户通过环境变量覆盖（DATAPILLAR_*）
etl_orchestrator_max_iterations = 3
etl_orchestrator_agent_max_retries = 2
etl_orchestrator_max_human_requests = 6

# ==================== OpenLineage Sink 配置 ====================
# Sink 端负责接收事件并写入 Neo4j
# retry、rate_limit、filter 等配置由 Producer 端（Flink/Spark/Airflow）在 openlineage.yml 中配置
[default.openlineage_sink]
graceful_shutdown_timeout = 30.0

# 队列配置 - Sink 端二次保护机制
[default.openlineage_sink.queue]
max_size = 10000              # 最大队列大小
batch_size = 100              # 批量处理大小
flush_interval_seconds = 3.0  # 刷新间隔（秒）

# Neo4j 写入配置
[default.openlineage_sink.neo4j]
batch_size = 50               # 批量写入大小
max_concurrent = 10           # 最大并发写入数


# ==================== 开发环境 ====================
[development]
debug = true
app_name = "Datapillar AI [DEV]"
auth_enabled = false  # 开发环境关闭认证

# 开发环境数据库（可以用不同的数据库）
mysql_database = "datapillar"


# ==================== 生产环境 ====================
[production]
debug = false
app_name = "Datapillar AI"

# 生产环境配置（敏感信息在 .secrets.toml）
mysql_host = "prod-mysql.example.com"
neo4j_uri = "bolt://prod-neo4j.example.com:7687"
redis_host = "prod-redis.example.com"


# ==================== 测试环境 ====================
[testing]
debug = true
app_name = "Datapillar AI [TEST]"

# 测试数据库
mysql_database = "datapillar_test"
