"""
Orchestrator - ç¼–æ’å™¨

è´Ÿè´£ï¼š
1. æµå¼æ‰§è¡Œ
2. æ–­ç‚¹æ¢å¤
3. SSE äº‹ä»¶æµ
"""

from __future__ import annotations

import logging
import time
from collections.abc import AsyncGenerator
from typing import Any

from langchain_core.messages import HumanMessage
from langgraph.graph import StateGraph
from langgraph.types import Command

from datapillar_oneagentic.core.process import Process
from datapillar_oneagentic.events import event_bus, SessionStartedEvent, SessionCompletedEvent
from datapillar_oneagentic.state.blackboard import create_blackboard

logger = logging.getLogger(__name__)


def _now_ms() -> int:
    return int(time.time() * 1000)


class Orchestrator:
    """
    ç¼–æ’å™¨

    è´Ÿè´£æ‰§è¡Œå›¢é˜Ÿçš„å·¥ä½œæµç¨‹ã€‚
    """

    def __init__(
        self,
        *,
        namespace: str,
        name: str,
        graph: StateGraph,
        entry_agent_id: str,
        agent_ids: list[str],
        checkpointer,
        store,
        experience_learner=None,
        experience_retriever=None,
        process: Process = Process.SEQUENTIAL,
    ):
        """
        åˆ›å»ºç¼–æ’å™¨

        å‚æ•°ï¼š
        - namespace: å‘½åç©ºé—´ï¼ˆç”¨äºæ•°æ®éš”ç¦»ï¼‰
        - name: åç§°
        - graph: LangGraph çŠ¶æ€å›¾
        - entry_agent_id: å…¥å£ Agent ID
        - agent_ids: æ‰€æœ‰ Agent ID åˆ—è¡¨
        - checkpointer: Checkpointer å®ä¾‹
        - store: Store å®ä¾‹
        - experience_learner: ExperienceLearner å®ä¾‹ï¼ˆå¯é€‰ï¼‰
        - experience_retriever: ExperienceRetriever å®ä¾‹ï¼ˆå¯é€‰ï¼‰
        - process: æ‰§è¡Œæ¨¡å¼
        """
        self.namespace = namespace
        self.name = name
        self.graph = graph
        self.entry_agent_id = entry_agent_id
        self.agent_ids = agent_ids
        self.process = process

        # å­˜å‚¨å®ä¾‹
        self._checkpointer = checkpointer
        self._store = store

        # ç»éªŒå­¦ä¹ 
        self._experience_learner = experience_learner
        self._experience_retriever = experience_retriever

        # ç¼–è¯‘å›¾ï¼ˆå»¶è¿Ÿç¼–è¯‘ï¼‰
        self._compiled_graph = None

    def _make_thread_id(self, session_id: str) -> str:
        """
        æ„å»º thread_id

        ä½¿ç”¨ namespace:session_id æ ¼å¼ï¼Œç¡®ä¿ï¼š
        - ä¸åŒ namespace çš„æ•°æ®éš”ç¦»
        - åŒä¸€ namespace å†…ä¸åŒ session çš„æ•°æ®éš”ç¦»
        """
        return f"{self.namespace}:{session_id}"

    def _extract_thinking_from_message(self, msg: Any) -> str | None:
        """
        ä»æ¶ˆæ¯ä¸­æå–æ€è€ƒå†…å®¹

        æ”¯æŒå¤šç§æ¨¡å‹çš„æ€è€ƒæ ¼å¼ï¼š
        - GLM: additional_kwargs.reasoning_content
        - Claude: content ä¸­çš„ thinking blocks
        - DeepSeek: additional_kwargs.reasoning_content
        """
        if not hasattr(msg, "additional_kwargs"):
            return None

        # 1. GLM / DeepSeek æ ¼å¼ï¼ˆreasoning_contentï¼‰
        reasoning = msg.additional_kwargs.get("reasoning_content")
        if reasoning:
            return reasoning

        # 2. Claude æ ¼å¼ï¼ˆcontent æ˜¯ listï¼ŒåŒ…å« thinking blocksï¼‰
        content = getattr(msg, "content", None)
        if isinstance(content, list):
            thinking_parts = []
            for block in content:
                if isinstance(block, dict) and block.get("type") == "thinking":
                    thinking_parts.append(block.get("thinking", ""))
            if thinking_parts:
                return "\n".join(thinking_parts)

        return None

    async def _ensure_compiled(self):
        """ç¡®ä¿å›¾å·²ç¼–è¯‘"""
        if self._compiled_graph is None:
            self._compiled_graph = self.graph.compile(
                checkpointer=self._checkpointer,
                store=self._store,
            )

        return self._compiled_graph

    async def stream(
        self,
        *,
        query: str | None = None,
        session_id: str,
        resume_value: Any | None = None,
    ) -> AsyncGenerator[dict[str, Any], None]:
        """
        æµå¼æ‰§è¡Œ

        æ”¯æŒä¸‰ç§åœºæ™¯ï¼š
        1. æ–°ä¼šè¯/ç»­èŠï¼šquery ä¸ä¸ºç©ºï¼Œresume_value ä¸ºç©º
        2. interrupt æ¢å¤ï¼šresume_value ä¸ä¸ºç©ºï¼ˆquery å¯é€‰ï¼Œä½œä¸ºä¸Šä¸‹æ–‡ï¼‰
        3. çº¯ç»­èŠï¼šquery ä¸ä¸ºç©ºï¼Œå·²æœ‰ä¼šè¯çŠ¶æ€

        å‚æ•°ï¼š
        - query: ç”¨æˆ·è¾“å…¥ï¼ˆæ–°é—®é¢˜æˆ–ç»­èŠå†…å®¹ï¼‰
        - session_id: ä¼šè¯ IDï¼ˆç”±è°ƒç”¨æ–¹æ§åˆ¶ï¼‰
        - resume_value: interrupt æ¢å¤å€¼ï¼ˆç”¨æˆ·å¯¹ interrupt çš„å›ç­”ï¼‰

        è¿”å›ï¼š
        - SSE äº‹ä»¶æµ
        """
        start_time = _now_ms()
        agent_count = 0
        tool_count = 0

        # å‘é€ä¼šè¯å¼€å§‹äº‹ä»¶
        await event_bus.emit(
            self,
            SessionStartedEvent(
                session_id=session_id,
                query=query or "",
            ),
        )

        # æ„å»º thread_idï¼ˆåŒ…å« namespace å‰ç¼€ï¼‰
        thread_id = self._make_thread_id(session_id)
        config = {
            "configurable": {
                "thread_id": thread_id,
            }
        }

        # ç¼–è¯‘å›¾
        compiled = await self._ensure_compiled()

        # å¼€å§‹è®°å½•ç»éªŒ
        if self._experience_learner and query:
            self._experience_learner.start_recording(session_id, query)

        # å°è¯•è·å–ç°æœ‰çŠ¶æ€ï¼ˆæ”¯æŒæ–­ç‚¹æ¢å¤ï¼‰
        state_snapshot = None
        existing_state = None
        is_interrupted = False

        try:
            state_snapshot = await compiled.aget_state(config)
            if state_snapshot and state_snapshot.values:
                existing_state = state_snapshot.values
                # æ£€æŸ¥æ˜¯å¦å¤„äºä¸­æ–­çŠ¶æ€
                if hasattr(state_snapshot, "tasks") and state_snapshot.tasks:
                    for task in state_snapshot.tasks:
                        if hasattr(task, "interrupts") and task.interrupts:
                            is_interrupted = True
                            logger.info(f"â¸ï¸ æ£€æµ‹åˆ°ä¸­æ–­çŠ¶æ€: session_id={session_id}")
                            break
                if not is_interrupted and existing_state:
                    logger.info(f"ğŸ”„ æ¢å¤ä¼šè¯çŠ¶æ€: session_id={session_id}")
        except Exception as e:
            logger.error(f"è·å–ä¼šè¯çŠ¶æ€å¤±è´¥: {e}")

        # æ£€ç´¢ç»éªŒä¸Šä¸‹æ–‡ï¼ˆä»…åœ¨æ–°ä¼šè¯ä¸”æœ‰ query æ—¶ï¼‰
        experience_context = None
        if self._experience_retriever and not existing_state and not is_interrupted and query:
            try:
                experience_context = await self._experience_retriever.build_context(query)
                if experience_context:
                    logger.info(f"ğŸ“š æ£€ç´¢åˆ°ç›¸ä¼¼ç»éªŒï¼Œå·²æ³¨å…¥ä¸Šä¸‹æ–‡")
            except Exception as e:
                logger.warning(f"æ£€ç´¢ç»éªŒå¤±è´¥: {e}")

        # æ ¹æ®çŠ¶æ€ç±»å‹å†³å®šæ‰§è¡Œæ–¹å¼
        input_for_stream: dict | Command | None = None

        if is_interrupted and resume_value is not None:
            # åœºæ™¯ 1: interrupt æ¢å¤ - ä½¿ç”¨ resume_value
            input_for_stream = Command(resume=resume_value)
            logger.info(f"â–¶ï¸ ä½¿ç”¨ Command(resume) æ¢å¤ä¸­æ–­: session_id={session_id}, resume_value={resume_value}")
        elif is_interrupted and query:
            # åœºæ™¯ 2: ä¸­æ–­çŠ¶æ€ä½†æ²¡æœ‰ resume_valueï¼Œç”¨ query ä½œä¸ºæ¢å¤å€¼ï¼ˆå…¼å®¹æ—§è¡Œä¸ºï¼‰
            input_for_stream = Command(resume=query)
            logger.warning(f"âš ï¸ ä¸­æ–­æ¢å¤ä½¿ç”¨ query ä½œä¸º resume_valueï¼ˆå»ºè®®ä½¿ç”¨ resume_value å‚æ•°ï¼‰: session_id={session_id}")
        elif existing_state and query:
            # åœºæ™¯ 3: ç»­èŠæ¨¡å¼
            input_for_stream = {
                "messages": [HumanMessage(content=query)],
                "active_agent": self.entry_agent_id,
            }
            logger.info(f"ğŸ’¬ ç»­èŠæ¨¡å¼: session_id={session_id}")
        elif query:
            # åœºæ™¯ 4: æ–°ä¼šè¯
            input_for_stream = create_blackboard(
                namespace=self.namespace,
                session_id=session_id,
                experience_context=experience_context,
            )
            input_for_stream["messages"] = [HumanMessage(content=query)]
            input_for_stream["active_agent"] = self.entry_agent_id
            logger.info(f"ğŸ†• æ–°ä¼šè¯: session_id={session_id}")
        else:
            # æ— æ•ˆè°ƒç”¨ï¼šæ—¢æ²¡æœ‰ query ä¹Ÿæ²¡æœ‰ resume_value
            logger.error(f"æ— æ•ˆè°ƒç”¨ï¼šquery å’Œ resume_value éƒ½ä¸ºç©º: session_id={session_id}")
            yield {
                "event": "error",
                "data": {
                    "detail": "æ— æ•ˆè°ƒç”¨ï¼šå¿…é¡»æä¾› query æˆ– resume_value",
                    "duration_ms": 0,
                },
            }
            return

        try:
            yield {
                "event": "start",
                "data": {
                    "session_id": session_id,
                    "team": self.name,
                    "entry_agent": self.entry_agent_id,
                    "resumed": existing_state is not None,
                    "from_interrupt": is_interrupted,
                },
            }

            async for event in compiled.astream(input_for_stream, config):
                for node_name, node_output in event.items():
                    if node_name == "__end__":
                        continue

                    agent_count += 1

                    # è®°å½• Agent å‚ä¸
                    if self._experience_learner:
                        self._experience_learner.record_agent(session_id, node_name)

                    # æ”¶é›†å·¥å…·è°ƒç”¨ä¿¡æ¯
                    step_tools: list[str] = []
                    step_tool_count = 0
                    if isinstance(node_output, dict):
                        messages = node_output.get("messages", [])
                        for msg in messages:
                            # æå–æ€è€ƒå†…å®¹
                            thinking_content = self._extract_thinking_from_message(msg)
                            if thinking_content:
                                yield {
                                    "event": "thinking",
                                    "data": {
                                        "agent_id": node_name,
                                        "thinking_content": thinking_content,
                                    },
                                }

                            if hasattr(msg, "tool_calls") and msg.tool_calls:
                                step_tool_count += len(msg.tool_calls)
                                for tc in msg.tool_calls:
                                    tool_name = tc.get("name", "") if isinstance(tc, dict) else getattr(tc, "name", "")
                                    if tool_name:
                                        if tool_name not in step_tools:
                                            step_tools.append(tool_name)
                                        # è®°å½•å·¥å…·ä½¿ç”¨
                                        if self._experience_learner:
                                            self._experience_learner.record_tool(session_id, tool_name)
                        tool_count += step_tool_count

                    agent_status = "completed"
                    agent_error = None
                    if isinstance(node_output, dict):
                        agent_status = node_output.get("last_agent_status", "completed")
                        agent_error = node_output.get("last_agent_error")

                    event_data = {
                        "agent_id": node_name,
                        "status": agent_status,
                    }
                    if agent_error:
                        event_data["error"] = agent_error

                    yield {
                        "event": "agent",
                        "data": event_data,
                    }

            # è·å–æœ€ç»ˆçŠ¶æ€
            final_state = await compiled.aget_state(config)
            final_interrupted = False
            interrupt_info = None

            if hasattr(final_state, "tasks") and final_state.tasks:
                for task in final_state.tasks:
                    if hasattr(task, "interrupts") and task.interrupts:
                        final_interrupted = True
                        interrupt_info = {
                            "interrupts": [
                                {
                                    "value": getattr(i, "value", None),
                                    "resumable": getattr(i, "resumable", True),
                                }
                                for i in task.interrupts
                            ]
                        }
                        logger.info(f"â¸ï¸ æ‰§è¡Œè¢«ä¸­æ–­: session_id={session_id}")
                        break

            if final_interrupted and interrupt_info:
                yield {
                    "event": "interrupt",
                    "data": {
                        "session_id": session_id,
                        "interrupt_info": interrupt_info,
                        "message": "éœ€è¦ç”¨æˆ·è¾“å…¥ä»¥ç»§ç»­",
                        "duration_ms": _now_ms() - start_time,
                    },
                }
            else:
                # è¯»å– deliverables
                deliverables = {}
                deliverable_keys = final_state.values.get("deliverable_keys", [])
                if self._store and deliverable_keys:
                    store_namespaces = [
                        ("deliverables", self.namespace, session_id, "latest"),
                        ("deliverables", self.namespace, session_id),
                    ]
                    for key in deliverable_keys:
                        try:
                            item = None
                            for store_namespace in store_namespaces:
                                item = await self._store.aget(store_namespace, key)
                                if item:
                                    break
                            if item:
                                deliverables[key] = item.value
                        except Exception as e:
                            logger.error(f"è¯»å– deliverable {key} å¤±è´¥: {e}")

                timeline_data = final_state.values.get("timeline")

                yield {
                    "event": "result",
                    "data": {
                        "deliverables": deliverables,
                        "timeline": timeline_data,
                        "duration_ms": _now_ms() - start_time,
                    },
                }

                await event_bus.emit(
                    self,
                    SessionCompletedEvent(
                        session_id=session_id,
                        result=deliverables,
                        duration_ms=_now_ms() - start_time,
                        agent_count=agent_count,
                        tool_count=tool_count,
                    ),
                )

                # å®Œæˆç»éªŒè®°å½•
                if self._experience_learner:
                    self._experience_learner.complete_recording(
                        session_id=session_id,
                        outcome="success",
                    )

        except Exception as e:
            logger.error(f"æ‰§è¡Œå¤±è´¥: {e}", exc_info=True)
            yield {
                "event": "error",
                "data": {
                    "detail": str(e),
                    "duration_ms": _now_ms() - start_time,
                },
            }

            # å®Œæˆç»éªŒè®°å½•ï¼ˆå¤±è´¥ï¼‰
            if self._experience_learner:
                self._experience_learner.complete_recording(
                    session_id=session_id,
                    outcome="failure",
                    result_summary=str(e),
                )

    async def compact_session(self, session_id: str) -> dict:
        """æ‰‹åŠ¨å‹ç¼©ä¼šè¯ï¼ˆæš‚ä¸å¯ç”¨ï¼Œå¾…å®ç°åŸºäº messages çš„å‹ç¼©ï¼‰"""
        return {"status": "not_implemented", "message": "å‹ç¼©åŠŸèƒ½å¾…é‡æ„"}

    async def delete_session(self, session_id: str) -> None:
        """åˆ é™¤ä¼šè¯"""
        thread_id = self._make_thread_id(session_id)

        # åˆ é™¤ checkpointer çŠ¶æ€
        if hasattr(self._checkpointer, "adelete_thread"):
            await self._checkpointer.adelete_thread(thread_id)
        elif hasattr(self._checkpointer, "delete_thread"):
            self._checkpointer.delete_thread(thread_id)

        # åˆ é™¤ deliverables
        store_namespaces = [
            ("deliverables", self.namespace, session_id, "latest"),
            ("deliverables", self.namespace, session_id, "versions"),
            ("deliverables", self.namespace, session_id),
        ]
        for store_namespace in store_namespaces:
            try:
                items = await self._store.asearch(store_namespace)
                for item in items:
                    await self._store.adelete(store_namespace, item.key)
            except Exception as e:
                logger.error(f"åˆ é™¤ deliverables å¤±è´¥: {e}")


    async def get_session_stats(self, session_id: str) -> dict:
        """è·å–ä¼šè¯ç»Ÿè®¡"""
        thread_id = self._make_thread_id(session_id)
        config = {"configurable": {"thread_id": thread_id}}

        compiled = await self._ensure_compiled()

        try:
            state_snapshot = await compiled.aget_state(config)
            if not state_snapshot or not state_snapshot.values:
                return {
                    "session_id": session_id,
                    "namespace": self.namespace,
                    "exists": False,
                }

            state = state_snapshot.values

            return {
                "session_id": session_id,
                "namespace": self.namespace,
                "exists": True,
                "message_count": len(state.get("messages", [])),
                "deliverables_count": len(state.get("deliverable_keys", [])),
                "active_agent": state.get("active_agent"),
            }

        except Exception as e:
            logger.error(f"è·å–ä¼šè¯ç»Ÿè®¡å¤±è´¥: {e}")
            return {
                "session_id": session_id,
                "namespace": self.namespace,
                "error": str(e),
            }
