"""
Orchestrator - ç¼–æ’å™¨

è´Ÿè´£ï¼š
1. æµå¼æ‰§è¡Œ
2. æ–­ç‚¹æ¢å¤
3. SSE äº‹ä»¶æµ
"""

from __future__ import annotations

import logging
import time
from collections.abc import AsyncGenerator
from dataclasses import dataclass
from typing import Any

from langchain_core.messages import HumanMessage
from langgraph.graph import StateGraph
from langgraph.types import Command

from datapillar_oneagentic.core.process import Process
from datapillar_oneagentic.core.types import SessionKey
from datapillar_oneagentic.events import SessionCompletedEvent, SessionStartedEvent, event_bus
from datapillar_oneagentic.sse.event import (
    SseAgent,
    SseEvent,
    SseEventType,
    SseLevel,
    SseMessage,
    SseState,
)
from datapillar_oneagentic.state.blackboard import create_blackboard

logger = logging.getLogger(__name__)


def _now_ms() -> int:
    return int(time.time() * 1000)


@dataclass
class _SessionState:
    """ä¼šè¯çŠ¶æ€æ£€æµ‹ç»“æœ"""

    existing_state: dict | None
    is_interrupted: bool
    experience_context: str | None


class Orchestrator:
    """
    ç¼–æ’å™¨

    è´Ÿè´£æ‰§è¡Œå›¢é˜Ÿçš„å·¥ä½œæµç¨‹ã€‚
    """

    def __init__(
        self,
        *,
        namespace: str,
        name: str,
        graph: StateGraph,
        entry_agent_id: str,
        agent_ids: list[str],
        agent_name_map: dict[str, str] | None = None,
        checkpointer,
        store,
        experience_learner=None,
        experience_retriever=None,
        process: Process = Process.SEQUENTIAL,
    ):
        """
        åˆ›å»ºç¼–æ’å™¨

        å‚æ•°ï¼š
        - namespace: å‘½åç©ºé—´ï¼ˆç”¨äºæ•°æ®éš”ç¦»ï¼‰
        - name: åç§°
        - graph: LangGraph çŠ¶æ€å›¾
        - entry_agent_id: å…¥å£ Agent ID
        - agent_ids: æ‰€æœ‰ Agent ID åˆ—è¡¨
        - checkpointer: Checkpointer å®ä¾‹
        - store: Store å®ä¾‹
        - experience_learner: ExperienceLearner å®ä¾‹ï¼ˆå¯é€‰ï¼‰
        - experience_retriever: ExperienceRetriever å®ä¾‹ï¼ˆå¯é€‰ï¼‰
        - process: æ‰§è¡Œæ¨¡å¼
        """
        self.namespace = namespace
        self.name = name
        self.graph = graph
        self.entry_agent_id = entry_agent_id
        self.agent_ids = agent_ids
        self._agent_name_map = agent_name_map or {}
        self.process = process

        # å­˜å‚¨å®ä¾‹
        self._checkpointer = checkpointer
        self._store = store

        # ç»éªŒå­¦ä¹ 
        self._experience_learner = experience_learner
        self._experience_retriever = experience_retriever

        # ç¼–è¯‘å›¾ï¼ˆå»¶è¿Ÿç¼–è¯‘ï¼‰
        self._compiled_graph = None

    def _make_key(self, session_id: str) -> SessionKey:
        """
        æ„å»º SessionKey

        ä½¿ç”¨ namespace + session_id ç»„åˆï¼Œç¡®ä¿ï¼š
        - ä¸åŒ namespace çš„æ•°æ®éš”ç¦»
        - åŒä¸€ namespace å†…ä¸åŒ session çš„æ•°æ®éš”ç¦»
        """
        return SessionKey(namespace=self.namespace, session_id=session_id)

    def _get_agent_name(self, agent_id: str) -> str:
        """è·å– Agent å±•ç¤ºåï¼ˆæ— æ˜ å°„æ—¶å›é€€ä¸º IDï¼‰"""
        return self._agent_name_map.get(agent_id, agent_id)

    def _extract_agent_id_from_interrupt(self, interrupt_obj: Any) -> str | None:
        """ä» interrupt å¯¹è±¡ä¸­è§£æèŠ‚ç‚¹å"""
        namespaces = getattr(interrupt_obj, "ns", None)
        if isinstance(namespaces, list) and namespaces:
            first = namespaces[0]
            if isinstance(first, str):
                return first.split(":", 1)[0]
        return None

    def _to_sse_dict(self, event: SseEvent, key: SessionKey) -> dict:
        """è¡¥å……ä¼šè¯ä¿¡æ¯å¹¶è½¬æ¢ä¸º dict"""
        return event.with_session(namespace=key.namespace, session_id=key.session_id).to_dict()

    def _extract_thinking_from_message(self, msg: Any) -> str | None:
        """
        ä»æ¶ˆæ¯ä¸­æå–æ€è€ƒå†…å®¹

        æ”¯æŒå¤šç§æ¨¡å‹çš„æ€è€ƒæ ¼å¼ï¼š
        - GLM: additional_kwargs.reasoning_content
        - Claude: content ä¸­çš„ thinking blocks
        - DeepSeek: additional_kwargs.reasoning_content
        """
        if not hasattr(msg, "additional_kwargs"):
            return None

        # 1. GLM / DeepSeek æ ¼å¼ï¼ˆreasoning_contentï¼‰
        reasoning = msg.additional_kwargs.get("reasoning_content")
        if reasoning:
            return reasoning

        # 2. Claude æ ¼å¼ï¼ˆcontent æ˜¯ listï¼ŒåŒ…å« thinking blocksï¼‰
        content = getattr(msg, "content", None)
        if isinstance(content, list):
            thinking_parts = []
            for block in content:
                if isinstance(block, dict) and block.get("type") == "thinking":
                    thinking_parts.append(block.get("thinking", ""))
            if thinking_parts:
                return "\n".join(thinking_parts)

        return None

    async def _ensure_compiled(self):
        """ç¡®ä¿å›¾å·²ç¼–è¯‘"""
        if self._compiled_graph is None:
            self._compiled_graph = self.graph.compile(
                checkpointer=self._checkpointer,
                store=self._store,
            )

        return self._compiled_graph

    async def _detect_session_state(
        self, compiled, config: dict, query: str | None, key: SessionKey
    ) -> _SessionState:
        """æ£€æµ‹ä¼šè¯çŠ¶æ€ï¼šæ˜¯å¦å­˜åœ¨ã€æ˜¯å¦ä¸­æ–­ã€ç»éªŒä¸Šä¸‹æ–‡"""
        existing_state = None
        is_interrupted = False

        try:
            state_snapshot = await compiled.aget_state(config)
            if state_snapshot and state_snapshot.values:
                existing_state = state_snapshot.values
                if hasattr(state_snapshot, "tasks") and state_snapshot.tasks:
                    for task in state_snapshot.tasks:
                        if hasattr(task, "interrupts") and task.interrupts:
                            is_interrupted = True
                            logger.info(f"â¸ï¸ æ£€æµ‹åˆ°ä¸­æ–­çŠ¶æ€: key={key}")
                            break
                if not is_interrupted and existing_state:
                    logger.info(f"ğŸ”„ æ¢å¤ä¼šè¯çŠ¶æ€: key={key}")
        except Exception as e:
            logger.error(f"è·å–ä¼šè¯çŠ¶æ€å¤±è´¥: {e}")

        # æ£€ç´¢ç»éªŒä¸Šä¸‹æ–‡ï¼ˆä»…åœ¨æ–°ä¼šè¯ä¸”æœ‰ query æ—¶ï¼‰
        experience_context = None
        if self._experience_retriever and not existing_state and not is_interrupted and query:
            try:
                experience_context = await self._experience_retriever.build_context(query)
                if experience_context:
                    logger.info("ğŸ“š æ£€ç´¢åˆ°ç›¸ä¼¼ç»éªŒï¼Œå·²æ³¨å…¥ä¸Šä¸‹æ–‡")
            except Exception as e:
                logger.warning(f"æ£€ç´¢ç»éªŒå¤±è´¥: {e}")

        return _SessionState(
            existing_state=existing_state,
            is_interrupted=is_interrupted,
            experience_context=experience_context,
        )

    def _build_stream_input(
        self,
        *,
        query: str | None,
        resume_value: Any | None,
        session_state: _SessionState,
        key: SessionKey,
    ) -> dict | Command | None:
        """æ ¹æ®åœºæ™¯æ„å»º stream è¾“å…¥"""
        if session_state.is_interrupted and resume_value is not None:
            logger.info(f"â–¶ï¸ ä½¿ç”¨ Command(resume) æ¢å¤ä¸­æ–­: key={key}")
            return Command(resume=resume_value)

        if session_state.is_interrupted and query:
            logger.warning(f"âš ï¸ ä¸­æ–­æ¢å¤ä½¿ç”¨ query ä½œä¸º resume_value: key={key}")
            return Command(resume=query)

        if session_state.existing_state and query:
            logger.info(f"ğŸ’¬ ç»­èŠæ¨¡å¼: key={key}")
            return {
                "messages": [HumanMessage(content=query)],
                "active_agent": self.entry_agent_id,
            }

        if query:
            logger.info(f"ğŸ†• æ–°ä¼šè¯: key={key}")
            input_data = create_blackboard(
                namespace=self.namespace,
                session_id=key.session_id,
                experience_context=session_state.experience_context,
            )
            input_data["messages"] = [HumanMessage(content=query)]
            input_data["active_agent"] = self.entry_agent_id
            return input_data

        return None

    def _process_node_output(
        self, node_name: str, node_output: Any, key: SessionKey
    ) -> tuple[list[dict], int]:
        """å¤„ç†èŠ‚ç‚¹è¾“å‡ºï¼Œè¿”å› SSE äº‹ä»¶åˆ—è¡¨å’Œå·¥å…·è°ƒç”¨æ•°"""
        events: list[dict] = []
        tool_count = 0

        if not isinstance(node_output, dict):
            return events, tool_count

        messages = node_output.get("messages", [])
        for msg in messages:
            # æå–æ€è€ƒå†…å®¹
            thinking_content = self._extract_thinking_from_message(msg)
            if thinking_content:
                events.append(
                    self._to_sse_dict(
                        SseEvent.agent_thinking(
                            agent_id=node_name,
                            agent_name=self._get_agent_name(node_name),
                            content=thinking_content,
                        ),
                        key,
                    )
                )

            # æ”¶é›†å·¥å…·è°ƒç”¨
            if hasattr(msg, "tool_calls") and msg.tool_calls:
                tool_count += len(msg.tool_calls)
                for tc in msg.tool_calls:
                    tool_name = tc.get("name", "") if isinstance(tc, dict) else getattr(tc, "name", "")
                    if tool_name and self._experience_learner:
                        self._experience_learner.record_tool(key.session_id, tool_name)

        return events, tool_count

    async def _build_final_result(
        self, compiled, config: dict, key: SessionKey, start_time: int
    ) -> dict:
        """æ„å»ºæœ€ç»ˆç»“æœæˆ–ä¸­æ–­ä¿¡æ¯"""
        final_state = await compiled.aget_state(config)

        # æ£€æµ‹ä¸­æ–­
        if hasattr(final_state, "tasks") and final_state.tasks:
            for task in final_state.tasks:
                if hasattr(task, "interrupts") and task.interrupts:
                    logger.info(f"â¸ï¸ æ‰§è¡Œè¢«ä¸­æ–­: key={key}")
                    payloads = [getattr(i, "value", None) for i in task.interrupts]
                    payload = payloads[0] if len(payloads) == 1 else payloads
                    interrupt_obj = task.interrupts[0]
                    agent_id = (
                        getattr(task, "name", None)
                        or getattr(task, "node", None)
                        or self._extract_agent_id_from_interrupt(interrupt_obj)
                        or "unknown"
                    )
                    agent_name = self._get_agent_name(agent_id)
                    event = SseEvent.agent_interrupt(
                        agent_id=agent_id,
                        agent_name=agent_name,
                        payload=payload,
                    ).model_copy(update={"duration_ms": _now_ms() - start_time})
                    return self._to_sse_dict(event, key)

        # è¯»å– deliverables
        deliverables = {}
        deliverable_keys = []
        if final_state and final_state.values:
            deliverable_keys = final_state.values.get("deliverable_keys", [])

        if self._store and deliverable_keys:
            store_namespaces = [
                ("deliverables", self.namespace, key.session_id, "latest"),
                ("deliverables", self.namespace, key.session_id),
            ]
            for dk in deliverable_keys:
                try:
                    for store_namespace in store_namespaces:
                        item = await self._store.aget(store_namespace, dk)
                        if item:
                            deliverables[dk] = item.value
                            break
                except Exception as e:
                    logger.error(f"è¯»å– deliverable {dk} å¤±è´¥: {e}")

        timeline_data = None
        if final_state and final_state.values:
            timeline_data = final_state.values.get("timeline")

        event = SseEvent.result_event(
            deliverable=deliverables,
            deliverable_type=None,
        ).model_copy(
            update={
                "duration_ms": _now_ms() - start_time,
                "timeline": timeline_data,
            }
        )
        return self._to_sse_dict(event, key)

    async def stream(
        self,
        *,
        query: str | None = None,
        key: SessionKey,
        resume_value: Any | None = None,
    ) -> AsyncGenerator[dict[str, Any], None]:
        """
        æµå¼æ‰§è¡Œ

        æ”¯æŒä¸‰ç§åœºæ™¯ï¼š
        1. æ–°ä¼šè¯/ç»­èŠï¼šquery ä¸ä¸ºç©ºï¼Œresume_value ä¸ºç©º
        2. interrupt æ¢å¤ï¼šresume_value ä¸ä¸ºç©ºï¼ˆquery å¯é€‰ï¼Œä½œä¸ºä¸Šä¸‹æ–‡ï¼‰
        3. çº¯ç»­èŠï¼šquery ä¸ä¸ºç©ºï¼Œå·²æœ‰ä¼šè¯çŠ¶æ€

        å‚æ•°ï¼š
        - query: ç”¨æˆ·è¾“å…¥ï¼ˆæ–°é—®é¢˜æˆ–ç»­èŠå†…å®¹ï¼‰
        - key: SessionKeyï¼ˆnamespace + session_id ç»„åˆï¼‰
        - resume_value: interrupt æ¢å¤å€¼ï¼ˆç”¨æˆ·å¯¹ interrupt çš„å›ç­”ï¼‰

        è¿”å›ï¼š
        - SSE äº‹ä»¶æµ
        """
        start_time = _now_ms()
        agent_count = 0
        tool_count = 0

        await event_bus.emit(self, SessionStartedEvent(key=key, query=query or ""))

        config = {"configurable": {"thread_id": str(key)}}
        compiled = await self._ensure_compiled()

        if self._experience_learner and query:
            self._experience_learner.start_recording(key.session_id, query)

        # Phase 1: æ£€æµ‹ä¼šè¯çŠ¶æ€
        session_state = await self._detect_session_state(compiled, config, query, key)

        # Phase 2: æ„å»ºè¾“å…¥
        input_for_stream = self._build_stream_input(
            query=query,
            resume_value=resume_value,
            session_state=session_state,
            key=key,
        )

        if input_for_stream is None:
            logger.error(f"æ— æ•ˆè°ƒç”¨ï¼šquery å’Œ resume_value éƒ½ä¸ºç©º: key={key}")
            error_event = SseEvent.error_event(
                message="æ— æ•ˆè°ƒç”¨ï¼šå¿…é¡»æä¾› query æˆ– resume_value",
                detail="query å’Œ resume_value å‡ä¸ºç©º",
            ).model_copy(update={"duration_ms": 0})
            yield self._to_sse_dict(error_event, key)
            return

        try:
            # Phase 3: æ‰§è¡Œæµ
            async for event in compiled.astream(input_for_stream, config):
                for node_name, node_output in event.items():
                    if node_name == "__end__":
                        continue

                    agent_count += 1
                    if self._experience_learner:
                        self._experience_learner.record_agent(key.session_id, node_name)

                    agent_name = self._get_agent_name(node_name)
                    yield self._to_sse_dict(
                        SseEvent.agent_start(agent_id=node_name, agent_name=agent_name),
                        key,
                    )

                    # å¤„ç†èŠ‚ç‚¹è¾“å‡º
                    node_events, node_tool_count = self._process_node_output(node_name, node_output, key)
                    for evt in node_events:
                        yield evt
                    tool_count += node_tool_count

                    # æ„å»º agent.end äº‹ä»¶
                    agent_status = "completed"
                    agent_error = None
                    if isinstance(node_output, dict):
                        agent_status = node_output.get("last_agent_status", "completed")
                        agent_error = node_output.get("last_agent_error")

                    if agent_status in {"failed", "error"}:
                        event = SseEvent(
                            event=SseEventType.AGENT_END,
                            state=SseState.ERROR,
                            level=SseLevel.ERROR,
                            agent=SseAgent(id=node_name, name=agent_name),
                            message=SseMessage(
                                role="assistant",
                                content=agent_error or "æ‰§è¡Œå¤±è´¥",
                            ),
                        )
                    else:
                        event = SseEvent.agent_end(
                            agent_id=node_name,
                            agent_name=agent_name,
                        )
                    yield self._to_sse_dict(event, key)

            # Phase 5: æ„å»ºæœ€ç»ˆç»“æœ
            final_event = await self._build_final_result(compiled, config, key, start_time)
            yield final_event

            # å®Œæˆäº‹ä»¶å’Œç»éªŒè®°å½•
            if final_event["event"] == "result":
                deliverables = {}
                result_data = final_event.get("result")
                if isinstance(result_data, dict):
                    deliverables = result_data.get("deliverable") or {}
                await event_bus.emit(
                    self,
                    SessionCompletedEvent(
                        key=key,
                        result=deliverables,
                        duration_ms=_now_ms() - start_time,
                        agent_count=agent_count,
                        tool_count=tool_count,
                    ),
                )
                if self._experience_learner:
                    self._experience_learner.complete_recording(session_id=key.session_id, outcome="success")

        except Exception as e:
            logger.error(f"æ‰§è¡Œå¤±è´¥: {e}", exc_info=True)
            error_event = SseEvent.error_event(
                message="æ‰§è¡Œå¤±è´¥",
                detail=str(e),
            ).model_copy(update={"duration_ms": _now_ms() - start_time})
            yield self._to_sse_dict(error_event, key)
            if self._experience_learner:
                self._experience_learner.complete_recording(
                    session_id=key.session_id, outcome="failure", result_summary=str(e)
                )

    async def compact_session(self, session_id: str) -> dict:
        """æ‰‹åŠ¨å‹ç¼©ä¼šè¯ï¼ˆæš‚ä¸å¯ç”¨ï¼Œå¾…å®ç°åŸºäº messages çš„å‹ç¼©ï¼‰"""
        return {"status": "not_implemented", "message": "å‹ç¼©åŠŸèƒ½å¾…é‡æ„"}

    async def delete_session(self, session_id: str) -> None:
        """åˆ é™¤ä¼šè¯"""
        key = self._make_key(session_id)
        thread_id = str(key)

        # åˆ é™¤ checkpointer çŠ¶æ€
        if hasattr(self._checkpointer, "adelete_thread"):
            await self._checkpointer.adelete_thread(thread_id)
        elif hasattr(self._checkpointer, "delete_thread"):
            self._checkpointer.delete_thread(thread_id)

        # åˆ é™¤ deliverables
        store_namespaces = [
            ("deliverables", self.namespace, session_id, "latest"),
            ("deliverables", self.namespace, session_id, "versions"),
            ("deliverables", self.namespace, session_id),
        ]
        for store_namespace in store_namespaces:
            try:
                items = await self._store.asearch(store_namespace)
                for item in items:
                    await self._store.adelete(store_namespace, item.key)
            except Exception as e:
                logger.error(f"åˆ é™¤ deliverables å¤±è´¥: {e}")


    async def get_session_stats(self, session_id: str) -> dict:
        """è·å–ä¼šè¯ç»Ÿè®¡"""
        key = self._make_key(session_id)
        thread_id = str(key)
        config = {"configurable": {"thread_id": thread_id}}

        compiled = await self._ensure_compiled()

        try:
            state_snapshot = await compiled.aget_state(config)
            if not state_snapshot or not state_snapshot.values:
                return {
                    "session_id": session_id,
                    "namespace": self.namespace,
                    "exists": False,
                }

            state = state_snapshot.values

            return {
                "session_id": session_id,
                "namespace": self.namespace,
                "exists": True,
                "message_count": len(state.get("messages", [])),
                "deliverables_count": len(state.get("deliverable_keys", [])),
                "active_agent": state.get("active_agent"),
            }

        except Exception as e:
            logger.error(f"è·å–ä¼šè¯ç»Ÿè®¡å¤±è´¥: {e}")
            return {
                "session_id": session_id,
                "namespace": self.namespace,
                "error": str(e),
            }
