"""
ContextBuilder - ç»Ÿä¸€çš„ä¸Šä¸‹æ–‡ç®¡ç†å™¨

è´Ÿè´£ï¼š
- messages ç®¡ç†ï¼ˆæ·»åŠ ã€å‹ç¼©ï¼‰
- Timeline è®°å½•
- ä¸º nodes.py æä¾›ç»Ÿä¸€çš„ API

è®¾è®¡åŸåˆ™ï¼š
- æ‰€æœ‰ä¸Šä¸‹æ–‡æ“ä½œéƒ½é€šè¿‡ ContextBuilder
- nodes.py ä¸ç›´æ¥æ“ä½œ messages æˆ– Timeline
- å‹ç¼©ç”± LLM ä¸Šä¸‹æ–‡è¶…é™è§¦å‘
"""

from __future__ import annotations

import json
import logging

from langchain_core.messages import AIMessage, BaseMessage, HumanMessage, SystemMessage
from pydantic import BaseModel

from datapillar_oneagentic.todo.session_todo import SessionTodoList
from datapillar_oneagentic.utils.structured_output import build_output_instructions
from datapillar_oneagentic.todo.tool import TODO_PLAN_TOOL_NAME, TODO_TOOL_NAME

from datapillar_oneagentic.context.compaction import CompactResult, Compactor
from datapillar_oneagentic.context.timeline import Timeline
from datapillar_oneagentic.knowledge.config import KnowledgeInjectConfig
from datapillar_oneagentic.knowledge.models import KnowledgeChunk

logger = logging.getLogger(__name__)

_KNOWLEDGE_TOOL_PROMPT = (
    "## çŸ¥è¯†æ£€ç´¢\n"
    "- å½“ä»»åŠ¡éœ€è¦å¤–éƒ¨çŸ¥è¯†æ—¶ï¼Œå¿…é¡»è°ƒç”¨ knowledge_retrieve(query) è·å–æ£€ç´¢ç»“æœã€‚\n"
    "- ç¦æ­¢ç¼–é€ å¤–éƒ¨çŸ¥è¯†æˆ–å‡è®¾ä¸å­˜åœ¨çš„èµ„æ–™ã€‚"
)


class ContextBuilder:
    """
    ç»Ÿä¸€çš„ä¸Šä¸‹æ–‡ç®¡ç†å™¨

    ç®¡ç†ï¼š
    - messages: LangGraph çš„æ¶ˆæ¯åˆ—è¡¨
    - timeline: æ‰§è¡Œæ—¶é—´çº¿
    - å‹ç¼©: ç”± LLM ä¸Šä¸‹æ–‡è¶…é™è§¦å‘
    """

    def __init__(
        self,
        *,
        session_id: str,
        messages: list[BaseMessage] | None = None,
        timeline: Timeline | None = None,
        compactor: Compactor,
    ):
        """
        åˆå§‹åŒ–

        Args:
            session_id: ä¼šè¯ ID
            messages: åˆå§‹æ¶ˆæ¯åˆ—è¡¨
            timeline: åˆå§‹æ—¶é—´çº¿
        """
        self.session_id = session_id
        self._messages = list(messages) if messages else []
        self._timeline = timeline or Timeline()
        self._compactor = compactor

    @classmethod
    def from_state(cls, state: dict, *, compactor: Compactor) -> ContextBuilder:
        """ä» state åˆ›å»º ContextBuilder"""
        session_id = state.get("session_id", "")
        messages = list(state.get("messages", []))

        timeline_data = state.get("timeline")
        timeline = Timeline.from_dict(timeline_data) if timeline_data else Timeline()

        return cls(
            session_id=session_id,
            messages=messages,
            timeline=timeline,
            compactor=compactor,
        )

    # ========== LLM Messages æ„å»º ==========

    @staticmethod
    def build_llm_messages(
        *,
        system_prompt: str,
        query: str | None,
        state: dict,
        include_knowledge_tool_prompt: bool = False,
        output_schema: type[BaseModel] | None = None,
    ) -> list[BaseMessage]:
        messages: list[BaseMessage] = [SystemMessage(content=system_prompt)]

        if output_schema is not None:
            messages.append(SystemMessage(content=build_output_instructions(output_schema)))

        context_parts = []

        upstream_messages = state.get("messages", [])
        if upstream_messages:
            for msg in upstream_messages:
                if isinstance(msg, (HumanMessage, AIMessage)):
                    messages.append(msg)

        knowledge_context = state.get("knowledge_context")
        if knowledge_context:
            context_parts.append(knowledge_context)

        experience_context = state.get("experience_context")
        if experience_context:
            context_parts.append(experience_context)

        if context_parts:
            context_content = "\n\n".join(context_parts)
            messages.append(SystemMessage(content=context_content))

        if include_knowledge_tool_prompt:
            messages.append(SystemMessage(content=_KNOWLEDGE_TOOL_PROMPT))

        assigned_task = state.get("assigned_task")
        if assigned_task:
            messages.append(SystemMessage(content=f"## ä¸‹å‘ä»»åŠ¡\n{assigned_task}"))

        todo_prompt = None
        todo_context = state.get("todo_context")
        if isinstance(todo_context, str) and todo_context.strip():
            todo_prompt = todo_context.strip()
        else:
            todo_data = state.get("todo")
            if todo_data:
                try:
                    todo = SessionTodoList.model_validate(todo_data)
                except Exception as exc:
                    logger.warning(f"Todo è§£æå¤±è´¥: {exc}")
                else:
                    todo_prompt = todo.to_prompt()

        if todo_prompt:
            todo_instruction = (
                "## Todo ç®¡ç†\n"
                f"- å½“ä»»åŠ¡å¤æ‚æˆ–éœ€æ±‚å˜åŒ–å¯¼è‡´éœ€è¦é‡æ–°æ‹†è§£æ—¶ï¼Œå¿…é¡»è°ƒç”¨ {TODO_PLAN_TOOL_NAME} å·¥å…·è°ƒæ•´ Todoã€‚\n"
                f"- è‹¥ä½ æ¨è¿›äº†ä»»ä¸€ Todoï¼Œè¯·è°ƒç”¨ {TODO_TOOL_NAME} å·¥å…·ä¸ŠæŠ¥ã€‚\n"
                "- æœ€ç»ˆè¾“å‡ºå¿…é¡»ä¸¥æ ¼éµå¾ª deliverable schemaï¼Œ"
                "ä¸è¦åœ¨æœ€ç»ˆè¾“å‡ºä¸­åŒ…å« Todo ä¿¡æ¯ã€‚"
            )
            messages.append(SystemMessage(content=f"{todo_prompt}\n\n{todo_instruction}"))
        else:
            todo_hint = (
                "## Todo è§„åˆ’\n"
                f"- å½“ä»»åŠ¡å¤æ‚æˆ–éœ€è¦åˆ†é˜¶æ®µæ¨è¿›æ—¶ï¼Œå¿…é¡»è°ƒç”¨ {TODO_PLAN_TOOL_NAME} å·¥å…·ç”Ÿæˆ Todoã€‚\n"
                "- ç”¨æˆ·æ˜ç¡®è¦æ±‚ Todo æˆ–æ•°é‡æ—¶ï¼Œå¿…é¡»æŒ‰è¦æ±‚ç”Ÿæˆã€‚\n"
                "- æœ€ç»ˆè¾“å‡ºå¿…é¡»ä¸¥æ ¼éµå¾ª deliverable schemaã€‚"
            )
            messages.append(SystemMessage(content=todo_hint))

        if query and not upstream_messages:
            messages.append(HumanMessage(content=query))

        return messages

    # ========== çŸ¥è¯†ä¸Šä¸‹æ–‡æ„å»º ==========

    @staticmethod
    def build_knowledge_context(
        *,
        chunks: list[KnowledgeChunk],
        inject: KnowledgeInjectConfig,
    ) -> str:
        if not chunks:
            return ""

        max_chunks = inject.max_chunks
        max_chars = inject.max_tokens * 2
        format_value = (inject.format or "markdown").lower()
        if format_value not in {"markdown", "json"}:
            raise ValueError(f"ä¸æ”¯æŒçš„çŸ¥è¯†æ³¨å…¥æ ¼å¼: {format_value}")

        total_chars = 0
        selected: list[KnowledgeChunk] = []
        for chunk in chunks:
            content = chunk.content.strip()
            if not content:
                continue
            if total_chars + len(content) > max_chars:
                break
            selected.append(chunk)
            total_chars += len(content)
            if len(selected) >= max_chunks:
                break

        if not selected:
            return ""

        if format_value == "json":
            payload = {
                "title": "çŸ¥è¯†ä¸Šä¸‹æ–‡",
                "chunks": [
                    {
                        "source_id": chunk.source_id,
                        "doc_id": chunk.doc_id,
                        "doc_title": chunk.doc_title or chunk.doc_id,
                        "chunk_id": chunk.chunk_id,
                        "content": chunk.content.strip(),
                    }
                    for chunk in selected
                ],
            }
            return json.dumps(payload, ensure_ascii=False)

        lines = ["## çŸ¥è¯†ä¸Šä¸‹æ–‡", ""]
        for idx, chunk in enumerate(selected, 1):
            title = chunk.doc_title or chunk.doc_id
            lines.append(f"### ç‰‡æ®µ {idx}")
            lines.append(f"- æ¥æº: {chunk.source_id} / {title}")
            lines.append(chunk.content.strip())
            lines.append("")

        return "\n".join(lines).strip()

    # ========== Messages æ“ä½œ ==========

    def add_messages(self, messages: list[BaseMessage]) -> None:
        """æ·»åŠ æ¶ˆæ¯"""
        self._messages.extend(messages)

    def get_messages(self) -> list[BaseMessage]:
        """è·å–æ‰€æœ‰æ¶ˆæ¯"""
        return self._messages

    def set_messages(self, messages: list[BaseMessage]) -> None:
        """è®¾ç½®æ¶ˆæ¯åˆ—è¡¨ï¼ˆå‹ç¼©åä½¿ç”¨ï¼‰"""
        self._messages = list(messages)

    # ========== Timeline æ“ä½œ ==========

    def record_event(self, event_data: dict) -> None:
        """è®°å½•äº‹ä»¶åˆ° Timeline"""
        self._timeline.add_entry_from_dict(event_data)

    def record_events(self, events: list[dict]) -> None:
        """æ‰¹é‡è®°å½•äº‹ä»¶"""
        for event_data in events:
            self._timeline.add_entry_from_dict(event_data)

    # ========== å‹ç¼© ==========

    async def compact(self) -> CompactResult:
        """
        æ‰§è¡Œå‹ç¼©ï¼ˆç”± LLM ä¸Šä¸‹æ–‡è¶…é™è§¦å‘æ—¶è°ƒç”¨ï¼‰

        Returns:
            CompactResult
        """
        try:
            compressed_messages, result = await self._compactor.compact(self._messages)
            if result.success and result.removed_count > 0:
                self._messages = compressed_messages
                logger.info(
                    f"ğŸ“¦ ä¸Šä¸‹æ–‡å‹ç¼©: {result.removed_count} æ¡æ¶ˆæ¯ â†’ æ‘˜è¦ï¼Œ"
                    f"ä¿ç•™ {result.kept_count} æ¡"
                )
            return result
        except Exception as e:
            logger.warning(f"ä¸Šä¸‹æ–‡å‹ç¼©å¤±è´¥: {e}")
            return CompactResult.failed(str(e))

    # ========== çŠ¶æ€æ›´æ–° ==========

    def to_state_update(self) -> dict:
        """
        ç”Ÿæˆ state æ›´æ–°å­—å…¸

        Returns:
            åŒ…å« messages å’Œ timeline çš„æ›´æ–°å­—å…¸
        """
        return {
            "messages": self._messages,
            "timeline": self._timeline.to_dict(),
        }

    def get_timeline_update(self) -> dict | None:
        """è·å– Timeline æ›´æ–°ï¼ˆå¦‚æœæœ‰å˜åŒ–ï¼‰"""
        if self._timeline.entries:
            return self._timeline.to_dict()
        return None
