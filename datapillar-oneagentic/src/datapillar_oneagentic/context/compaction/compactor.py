"""
ä¸Šä¸‹æ–‡å‹ç¼©å™¨

ç›´æ¥æ“ä½œ LangGraph çš„ messages åˆ—è¡¨ï¼Œå°†å†å²æ¶ˆæ¯å‹ç¼©ä¸ºæ‘˜è¦ã€‚

å‹ç¼©æµç¨‹ï¼š
1. ä¿ç•™æœ€è¿‘ N æ¡æ¶ˆæ¯ + ç”¨æˆ·æ¶ˆæ¯
2. å°†å…¶ä»–æ¶ˆæ¯å‹ç¼©ä¸ºæ‘˜è¦
3. è¿”å›å‹ç¼©åçš„ messages åˆ—è¡¨

è§¦å‘æ—¶æœºï¼šç”± ContextLengthExceededError å¼‚å¸¸è§¦å‘ï¼Œä¸å†ä¸»åŠ¨æ£€æŸ¥ tokenã€‚
"""

from __future__ import annotations

import logging
from typing import Any

from langchain_core.messages import (
    AIMessage,
    BaseMessage,
    HumanMessage,
    SystemMessage,
    ToolMessage,
)

from datapillar_oneagentic.context.compaction.compact_policy import CompactPolicy, CompactResult

logger = logging.getLogger(__name__)


class Compactor:
    """
    ä¸Šä¸‹æ–‡å‹ç¼©å™¨

    ç›´æ¥æ“ä½œ LangGraph çš„ messages åˆ—è¡¨ï¼ŒåŒ…æ‹¬ï¼š
    - è°ƒç”¨ LLM ç”Ÿæˆæ‘˜è¦
    - è¿”å›å‹ç¼©åçš„ messages
    """

    def __init__(self, llm: Any, policy: CompactPolicy | None = None):
        """
        åˆå§‹åŒ–å‹ç¼©å™¨

        Args:
            llm: LLM å®ä¾‹
            policy: å‹ç¼©ç­–ç•¥
        """
        self.llm = llm
        self.policy = policy or CompactPolicy()

    async def compact(
        self,
        messages: list[BaseMessage],
    ) -> tuple[list[BaseMessage], CompactResult]:
        """
        æ‰§è¡Œå‹ç¼©

        Args:
            messages: åŸå§‹æ¶ˆæ¯åˆ—è¡¨

        Returns:
            (å‹ç¼©åçš„ messages, CompactResult)
        """
        if not messages:
            return messages, CompactResult.no_action("æ²¡æœ‰æ¶ˆæ¯")

        # åˆ†ç±»æ¶ˆæ¯ï¼šä¿ç•™ vs å‹ç¼©
        keep_messages, compress_messages = self._classify_messages(messages)

        if not compress_messages:
            return messages, CompactResult.no_action("æ²¡æœ‰å¯å‹ç¼©çš„æ¶ˆæ¯")

        # ç”Ÿæˆå‹ç¼©æ‘˜è¦
        try:
            summary = await self._generate_summary(compress_messages)
        except Exception as e:
            logger.error(f"å‹ç¼©å¤±è´¥: {e}", exc_info=True)
            return messages, CompactResult.failed(str(e))

        # æ„å»ºå‹ç¼©åçš„ messagesï¼šæ‘˜è¦ + ä¿ç•™çš„æ¶ˆæ¯
        compressed_messages = [
            SystemMessage(content=f"[å†å²æ‘˜è¦]\n{summary}"),
            *keep_messages,
        ]

        logger.info(
            f"ğŸ“¦ å‹ç¼©å®Œæˆ: {len(compress_messages)} æ¡ â†’ æ‘˜è¦ï¼Œ"
            f"ä¿ç•™ {len(keep_messages)} æ¡"
        )

        return compressed_messages, CompactResult(
            success=True,
            summary=summary,
            kept_count=len(keep_messages),
            removed_count=len(compress_messages),
        )

    def _classify_messages(
        self,
        messages: list[BaseMessage],
    ) -> tuple[list[BaseMessage], list[BaseMessage]]:
        """
        åˆ†ç±»æ¶ˆæ¯

        è§„åˆ™ï¼š
        - æœ€è¿‘ min_keep_entries æ¡æ¶ˆæ¯å§‹ç»ˆä¿ç•™
        - HumanMessageï¼ˆç”¨æˆ·æ¶ˆæ¯ï¼‰å§‹ç»ˆä¿ç•™
        - å…¶ä»–æ¶ˆæ¯å‹ç¼©
        """
        min_keep = self.policy.get_min_keep_entries()

        if len(messages) <= min_keep:
            return messages.copy(), []

        # æœ€è¿‘çš„æ¶ˆæ¯å§‹ç»ˆä¿ç•™
        recent_messages = messages[-min_keep:]
        older_messages = messages[:-min_keep]

        keep_messages = []
        compress_messages = []

        for msg in older_messages:
            # ç”¨æˆ·æ¶ˆæ¯å§‹ç»ˆä¿ç•™
            if isinstance(msg, (HumanMessage, SystemMessage)):
                keep_messages.append(msg)
            else:
                compress_messages.append(msg)

        # åˆå¹¶ï¼šä¿ç•™çš„ + æœ€è¿‘çš„
        keep_messages.extend(recent_messages)

        return keep_messages, compress_messages

    async def _generate_summary(self, messages: list[BaseMessage]) -> str:
        """ç”Ÿæˆå‹ç¼©æ‘˜è¦"""
        # æ„å»ºå†å²æ–‡æœ¬
        history_lines = []
        for msg in messages:
            role = self._get_role_name(msg)
            content = msg.content if isinstance(msg.content, str) else str(msg.content)
            # æˆªæ–­è¿‡é•¿çš„å•æ¡æ¶ˆæ¯
            if len(content) > 500:
                content = content[:500] + "..."
            history_lines.append(f"[{role}] {content}")

        history_text = "\n".join(history_lines)

        # æ„å»ºå‹ç¼© prompt
        prompt = self.policy.compress_prompt_template.format(history=history_text)

        # è°ƒç”¨ LLM
        llm_messages = [
            SystemMessage(content="ä½ æ˜¯ä¸€ä¸ªå¯¹è¯å†å²å‹ç¼©ä¸“å®¶ï¼Œè´Ÿè´£ç”Ÿæˆç»“æ„åŒ–çš„å¯¹è¯æ‘˜è¦ã€‚"),
            HumanMessage(content=prompt),
        ]

        response = await self.llm.ainvoke(llm_messages)
        summary = response.content.strip()

        return summary

    def _get_role_name(self, msg: BaseMessage) -> str:
        """è·å–æ¶ˆæ¯è§’è‰²å"""
        if isinstance(msg, HumanMessage):
            return "ç”¨æˆ·"
        elif isinstance(msg, AIMessage):
            name = getattr(msg, "name", None)
            return name if name else "AI"
        elif isinstance(msg, ToolMessage):
            return f"å·¥å…·:{getattr(msg, 'name', 'unknown')}"
        elif isinstance(msg, SystemMessage):
            return "ç³»ç»Ÿ"
        return "æœªçŸ¥"


# === å…¨å±€å‹ç¼©å™¨å·¥å‚ ===

_compactor_cache: Compactor | None = None


def get_compactor(policy: CompactPolicy | None = None) -> Compactor:
    """
    è·å–å‹ç¼©å™¨å®ä¾‹ï¼ˆå¸¦ç¼“å­˜ï¼‰

    Args:
        policy: å‹ç¼©ç­–ç•¥ï¼ˆå¯é€‰ï¼‰

    Returns:
        Compactor å®ä¾‹
    """
    global _compactor_cache

    if _compactor_cache is None:
        from datapillar_oneagentic.providers.llm import call_llm

        llm = call_llm(temperature=0.0)
        _compactor_cache = Compactor(llm=llm, policy=policy or CompactPolicy())

    return _compactor_cache


def clear_compactor_cache() -> None:
    """æ¸…ç©ºå‹ç¼©å™¨ç¼“å­˜ï¼ˆä»…æµ‹è¯•ç”¨ï¼‰"""
    global _compactor_cache
    _compactor_cache = None
