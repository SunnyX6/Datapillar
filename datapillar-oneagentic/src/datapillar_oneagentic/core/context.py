"""
Agent æ‰§è¡Œä¸Šä¸‹æ–‡

AgentContext æ˜¯æ¡†æ¶æä¾›ç»™ä¸šåŠ¡ Agent çš„æ¥å£ï¼š
- åªè¯»ä¿¡æ¯ï¼šnamespace, query, session_id
- å·¥ä½œæ–¹æ³•ï¼šbuild_messages, invoke_tools, get_structured_output, interrupt
- ä¾èµ–è·å–ï¼šget_deliverable

è®¾è®¡åŸåˆ™ï¼š
- ä¸šåŠ¡ä¾§åªèƒ½ä½¿ç”¨å…¬å¼€çš„æ–¹æ³•å’Œå±æ€§
- æ¡†æ¶å†…éƒ¨å¯¹è±¡ç§æœ‰åŒ–ï¼Œé˜²æ­¢ä¸šåŠ¡ä¾§è¶Šæƒ
- è®°å¿†ã€LLMã€å·¥å…·ç­‰ç”±æ¡†æ¶è‡ªåŠ¨ç®¡ç†
- å§”æ´¾ç”±æ¡†æ¶å†…éƒ¨å¤„ç†ï¼Œä¸šåŠ¡ä¾§æ— éœ€å…³å¿ƒ
- Store æ“ä½œå°è£…åœ¨æ¡†æ¶å†…éƒ¨ï¼Œä¸šåŠ¡ä¾§é€šè¿‡ç®€æ´ API è®¿é—®
"""

from __future__ import annotations

import asyncio
import logging
from dataclasses import dataclass, field
from typing import TYPE_CHECKING, Any

from langchain_core.messages import AIMessage, BaseMessage
from langgraph.prebuilt import ToolNode
from langgraph.types import Command, interrupt

from datapillar_oneagentic.context import ContextBuilder
from datapillar_oneagentic.state import StateBuilder
from datapillar_oneagentic.events import (
    EventBus,
    LLMThinkingEvent,
    ToolCalledEvent,
    ToolCompletedEvent,
    ToolFailedEvent,
)
from datapillar_oneagentic.providers.llm.llm import extract_thinking
from datapillar_oneagentic.core.types import SessionKey
from datapillar_oneagentic.utils.structured_output import parse_structured_output

if TYPE_CHECKING:
    from datapillar_oneagentic.core.agent import AgentSpec
    from datapillar_oneagentic.core.config import AgentConfig

logger = logging.getLogger(__name__)

class DelegationSignal(Exception):
    """
    å§”æ´¾ä¿¡å·ï¼ˆæ¡†æ¶å†…éƒ¨ï¼‰

    å½“ Agent è°ƒç”¨å§”æ´¾å·¥å…·æ—¶æŠ›å‡ºï¼Œç”± Executor æ•è·å¤„ç†ã€‚
    ä¸šåŠ¡ä¾§ä¸éœ€è¦çŸ¥é“è¿™ä¸ªå¼‚å¸¸çš„å­˜åœ¨ã€‚
    """

    def __init__(self, command: Command):
        self.command = command
        super().__init__(f"Delegation to {command.goto}")


@dataclass
class AgentContext:
    """
    Agent æ‰§è¡Œä¸Šä¸‹æ–‡

    ä¸šåŠ¡ Agent é€šè¿‡æ­¤ä¸Šä¸‹æ–‡ä¸æ¡†æ¶äº¤äº’ã€‚

    å…¬å¼€å±æ€§ï¼ˆåªè¯»ï¼‰ï¼š
    - namespace: å‘½åç©ºé—´
    - session_id: ä¼šè¯ ID
    - query: ç”¨æˆ·è¾“å…¥

    å…¬å¼€æ–¹æ³•ï¼š
    - build_messages(system_prompt, human_message=None): æ„å»º LLM æ¶ˆæ¯
    - invoke_tools(messages): æ‰§è¡Œå·¥å…·è°ƒç”¨å¾ªç¯
    - get_structured_output(messages): è·å–ç»“æ„åŒ–è¾“å‡º
    - interrupt(payload): ä¸­æ–­ç­‰å¾…ç”¨æˆ·å›å¤
    - get_deliverable(agent_id): è·å–å…¶ä»– Agent çš„äº§å‡º

    ä½¿ç”¨ç¤ºä¾‹ï¼š
    ```python
    async def run(self, ctx: AgentContext) -> AnalysisOutput:
        # è·å–ä¸Šæ¸¸ Agent çš„äº§å‡ºï¼ˆé€šè¿‡ agent_idï¼‰
        upstream_data = await ctx.get_deliverable(agent_id="data_extractor")

        # 1. æ„å»ºæ¶ˆæ¯
        messages = ctx.build_messages(self.SYSTEM_PROMPT)

        # 2. å·¥å…·è°ƒç”¨å¾ªç¯ï¼ˆå§”æ´¾ç”±æ¡†æ¶è‡ªåŠ¨å¤„ç†ï¼‰
        messages = await ctx.invoke_tools(messages)

        # 3. è·å–ç»“æ„åŒ–è¾“å‡º
        output = await ctx.get_structured_output(messages)

        # 4. ä¸šåŠ¡åˆ¤æ–­
        if output.confidence < 0.7:
            user_reply = ctx.interrupt("éœ€æ±‚ä¸å¤Ÿæ˜ç¡®")
            # å¯æ ¹æ® user_reply è¡¥å……ä¸Šä¸‹æ–‡åç»§ç»­

        return output
    ```
    """

    # === å…¬å¼€å±æ€§ï¼ˆåªè¯»ï¼‰===
    namespace: str
    """å‘½åç©ºé—´"""

    session_id: str
    """ä¼šè¯ ID"""

    query: str
    """ç”¨æˆ·è¾“å…¥"""

    # === æ¡†æ¶å†…éƒ¨ï¼ˆç§æœ‰åŒ–ï¼‰===
    _spec: AgentSpec = field(default=None, repr=False)
    """Agent è§„æ ¼ï¼ˆæ¡†æ¶å†…éƒ¨ï¼‰"""

    _llm: Any = field(default=None, repr=False)
    """LLM å®ä¾‹ï¼ˆæ¡†æ¶å†…éƒ¨ï¼‰"""

    _tools: list[Any] = field(default_factory=list, repr=False)
    """å·¥å…·åˆ—è¡¨ï¼ˆæ¡†æ¶å†…éƒ¨ï¼‰"""

    _state: dict = field(default_factory=dict, repr=False)
    """å…±äº«çŠ¶æ€ï¼ˆæ¡†æ¶å†…éƒ¨ï¼‰"""

    _delegation_command: Command | None = field(default=None, repr=False)
    """å§”æ´¾å‘½ä»¤ï¼ˆæ¡†æ¶å†…éƒ¨ï¼‰"""

    _messages: list[BaseMessage] = field(default_factory=list, repr=False)
    _agent_config: AgentConfig | None = field(default=None, repr=False)
    _event_bus: EventBus | None = field(default=None, repr=False)
    """æ¶ˆæ¯å†å²ï¼ˆæ¡†æ¶å†…éƒ¨ï¼‰"""

    # === å…¬å¼€æ–¹æ³• ===

    def build_messages(self, system_prompt: str, human_message: str | None = None) -> Any:
        """
        æ„å»º LLM æ¶ˆæ¯

        è‡ªåŠ¨æ³¨å…¥ï¼š
        - ç³»ç»Ÿæç¤ºè¯
        - Checkpoint è®°å¿†ï¼ˆmessagesï¼‰
        - çŸ¥è¯†ä¸Šä¸‹æ–‡
        - ç»éªŒä¸Šä¸‹æ–‡
        - ç”¨æˆ·æŸ¥è¯¢

        å‚æ•°ï¼š
        - system_prompt: Agent çš„ç³»ç»Ÿæç¤ºè¯
        - human_message: è¿½åŠ çš„äººç±»æ¶ˆæ¯ï¼ˆå¯é€‰ï¼Œä»…ç”¨äºå½“å‰è°ƒç”¨ï¼‰

        è¿”å›ï¼š
        - æ¶ˆæ¯å¯¹è±¡ï¼ˆä¸šåŠ¡ä¾§ä¸éœ€è¦äº†è§£å…·ä½“ç±»å‹ï¼Œåªéœ€ä¼ é€’ï¼‰
        """
        ctx_builder = ContextBuilder.from_state(self._state)
        messages = ctx_builder.compose_llm_messages(
            system_prompt=system_prompt,
            query=self.query,
            human_message=human_message,
        )
        self._messages = messages
        return messages

    def _has_tool(self, tool_name: str) -> bool:
        for tool in self._tools or []:
            name = getattr(tool, "name", None)
            if not name and callable(tool):
                name = getattr(tool, "__name__", "")
            if name == tool_name:
                return True
        return False

    async def invoke_tools(self, messages: Any) -> Any:
        """
        å·¥å…·è°ƒç”¨å¾ªç¯

        æ‰§è¡Œ LLM è°ƒç”¨å’Œå·¥å…·è°ƒç”¨çš„å¾ªç¯ï¼Œç›´åˆ° LLM ä¸å†è°ƒç”¨å·¥å…·ã€‚
        å¦‚æœè°ƒç”¨äº†å§”æ´¾å·¥å…·ï¼Œä¼šæŠ›å‡º DelegationSignal ç”±æ¡†æ¶å¤„ç†ã€‚

        å…³é”®è¯´æ˜ï¼š
        - æœ‰å·¥å…·æ—¶ä»…ä½¿ç”¨ bind_tools è¿›è¡Œå·¥å…·è°ƒç”¨å¾ªç¯ï¼Œä¸å¼ºåˆ¶ç»“æ„åŒ–è¾“å‡º
        - æ— å·¥å…·æ—¶ä½¿ç”¨ç»“æ„åŒ–è¾“å‡ºï¼Œé¿å…é¢å¤–è°ƒç”¨ get_structured_output
        - å·¥å…·è·¯å¾„æœ€ç»ˆä»éœ€è°ƒç”¨ get_structured_output è§£æç»“æœ

        å‚æ•°ï¼š
        - messages: build_messages() è¿”å›çš„æ¶ˆæ¯å¯¹è±¡

        è¿”å›ï¼š
        - æ›´æ–°åçš„æ¶ˆæ¯å¯¹è±¡

        å¼‚å¸¸ï¼š
        - DelegationSignal: å½“è°ƒç”¨å§”æ´¾å·¥å…·æ—¶ï¼ˆæ¡†æ¶å†…éƒ¨å¤„ç†ï¼‰
        """
        schema = self._spec.deliverable_schema

        if not self._tools:
            # æ²¡æœ‰å·¥å…·ï¼Œç›´æ¥è°ƒç”¨ LLMï¼ˆå¸¦ç»“æ„åŒ–è¾“å‡ºï¼‰
            llm_structured = self._llm.with_structured_output(schema, method="function_calling")
            response = await llm_structured.ainvoke(messages)
            # å°† Pydantic å¯¹è±¡åºåˆ—åŒ–ä¸º JSON å­—ç¬¦ä¸²ï¼ŒåŒ…è£…æˆ AIMessage
            if hasattr(response, "model_dump_json"):
                content = response.model_dump_json()
            else:
                import json
                content = json.dumps(response) if isinstance(response, dict) else str(response)
            messages.append(AIMessage(content=content))
            self._messages = messages
            return messages

        # åˆ›å»º ToolNode
        tool_node = ToolNode(self._tools)

        # bind_tools ç»‘å®šå·¥å…·
        llm_with_tools = self._llm.bind_tools(self._tools)

        max_steps = self._spec.get_max_steps(self._agent_config)
        key = SessionKey(namespace=self.namespace, session_id=self.session_id)
        for _iteration in range(1, max_steps + 1):
            # LLM è°ƒç”¨
            response = await llm_with_tools.ainvoke(messages)

            # æå–å¹¶å‘é€æ€è€ƒå†…å®¹ï¼ˆå¦‚æœæœ‰ï¼‰
            thinking_content = self._extract_thinking(response)
            if thinking_content:
                await self._emit_event(
                    LLMThinkingEvent(
                        agent_id=self._spec.id,
                        key=key,
                        thinking_content=thinking_content,
                    )
                )

            if not response.tool_calls:
                # æ²¡æœ‰å·¥å…·è°ƒç”¨ï¼Œç»“æŸ
                messages.append(response)
                break

            messages.append(response)

            # è®°å½•å·¥å…·è°ƒç”¨ä¿¡æ¯ï¼ˆç”¨äºåç»­å‘é€å®Œæˆ/å¤±è´¥äº‹ä»¶ï¼‰
            tool_calls_info = []
            for tc in response.tool_calls:
                tool_name = tc.get("name") if isinstance(tc, dict) else getattr(tc, "name", None)
                tool_args = tc.get("args", {}) if isinstance(tc, dict) else getattr(tc, "args", {})
                tool_call_id = tc.get("id", "") if isinstance(tc, dict) else getattr(tc, "id", "")

                if not tool_name:
                    continue

                logger.info(f"ğŸ”§ [{self._spec.name}] è°ƒç”¨å·¥å…·: {tool_name}")
                tool_calls_info.append({
                    "name": tool_name,
                    "args": tool_args if isinstance(tool_args, dict) else {},
                    "id": tool_call_id or "",
                })
                await self._emit_event(
                    ToolCalledEvent(
                        agent_id=self._spec.id,
                        key=key,
                        tool_name=tool_name,
                        tool_call_id=tool_call_id or "",
                        tool_input=tool_args if isinstance(tool_args, dict) else {},
                    )
                )

            # æ‰§è¡Œå·¥å…·ï¼ˆå¸¦è¶…æ—¶æ§åˆ¶ï¼‰
            import time
            tool_start_time = time.time()
            current_state = dict(self._state)
            current_state["messages"] = list(messages)
            tool_error = None
            tool_timeout = self._spec.get_tool_timeout_seconds(self._agent_config)
            try:
                result = await asyncio.wait_for(
                    tool_node.ainvoke(current_state),
                    timeout=tool_timeout,
                )
            except asyncio.TimeoutError:
                tool_error = f"å·¥å…·è°ƒç”¨è¶…æ—¶ï¼ˆ{tool_timeout}ç§’ï¼‰"
                logger.error(f"â° [{self._spec.name}] {tool_error}")
                for tc_info in tool_calls_info:
                    await self._emit_event(
                        ToolFailedEvent(
                            agent_id=self._spec.id,
                            key=key,
                            tool_name=tc_info["name"],
                            tool_call_id=tc_info["id"],
                            error=tool_error,
                        )
                    )
                raise TimeoutError(tool_error)
            except Exception as e:
                tool_error = str(e)
                # å‘é€æ‰€æœ‰å·¥å…·çš„å¤±è´¥äº‹ä»¶
                for tc_info in tool_calls_info:
                    await self._emit_event(
                        ToolFailedEvent(
                            agent_id=self._spec.id,
                            key=key,
                            tool_name=tc_info["name"],
                            tool_call_id=tc_info["id"],
                            error=tool_error,
                        )
                    )
                raise
            tool_duration_ms = (time.time() - tool_start_time) * 1000

            # è§£æå·¥å…·ç»“æœï¼šåˆ†ç¦» Command å’Œæ™®é€šæ¶ˆæ¯
            delegation_command = None
            new_messages = []

            if isinstance(result, dict):
                new_messages = result.get("messages", [])
            elif isinstance(result, list):
                for item in result:
                    if isinstance(item, Command):
                        # åªå–ç¬¬ä¸€ä¸ª Commandï¼ˆå¤šä¸ªå§”æ´¾ä¸åˆç†ï¼‰
                        if delegation_command is None:
                            delegation_command = item
                        else:
                            logger.warning(f"ğŸ”„ [{self._spec.name}] å¿½ç•¥å¤šä½™çš„å§”æ´¾å‘½ä»¤")
                    else:
                        new_messages.append(item)

            # å¤„ç†å§”æ´¾å‘½ä»¤
            if delegation_command is not None:
                self._delegation_command = delegation_command
                logger.info(f"ğŸ”„ [{self._spec.name}] å§”æ´¾ç»™ {self._delegation_command.goto}")
                self._messages = messages
                # æŠ›å‡ºå§”æ´¾ä¿¡å·ï¼Œç”±æ¡†æ¶å¤„ç†
                raise DelegationSignal(self._delegation_command)

            # å‘é€å·¥å…·å®Œæˆäº‹ä»¶ï¼ˆä» ToolMessage ä¸­æå–ç»“æœï¼‰
            tool_outputs = {}
            for msg in new_messages:
                if hasattr(msg, "tool_call_id") and hasattr(msg, "content"):
                    tool_outputs[msg.tool_call_id] = msg.content

            for tc_info in tool_calls_info:
                tool_output = tool_outputs.get(tc_info["id"], "")
                await self._emit_event(
                    ToolCompletedEvent(
                        agent_id=self._spec.id,
                        key=key,
                        tool_name=tc_info["name"],
                        tool_call_id=tc_info["id"],
                        tool_output=tool_output,
                        duration_ms=tool_duration_ms / len(tool_calls_info) if tool_calls_info else 0,
                    )
                )

            messages.extend(new_messages)

        self._messages = messages
        return messages

    async def get_structured_output(self, messages: Any) -> Any:
        """
        è·å–ç»“æ„åŒ–è¾“å‡º

        å‚æ•°ï¼š
        - messages: invoke_tools() è¿”å›çš„æ¶ˆæ¯å¯¹è±¡

        è¿”å›ï¼š
        - deliverable_schema å®ä¾‹
        """
        schema = self._spec.deliverable_schema
        # ç›´æ¥è°ƒç”¨ LLM ç”Ÿæˆç»“æ„åŒ–è¾“å‡ºï¼Œé¿å…å…±äº«ä¸Šä¸‹æ–‡ä¸­çš„éè¾“å‡ºæ¶ˆæ¯å¹²æ‰°è§£æ
        llm_structured = self._llm.with_structured_output(
            schema,
            method="function_calling",
            include_raw=True,
        )
        result = await llm_structured.ainvoke(messages)
        return parse_structured_output(result, schema, strict=False)

    async def _emit_event(self, event: Any) -> None:
        """å®‰å…¨å‘é€äº‹ä»¶ï¼ˆå…è®¸ event_bus ä¸ºç©ºï¼‰"""
        if self._event_bus is None:
            return
        await self._event_bus.emit(self, event)

    def _extract_thinking(self, response: AIMessage) -> str | None:
        """
        ä» LLM å“åº”ä¸­æå–æ€è€ƒå†…å®¹

        æ”¯æŒå¤šç§æ¨¡å‹çš„æ€è€ƒæ ¼å¼ï¼š
        - GLM: additional_kwargs.reasoning_content
        - Claude: content ä¸­çš„ thinking blocks
        - DeepSeek: additional_kwargs.reasoning_content
        """
        if not isinstance(response, AIMessage):
            return None
        return extract_thinking(response)

    def interrupt(self, payload: Any | None = None) -> Any:
        """
        ä¸­æ–­å¹¶ç­‰å¾…ç”¨æˆ·å›å¤

        payload æ˜¯å¯åºåˆ—åŒ–çš„æç¤ºä¿¡æ¯ï¼ˆå¯é€‰ï¼‰ã€‚
        æ¢å¤åè¿”å›ç”¨æˆ·è¾“å…¥ï¼Œå¹¶è‡ªåŠ¨å†™å…¥ä¸Šä¸‹æ–‡æ¶ˆæ¯ã€‚
        """
        resume_value = interrupt(payload)
        self._append_user_reply(resume_value)
        return resume_value

    def _append_user_reply(self, resume_value: Any) -> None:
        """å°†ç”¨æˆ·å›å¤è¿½åŠ ä¸º HumanMessageï¼ˆç»Ÿä¸€ç»“æ„ï¼‰"""
        sb = StateBuilder(self._state)
        sb.append_user_reply_inplace(resume_value)
        # interrupt æ¢å¤åï¼Œåç»­è°ƒç”¨åº”åŸºäºæœ€æ–° checkpoint è®°å¿†
        self._messages = sb.memory.snapshot()

    async def get_deliverable(self, agent_id: str) -> Any | None:
        """
        è·å–å…¶ä»– Agent çš„äº§å‡º

        é€šè¿‡ agent_id è·å–ä¸Šæ¸¸ Agent äº§å‡ºçš„äº¤ä»˜ç‰©ã€‚
        å¸¸ç”¨äºæœ‰ä¾èµ–å…³ç³»çš„ Agent ä¹‹é—´ä¼ é€’æ•°æ®ã€‚

        å‚æ•°ï¼š
        - agent_id: ä¸Šæ¸¸ Agent çš„ ID

        è¿”å›ï¼š
        - äº¤ä»˜ç‰©å†…å®¹ï¼ˆdictï¼‰ï¼Œå¦‚æœä¸å­˜åœ¨åˆ™è¿”å› None

        ä½¿ç”¨ç¤ºä¾‹ï¼š
        ```python
        async def run(self, ctx: AgentContext) -> ReportOutput:
            # è·å–æ•°æ®åˆ†æ Agent çš„äº§å‡º
            analysis = await ctx.get_deliverable(agent_id="analyst")
            if not analysis:
                user_reply = ctx.interrupt("ç¼ºå°‘åˆ†ææ•°æ®")
                # å¯æ ¹æ® user_reply è·å–æ•°æ®åç»§ç»­

            # ä½¿ç”¨åˆ†æç»“æœç”ŸæˆæŠ¥å‘Š
            ...
        ```
        """
        from langgraph.config import get_store

        store = get_store()
        if not store:
            logger.warning("Store æœªé…ç½®ï¼Œæ— æ³•è·å– deliverable")
            return None

        store_namespace = ("deliverables", self.namespace, self.session_id)

        try:
            item = await store.aget(store_namespace, agent_id)
            if item:
                return item.value
            return None
        except Exception as e:
            logger.error(f"è·å– deliverable å¤±è´¥: {e}")
            return None
