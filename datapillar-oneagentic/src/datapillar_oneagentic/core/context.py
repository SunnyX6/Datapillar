"""
Agent æ‰§è¡Œä¸Šä¸‹æ–‡

AgentContext æ˜¯æ¡†æ¶æä¾›ç»™ä¸šåŠ¡ Agent çš„æ¥å£ï¼š
- åªè¯»ä¿¡æ¯ï¼šquery, session_id
- å·¥ä½œæ–¹æ³•ï¼šbuild_messages, invoke_tools, get_structured_output, interrupt
- ä¾èµ–è·å–ï¼šget_deliverable

è®¾è®¡åŸåˆ™ï¼š
- ä¸šåŠ¡ä¾§åªèƒ½ä½¿ç”¨å…¬å¼€çš„æ–¹æ³•å’Œå±æ€§
- æ¡†æ¶å†…éƒ¨å¯¹è±¡ç§æœ‰åŒ–ï¼Œé˜²æ­¢ä¸šåŠ¡ä¾§è¶Šæƒ
- è®°å¿†ã€LLMã€å·¥å…·ç­‰ç”±æ¡†æ¶è‡ªåŠ¨ç®¡ç†
- å§”æ´¾ç”±æ¡†æ¶å†…éƒ¨å¤„ç†ï¼Œä¸šåŠ¡ä¾§æ— éœ€å…³å¿ƒ
- Store æ“ä½œå°è£…åœ¨æ¡†æ¶å†…éƒ¨ï¼Œä¸šåŠ¡ä¾§é€šè¿‡ç®€æ´ API è®¿é—®
"""

from __future__ import annotations

import asyncio
import json
import logging
from dataclasses import dataclass, field
from typing import TYPE_CHECKING, Any

from langchain_core.messages import AIMessage, BaseMessage, HumanMessage, SystemMessage
from langgraph.prebuilt import ToolNode
from langgraph.types import Command, interrupt

from datapillar_oneagentic.events import (
    LLMThinkingEvent,
    ToolCalledEvent,
    ToolCompletedEvent,
    ToolFailedEvent,
    event_bus,
)
from datapillar_oneagentic.utils.structured_output import parse_structured_output

if TYPE_CHECKING:
    from datapillar_oneagentic.core.agent import AgentSpec

logger = logging.getLogger(__name__)


def _parse_agent_output(result: Any, schema: type) -> Any:
    """
    è§£æ Agent è¾“å‡ºï¼ˆå¸¦ fallbackï¼‰

    ä¼˜å…ˆä½¿ç”¨ LangChain è§£æç»“æœï¼Œå¤±è´¥æ—¶ç”¨å†…éƒ¨è§£æå™¨å…œåº•ã€‚

    Args:
        result: LLM è¿”å›çš„ç»“æœï¼ˆå¯èƒ½æ˜¯ dictã€Pydantic å¯¹è±¡ç­‰ï¼‰
        schema: æœŸæœ›çš„ Pydantic schema

    Returns:
        è§£æåçš„ schema å®ä¾‹
    """
    # 1. ç›´æ¥æ˜¯ç›®æ ‡ç±»å‹
    if isinstance(result, schema):
        return result

    # 2. dict æ ¼å¼ï¼ˆinclude_raw=Trueï¼‰
    if isinstance(result, dict):
        parsed = result.get("parsed")
        if isinstance(parsed, schema):
            return parsed

        # parsed æ˜¯ dict
        if isinstance(parsed, dict):
            return schema.model_validate(parsed)

        # ä» raw æå–
        raw = result.get("raw")
        if raw:
            # å°è¯•ä» content æå–
            content = getattr(raw, "content", None)
            if content:
                return parse_structured_output(content, schema)

            # å°è¯•ä» tool_calls æå–
            tool_calls = getattr(raw, "tool_calls", None)
            if tool_calls and isinstance(tool_calls, list) and tool_calls:
                args = (
                    tool_calls[0].get("args")
                    if isinstance(tool_calls[0], dict)
                    else getattr(tool_calls[0], "args", None)
                )
                if isinstance(args, dict):
                    return schema.model_validate(args)
                if isinstance(args, str):
                    return parse_structured_output(args, schema)

    # ç”Ÿæˆæ¸…æ™°çš„é”™è¯¯ä¿¡æ¯
    expected_fields = []
    for name, field_info in schema.model_fields.items():
        field_type = (
            field_info.annotation.__name__
            if hasattr(field_info.annotation, "__name__")
            else str(field_info.annotation)
        )
        desc = field_info.description or ""
        expected_fields.append(f"  - {name}: {field_type}" + (f" ({desc})" if desc else ""))

    raise ValueError(
        "æ— æ³•è§£æç»“æ„åŒ–è¾“å‡ºã€‚\n\n"
        "æœŸæœ›çš„ JSON å­—æ®µ:\n" + "\n".join(expected_fields) + "\n\n"
        "å»ºè®®: è¯·ç¡®ä¿ SYSTEM_PROMPT ä¸­æ˜ç¡®æŒ‡å®šäº† JSON è¾“å‡ºæ ¼å¼ï¼Œå­—æ®µåéœ€ä¸ä¸Šè¿°å®šä¹‰ä¸€è‡´ã€‚"
    )


class DelegationSignal(Exception):
    """
    å§”æ´¾ä¿¡å·ï¼ˆæ¡†æ¶å†…éƒ¨ï¼‰

    å½“ Agent è°ƒç”¨å§”æ´¾å·¥å…·æ—¶æŠ›å‡ºï¼Œç”± Executor æ•è·å¤„ç†ã€‚
    ä¸šåŠ¡ä¾§ä¸éœ€è¦çŸ¥é“è¿™ä¸ªå¼‚å¸¸çš„å­˜åœ¨ã€‚
    """

    def __init__(self, command: Command):
        self.command = command
        super().__init__(f"Delegation to {command.goto}")


@dataclass
class AgentContext:
    """
    Agent æ‰§è¡Œä¸Šä¸‹æ–‡

    ä¸šåŠ¡ Agent é€šè¿‡æ­¤ä¸Šä¸‹æ–‡ä¸æ¡†æ¶äº¤äº’ã€‚

    å…¬å¼€å±æ€§ï¼ˆåªè¯»ï¼‰ï¼š
    - session_id: ä¼šè¯ ID
    - query: ç”¨æˆ·è¾“å…¥

    å…¬å¼€æ–¹æ³•ï¼š
    - build_messages(system_prompt): æ„å»º LLM æ¶ˆæ¯
    - invoke_tools(messages): æ‰§è¡Œå·¥å…·è°ƒç”¨å¾ªç¯
    - get_structured_output(messages): è·å–ç»“æ„åŒ–è¾“å‡º
    - interrupt(payload): ä¸­æ–­ç­‰å¾…ç”¨æˆ·å›å¤
    - get_deliverable(agent_id): è·å–å…¶ä»– Agent çš„äº§å‡º

    ä½¿ç”¨ç¤ºä¾‹ï¼š
    ```python
    async def run(self, ctx: AgentContext) -> AnalysisOutput:
        # è·å–ä¸Šæ¸¸ Agent çš„äº§å‡ºï¼ˆé€šè¿‡ agent_idï¼‰
        upstream_data = await ctx.get_deliverable(agent_id="data_extractor")

        # 1. æ„å»ºæ¶ˆæ¯
        messages = ctx.build_messages(self.SYSTEM_PROMPT)

        # 2. å·¥å…·è°ƒç”¨å¾ªç¯ï¼ˆå§”æ´¾ç”±æ¡†æ¶è‡ªåŠ¨å¤„ç†ï¼‰
        messages = await ctx.invoke_tools(messages)

        # 3. è·å–ç»“æ„åŒ–è¾“å‡º
        output = await ctx.get_structured_output(messages)

        # 4. ä¸šåŠ¡åˆ¤æ–­
        if output.confidence < 0.7:
            user_reply = ctx.interrupt("éœ€æ±‚ä¸å¤Ÿæ˜ç¡®")
            # å¯æ ¹æ® user_reply è¡¥å……ä¸Šä¸‹æ–‡åç»§ç»­

        return output
    ```
    """

    # === å…¬å¼€å±æ€§ï¼ˆåªè¯»ï¼‰===
    namespace: str
    """å‘½åç©ºé—´"""

    session_id: str
    """ä¼šè¯ ID"""

    query: str
    """ç”¨æˆ·è¾“å…¥"""

    # === æ¡†æ¶å†…éƒ¨ï¼ˆç§æœ‰åŒ–ï¼‰===
    _spec: AgentSpec = field(default=None, repr=False)
    """Agent è§„æ ¼ï¼ˆæ¡†æ¶å†…éƒ¨ï¼‰"""

    _knowledge_prompt: str = field(default="", repr=False)
    """çŸ¥è¯†ä¸Šä¸‹æ–‡ï¼ˆä½¿ç”¨è€…ä¼ å…¥çš„é™æ€çŸ¥è¯†ï¼‰"""

    _experience_prompt: str = field(default="", repr=False)
    """ç»éªŒä¸Šä¸‹æ–‡ï¼ˆæ¡†æ¶è‡ªåŠ¨æ£€ç´¢æ³¨å…¥ï¼‰"""

    _llm: Any = field(default=None, repr=False)
    """LLM å®ä¾‹ï¼ˆæ¡†æ¶å†…éƒ¨ï¼‰"""

    _tools: list[Any] = field(default_factory=list, repr=False)
    """å·¥å…·åˆ—è¡¨ï¼ˆæ¡†æ¶å†…éƒ¨ï¼‰"""

    _state: dict = field(default_factory=dict, repr=False)
    """å…±äº«çŠ¶æ€ï¼ˆæ¡†æ¶å†…éƒ¨ï¼‰"""

    _delegation_command: Command | None = field(default=None, repr=False)
    """å§”æ´¾å‘½ä»¤ï¼ˆæ¡†æ¶å†…éƒ¨ï¼‰"""

    _messages: list[BaseMessage] = field(default_factory=list, repr=False)
    """æ¶ˆæ¯å†å²ï¼ˆæ¡†æ¶å†…éƒ¨ï¼‰"""

    # === å…¬å¼€æ–¹æ³• ===

    def build_messages(self, system_prompt: str) -> Any:
        """
        æ„å»º LLM æ¶ˆæ¯

        è‡ªåŠ¨æ³¨å…¥ï¼š
        - ç³»ç»Ÿæç¤ºè¯
        - ä¸Šæ¸¸ Agent æ‰§è¡Œä¸Šä¸‹æ–‡ï¼ˆenable_share_context=True æ—¶ï¼‰
        - çŸ¥è¯†ä¸Šä¸‹æ–‡
        - ç»éªŒä¸Šä¸‹æ–‡
        - ç”¨æˆ·æŸ¥è¯¢

        å‚æ•°ï¼š
        - system_prompt: Agent çš„ç³»ç»Ÿæç¤ºè¯

        è¿”å›ï¼š
        - æ¶ˆæ¯å¯¹è±¡ï¼ˆä¸šåŠ¡ä¾§ä¸éœ€è¦äº†è§£å…·ä½“ç±»å‹ï¼Œåªéœ€ä¼ é€’ï¼‰
        """
        messages: list[BaseMessage] = [SystemMessage(content=system_prompt)]

        # æ³¨å…¥ä¸Šä¸‹æ–‡
        context_parts = []

        # ä¸Šæ¸¸ Agent æ‰§è¡Œä¸Šä¸‹æ–‡ï¼ˆenable_share_context=True æ—¶ç”±æ¡†æ¶æ³¨å…¥åˆ° state.messagesï¼‰
        # åªå…±äº« HumanMessage å’Œ AIMessageï¼Œä¸å…±äº« SystemMessage å’Œ ToolMessage
        upstream_messages = self._state.get("messages", [])
        if upstream_messages:
            for msg in upstream_messages:
                if isinstance(msg, (HumanMessage, AIMessage)):
                    messages.append(msg)

        # çŸ¥è¯†ä¸Šä¸‹æ–‡ï¼ˆä½¿ç”¨è€…ä¼ å…¥çš„é™æ€çŸ¥è¯†ï¼‰
        if self._knowledge_prompt:
            context_parts.append(self._knowledge_prompt)

        # ç»éªŒä¸Šä¸‹æ–‡ï¼ˆæ¡†æ¶è‡ªåŠ¨æ£€ç´¢æ³¨å…¥ï¼‰
        if self._experience_prompt:
            context_parts.append(self._experience_prompt)

        if context_parts:
            context_content = "\n\n".join(context_parts)
            messages.append(SystemMessage(content=context_content))

        # ç”¨æˆ·æŸ¥è¯¢ï¼ˆå¦‚æœä¸Šæ¸¸æ²¡æœ‰ messagesï¼Œæ‰æ·»åŠ  HumanMessageï¼‰
        if self.query and not upstream_messages:
            messages.append(HumanMessage(content=self.query))

        self._messages = messages
        return messages

    async def invoke_tools(self, messages: Any) -> Any:
        """
        å·¥å…·è°ƒç”¨å¾ªç¯

        æ‰§è¡Œ LLM è°ƒç”¨å’Œå·¥å…·è°ƒç”¨çš„å¾ªç¯ï¼Œç›´åˆ° LLM ä¸å†è°ƒç”¨å·¥å…·ã€‚
        å¦‚æœè°ƒç”¨äº†å§”æ´¾å·¥å…·ï¼Œä¼šæŠ›å‡º DelegationSignal ç”±æ¡†æ¶å¤„ç†ã€‚

        å…³é”®ä¼˜åŒ–ï¼š
        - bind_tools æ—¶ä¼ å…¥ response_format=deliverable_schema
        - å½“ LLM ä¸å†è°ƒç”¨å·¥å…·æ—¶ï¼Œç›´æ¥è¿”å›ç¬¦åˆ schema çš„ JSON
        - æ— éœ€é¢å¤–è°ƒç”¨ get_structured_output

        å‚æ•°ï¼š
        - messages: build_messages() è¿”å›çš„æ¶ˆæ¯å¯¹è±¡

        è¿”å›ï¼š
        - æ›´æ–°åçš„æ¶ˆæ¯å¯¹è±¡

        å¼‚å¸¸ï¼š
        - DelegationSignal: å½“è°ƒç”¨å§”æ´¾å·¥å…·æ—¶ï¼ˆæ¡†æ¶å†…éƒ¨å¤„ç†ï¼‰
        """
        schema = self._spec.deliverable_schema

        if not self._tools:
            # æ²¡æœ‰å·¥å…·ï¼Œç›´æ¥è°ƒç”¨ LLMï¼ˆå¸¦ç»“æ„åŒ–è¾“å‡ºï¼‰
            llm_structured = self._llm.with_structured_output(schema, method="json_mode")
            response = await llm_structured.ainvoke(messages)
            # å°† Pydantic å¯¹è±¡åºåˆ—åŒ–ä¸º JSON å­—ç¬¦ä¸²ï¼ŒåŒ…è£…æˆ AIMessage
            if hasattr(response, "model_dump_json"):
                content = response.model_dump_json()
            else:
                import json
                content = json.dumps(response) if isinstance(response, dict) else str(response)
            messages.append(AIMessage(content=content))
            self._messages = messages
            return messages

        # åˆ›å»º ToolNode
        tool_node = ToolNode(self._tools)

        # bind_tools ç»‘å®šå·¥å…·
        llm_with_tools = self._llm.bind_tools(self._tools)

        # å‡†å¤‡çŠ¶æ€
        current_state = self._state.copy()

        for _iteration in range(1, self._spec.get_max_steps() + 1):
            # LLM è°ƒç”¨
            response = await llm_with_tools.ainvoke(messages)

            # æå–å¹¶å‘é€æ€è€ƒå†…å®¹ï¼ˆå¦‚æœæœ‰ï¼‰
            thinking_content = self._extract_thinking(response)
            if thinking_content:
                await event_bus.emit(
                    self,
                    LLMThinkingEvent(
                        agent_id=self._spec.id,
                        thinking_content=thinking_content,
                    ),
                )

            if not response.tool_calls:
                # æ²¡æœ‰å·¥å…·è°ƒç”¨ï¼Œç»“æŸ
                messages.append(response)
                break

            messages.append(response)

            # è®°å½•å·¥å…·è°ƒç”¨ä¿¡æ¯ï¼ˆç”¨äºåç»­å‘é€å®Œæˆ/å¤±è´¥äº‹ä»¶ï¼‰
            tool_calls_info = []
            for tc in response.tool_calls:
                tool_name = tc.get("name") if isinstance(tc, dict) else getattr(tc, "name", None)
                tool_args = tc.get("args", {}) if isinstance(tc, dict) else getattr(tc, "args", {})
                tool_call_id = tc.get("id", "") if isinstance(tc, dict) else getattr(tc, "id", "")

                if not tool_name:
                    continue

                logger.info(f"ğŸ”§ [{self._spec.name}] è°ƒç”¨å·¥å…·: {tool_name}")
                tool_calls_info.append({
                    "name": tool_name,
                    "args": tool_args if isinstance(tool_args, dict) else {},
                    "id": tool_call_id or "",
                })
                await event_bus.emit(
                    self,
                    ToolCalledEvent(
                        agent_id=self._spec.id,
                        tool_name=tool_name,
                        tool_input=tool_args if isinstance(tool_args, dict) else {},
                    ),
                )

            # æ‰§è¡Œå·¥å…·ï¼ˆå¸¦è¶…æ—¶æ§åˆ¶ï¼‰
            import time
            tool_start_time = time.time()
            current_state["messages"] = messages
            tool_error = None
            tool_timeout = self._spec.get_tool_timeout_seconds()
            try:
                result = await asyncio.wait_for(
                    tool_node.ainvoke(current_state),
                    timeout=tool_timeout,
                )
            except asyncio.TimeoutError:
                tool_error = f"å·¥å…·è°ƒç”¨è¶…æ—¶ï¼ˆ{tool_timeout}ç§’ï¼‰"
                logger.error(f"â° [{self._spec.name}] {tool_error}")
                for tc_info in tool_calls_info:
                    await event_bus.emit(
                        self,
                        ToolFailedEvent(
                            agent_id=self._spec.id,
                            tool_name=tc_info["name"],
                            error=tool_error,
                        ),
                    )
                raise TimeoutError(tool_error)
            except Exception as e:
                tool_error = str(e)
                # å‘é€æ‰€æœ‰å·¥å…·çš„å¤±è´¥äº‹ä»¶
                for tc_info in tool_calls_info:
                    await event_bus.emit(
                        self,
                        ToolFailedEvent(
                            agent_id=self._spec.id,
                            tool_name=tc_info["name"],
                            error=tool_error,
                        ),
                    )
                raise
            tool_duration_ms = (time.time() - tool_start_time) * 1000

            # è§£æå·¥å…·ç»“æœï¼šåˆ†ç¦» Command å’Œæ™®é€šæ¶ˆæ¯
            delegation_command = None
            new_messages = []

            if isinstance(result, dict):
                new_messages = result.get("messages", [])
            elif isinstance(result, list):
                for item in result:
                    if isinstance(item, Command):
                        # åªå–ç¬¬ä¸€ä¸ª Commandï¼ˆå¤šä¸ªå§”æ´¾ä¸åˆç†ï¼‰
                        if delegation_command is None:
                            delegation_command = item
                        else:
                            logger.warning(f"ğŸ”„ [{self._spec.name}] å¿½ç•¥å¤šä½™çš„å§”æ´¾å‘½ä»¤")
                    else:
                        new_messages.append(item)

            # å¤„ç†å§”æ´¾å‘½ä»¤
            if delegation_command is not None:
                self._delegation_command = delegation_command
                logger.info(f"ğŸ”„ [{self._spec.name}] å§”æ´¾ç»™ {self._delegation_command.goto}")
                self._messages = messages
                # æŠ›å‡ºå§”æ´¾ä¿¡å·ï¼Œç”±æ¡†æ¶å¤„ç†
                raise DelegationSignal(self._delegation_command)

            # å‘é€å·¥å…·å®Œæˆäº‹ä»¶ï¼ˆä» ToolMessage ä¸­æå–ç»“æœï¼‰
            tool_outputs = {}
            for msg in new_messages:
                if hasattr(msg, "tool_call_id") and hasattr(msg, "content"):
                    tool_outputs[msg.tool_call_id] = msg.content

            for tc_info in tool_calls_info:
                tool_output = tool_outputs.get(tc_info["id"], "")
                await event_bus.emit(
                    self,
                    ToolCompletedEvent(
                        agent_id=self._spec.id,
                        tool_name=tc_info["name"],
                        tool_output=tool_output,
                        duration_ms=tool_duration_ms / len(tool_calls_info) if tool_calls_info else 0,
                    ),
                )

            messages.extend(new_messages)

        self._messages = messages
        return messages

    async def get_structured_output(self, messages: Any) -> Any:
        """
        è·å–ç»“æ„åŒ–è¾“å‡º

        ä¼˜åŒ–é€»è¾‘ï¼š
        1. å…ˆå°è¯•ä»æœ€åä¸€æ¡ AIMessage ç›´æ¥è§£æ JSONï¼ˆçœä¸€æ¬¡ LLM è°ƒç”¨ï¼‰
        2. å¦‚æœè§£æå¤±è´¥ï¼Œå†è°ƒç”¨ LLM ç”Ÿæˆç»“æ„åŒ–è¾“å‡º

        å‚æ•°ï¼š
        - messages: invoke_tools() è¿”å›çš„æ¶ˆæ¯å¯¹è±¡

        è¿”å›ï¼š
        - deliverable_schema å®ä¾‹
        """
        schema = self._spec.deliverable_schema

        # ä¼˜åŒ–ï¼šå…ˆå°è¯•ä»æœ€åä¸€æ¡ AIMessage ç›´æ¥è§£æ
        last_ai_content = self._get_last_ai_content(messages)
        if last_ai_content:
            try:
                result = parse_structured_output(last_ai_content, schema)
                return result
            except Exception:
                pass  # è§£æå¤±è´¥ï¼Œå›é€€åˆ° LLM

        # å›é€€ï¼šè°ƒç”¨ LLM ç”Ÿæˆç»“æ„åŒ–è¾“å‡º
        llm_structured = self._llm.with_structured_output(
            schema,
            method="json_mode",
            include_raw=True,
        )
        result = await llm_structured.ainvoke(messages)

        # è§£æç»“æœï¼ˆå¸¦ fallbackï¼‰
        return _parse_agent_output(result, schema)

    def _get_last_ai_content(self, messages: list) -> str | None:
        """è·å–æœ€åä¸€æ¡ AIMessage çš„ content"""
        for msg in reversed(messages):
            if isinstance(msg, AIMessage) and msg.content:
                return msg.content
        return None

    def _extract_thinking(self, response: AIMessage) -> str | None:
        """
        ä» LLM å“åº”ä¸­æå–æ€è€ƒå†…å®¹

        æ”¯æŒå¤šç§æ¨¡å‹çš„æ€è€ƒæ ¼å¼ï¼š
        - GLM: additional_kwargs.reasoning_content
        - Claude: content ä¸­çš„ thinking blocks
        - DeepSeek: additional_kwargs.reasoning_content
        """
        if not isinstance(response, AIMessage):
            return None

        # 1. GLM / DeepSeek æ ¼å¼ï¼ˆreasoning_contentï¼‰
        reasoning = response.additional_kwargs.get("reasoning_content")
        if reasoning:
            return reasoning

        # 2. Claude æ ¼å¼ï¼ˆcontent æ˜¯ listï¼ŒåŒ…å« thinking blocksï¼‰
        content = response.content
        if isinstance(content, list):
            thinking_parts = []
            for block in content:
                if isinstance(block, dict) and block.get("type") == "thinking":
                    thinking_parts.append(block.get("thinking", ""))
            if thinking_parts:
                return "\n".join(thinking_parts)

        return None

    def interrupt(self, payload: Any | None = None) -> Any:
        """
        ä¸­æ–­å¹¶ç­‰å¾…ç”¨æˆ·å›å¤

        payload æ˜¯å¯åºåˆ—åŒ–çš„æç¤ºä¿¡æ¯ï¼ˆå¯é€‰ï¼‰ã€‚
        æ¢å¤åè¿”å›ç”¨æˆ·è¾“å…¥ï¼Œå¹¶è‡ªåŠ¨å†™å…¥ä¸Šä¸‹æ–‡æ¶ˆæ¯ã€‚
        """
        resume_value = interrupt(payload)
        self._append_user_reply(resume_value)
        return resume_value

    def _append_user_reply(self, resume_value: Any) -> None:
        """å°†ç”¨æˆ·å›å¤è¿½åŠ ä¸º HumanMessageï¼ˆç»Ÿä¸€ç»“æ„ï¼‰"""
        content = self._serialize_user_reply(resume_value)
        message = HumanMessage(content=content)

        self._messages.append(message)
        state_messages = self._state.get("messages")
        if isinstance(state_messages, list):
            state_messages.append(message)
        else:
            self._state["messages"] = [message]

    def _serialize_user_reply(self, resume_value: Any) -> str:
        """ç»Ÿä¸€åºåˆ—åŒ–ç”¨æˆ·å›å¤ï¼Œä¿è¯å¯å†™å…¥æ¶ˆæ¯"""
        if isinstance(resume_value, str):
            return resume_value
        try:
            return json.dumps(resume_value, ensure_ascii=False)
        except Exception:
            return str(resume_value)

    async def get_deliverable(self, agent_id: str) -> Any | None:
        """
        è·å–å…¶ä»– Agent çš„äº§å‡º

        é€šè¿‡ agent_id è·å–ä¸Šæ¸¸ Agent äº§å‡ºçš„äº¤ä»˜ç‰©ã€‚
        å¸¸ç”¨äºæœ‰ä¾èµ–å…³ç³»çš„ Agent ä¹‹é—´ä¼ é€’æ•°æ®ã€‚

        å‚æ•°ï¼š
        - agent_id: ä¸Šæ¸¸ Agent çš„ ID

        è¿”å›ï¼š
        - äº¤ä»˜ç‰©å†…å®¹ï¼ˆdictï¼‰ï¼Œå¦‚æœä¸å­˜åœ¨åˆ™è¿”å› None

        ä½¿ç”¨ç¤ºä¾‹ï¼š
        ```python
        async def run(self, ctx: AgentContext) -> ReportOutput:
            # è·å–æ•°æ®åˆ†æ Agent çš„äº§å‡º
            analysis = await ctx.get_deliverable(agent_id="analyst")
            if not analysis:
                user_reply = ctx.interrupt("ç¼ºå°‘åˆ†ææ•°æ®")
                # å¯æ ¹æ® user_reply è·å–æ•°æ®åç»§ç»­

            # ä½¿ç”¨åˆ†æç»“æœç”ŸæˆæŠ¥å‘Š
            ...
        ```
        """
        from langgraph.config import get_store

        store = get_store()
        if not store:
            logger.warning("Store æœªé…ç½®ï¼Œæ— æ³•è·å– deliverable")
            return None

        store_namespaces = [
            ("deliverables", self.namespace, self.session_id, "latest"),
            ("deliverables", self.namespace, self.session_id),
        ]

        try:
            for store_namespace in store_namespaces:
                item = await store.aget(store_namespace, agent_id)
                if item:
                    return item.value
            return None
        except Exception as e:
            logger.error(f"è·å– deliverable å¤±è´¥: {e}")
            return None
