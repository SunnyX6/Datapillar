"""
Datapillar OneAgentic å±‚çº§æ¨¡å¼ç¤ºä¾‹

è¿è¡Œå‘½ä»¤ï¼š
    uv run python examples/quickstart_hierarchical.py
"""

from __future__ import annotations

import asyncio
import json

from pydantic import BaseModel

from datapillar_oneagentic import (
    AgentContext,
    Datapillar,
    DatapillarConfig,
    Process,
    agent,
    tool,
)
from datapillar_oneagentic.providers.llm import Provider


class TextOutput(BaseModel):
    text: str


@tool
def echo(text: str) -> str:
    """å›æ˜¾æ–‡æœ¬ã€‚

    Args:
        text: è¾“å…¥æ–‡æœ¬ã€‚

    Returns:
        å›æ˜¾ç»“æœã€‚
    """
    return f"echo:{text}"


@agent(
    id="manager",
    name="ç»ç†",
    deliverable_schema=TextOutput,
    description="è´Ÿè´£ä»»åŠ¡å§”æ´¾ä¸ç»“æœæ±‡æ€»",
)
class ManagerAgent:
    SYSTEM_PROMPT = """ä½ æ˜¯ç»ç†ã€‚

è¦æ±‚ï¼š
1. å½“æ²¡æœ‰ worker ç»“æœæ—¶ï¼Œå¿…é¡»è°ƒç”¨ delegate_to_workerã€‚
2. æ‹¿åˆ° worker è¾“å‡ºåï¼Œè¾“å‡ºæœ€ç»ˆç»“æœã€‚

## è¾“å‡ºè¦æ±‚
åªèƒ½è¾“å‡º JSONï¼ˆå•ä¸ªå¯¹è±¡ï¼‰ï¼Œä¸å¾—è¾“å‡ºè§£é‡Šæˆ– Markdownï¼š
{"text": "ä½ çš„æ€»ç»“"}
"""

    async def run(self, ctx: AgentContext) -> TextOutput:
        worker = await ctx.get_deliverable("worker")
        if worker:
            messages = ctx.build_messages(
                f"{self.SYSTEM_PROMPT}\nWorker è¾“å‡º: {worker.get('text', '')}"
            )
            return await ctx.get_structured_output(messages)

        messages = ctx.build_messages(self.SYSTEM_PROMPT)
        await ctx.invoke_tools(messages)
        return TextOutput(text="delegated")


@agent(
    id="worker",
    name="æ‰§è¡Œè€…",
    deliverable_schema=TextOutput,
    tools=[echo],
    description="æ‰§è¡Œå…·ä½“ä»»åŠ¡å¹¶è¿”å›ç»“æœ",
)
class WorkerAgent:
    SYSTEM_PROMPT = """ä½ æ˜¯æ‰§è¡Œè€…ã€‚
ä½¿ç”¨ echo å·¥å…·å¤„ç†ç”¨æˆ·è¯·æ±‚å¹¶ç»™å‡ºç»“æœã€‚

## è¾“å‡ºè¦æ±‚
åªèƒ½è¾“å‡º JSONï¼ˆå•ä¸ªå¯¹è±¡ï¼‰ï¼Œä¸å¾—è¾“å‡ºè§£é‡Šæˆ– Markdownï¼š
{"text": "ä½ çš„ç»“æœ"}
"""

    async def run(self, ctx: AgentContext) -> TextOutput:
        messages = ctx.build_messages(self.SYSTEM_PROMPT)
        messages = await ctx.invoke_tools(messages)
        return await ctx.get_structured_output(messages)


def _render_event(event: dict) -> None:
    event_type = event.get("event")
    data = event.get("data", {})
    if event_type == "agent.start":
        agent = event.get("agent", {})
        print(f"\nğŸ¤– [{agent.get('name')}] å¼€å§‹å·¥ä½œ...")
    elif event_type == "agent.thinking":
        message = data.get("message", {})
        thinking = message.get("content", "")
        if thinking:
            agent = event.get("agent", {})
            print(f"\nğŸ§  [{agent.get('id')}] æ€è€ƒä¸­...")
            print(f"   {thinking[:200]}..." if len(thinking) > 200 else f"   {thinking}")
    elif event_type == "tool.call":
        tool_info = data.get("tool", {})
        print(f"   ğŸ”§ è°ƒç”¨: {tool_info.get('name')}")
    elif event_type == "tool.result":
        tool_info = data.get("tool", {})
        result = str(tool_info.get("output", ""))
        if len(result) > 100:
            result = result[:100] + "..."
        print(f"   ğŸ“‹ ç»“æœ: {result}")
    elif event_type == "agent.end":
        deliverable = data.get("deliverable")
        if deliverable is not None:
            print("   âœ… å®Œæˆ")
            print(f"   ğŸ“¦ äº¤ä»˜ç‰©: {json.dumps(deliverable, ensure_ascii=False)}")
    elif event_type == "agent.interrupt":
        interrupt_payload = data.get("interrupt", {}).get("payload")
        print(f"\nâ“ éœ€è¦ç”¨æˆ·è¾“å…¥: {interrupt_payload}")
    elif event_type == "agent.failed":
        error = data.get("error", {})
        print(f"\nâŒ é”™è¯¯: {error.get('detail') or error.get('message')}")


def create_hierarchical_team(config: DatapillarConfig) -> Datapillar:
    team = Datapillar(
        config=config,
        namespace="demo_hier",
        name="å±‚çº§å›¢é˜Ÿç¤ºä¾‹",
        agents=[ManagerAgent, WorkerAgent],
        process=Process.HIERARCHICAL,
        enable_share_context=True,
        verbose=True,
    )
    return team


async def main() -> None:
    config = DatapillarConfig()
    if not config.llm.is_configured():
        supported = ", ".join(Provider.list_supported())
        raise RuntimeError(
            "è¯·å…ˆé…ç½® LLMï¼š\n"
            "  export DATAPILLAR_LLM_PROVIDER=\"openai\"\n"
            "  export DATAPILLAR_LLM_API_KEY=\"sk-xxx\"\n"
            "  export DATAPILLAR_LLM_MODEL=\"gpt-4o\"\n"
            "å¯é€‰ï¼šexport DATAPILLAR_LLM_BASE_URL=\"https://api.openai.com/v1\"\n"
            "å¯é€‰ï¼šexport DATAPILLAR_LLM_ENABLE_THINKING=\"false\"\n"
            f"æ”¯æŒ provider: {supported}"
        )
    team = create_hierarchical_team(config)

    print("=" * 60)
    print("ğŸ—ï¸ å±‚çº§æ¨¡å¼ç¤ºä¾‹å·²å°±ç»ª")
    print(f"   æ¨¡å‹: {config.llm.model}")
    print("   æˆå‘˜: ç»ç† -> æ‰§è¡Œè€…ï¼ˆç»ç†å§”æ´¾ï¼‰")
    print("=" * 60)

    query = (
        "è¯·æ€»ç»“ä»¥ä¸‹å†…å®¹ï¼šDatapillar æä¾›ä»»åŠ¡ç¼–æ’ã€æŒ‡æ ‡ç®¡ç†ä¸æƒé™æ§åˆ¶ï¼Œ"
        "å¼ºè°ƒå¯è§‚æµ‹æ€§ä¸æˆæœ¬æ²»ç†ã€‚"
    )
    print(f"\nğŸ“ ç”¨æˆ·éœ€æ±‚: {query}\n")
    print("-" * 60)

    async for event in team.stream(query=query, session_id="s_demo_hier"):
        _render_event(event)

    print("\n" + "=" * 60)
    print("âœ¨ æ¼”ç¤ºå®Œæˆ")


if __name__ == "__main__":
    asyncio.run(main())
